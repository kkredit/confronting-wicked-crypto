\chapter{EA Debate Arguments}
\label{chap-arguments}

In this chapter we will analyze the \ac{encryption} debate using \acp{argmap}. The maps help one digest the debate, but
there are two important shortcomings of the ones presented here. First, argument mapping is ideally just one tool in the
collaborative process that progressively approaches the problem definition and solution. One can make an approximation
from research, but it is not a replacement for debate arising from live discussion. Second, \acp{argmap} as portrayed in
this thesis can be deceiving about the strength of an argument. Argument nodes show no indication of their strength or
validity; one can formulate ten poor arguments against a single strong one, and a glance at the map will indicate that
the case of the ten is stronger. With those qualifications in mind, let us begin by looking at the factors at the heart
of the conflict.


\section{Contributing Factors}
\label{sed-arg-contrib}

\myfig{fig-args-contrib} maps the central arguments in the EA debate. As previously stated, it is \ac{encryption}'s dual
role as enabler of radical privacy and cornerstone of security is at the heart of the debate. Of course, there is only a
conflict if one sees radical privacy as a bad thing. The right to privacy is both a strongly held value and an enshrined
legal principle, and many use privacy-based arguments to show \ac{EA} as socially undesirable. The Snowden revelations
\cite{landau_making_2013} only unveiled the scale of privacy-eroding U.S. government surveillance enabled by
technological changes, terrorism-motivated policies, and weak oversight \cite{shamsi_2011}. Violations of privacy are
concerning for those most vulnerable and for society at large. For example, Saudi journalist Jamal Khashoggi's private
communications were surveilled by the Saudi government before he became a victim of politically motivated murder
\cite{liebermann_2019}. At a societal level, presence of surveillance alone changes behavior and chills free speech
\cite{rogaway_moral_2015}, while government violations of the law degrade institutional trust.

\begin{sidewaysfigure}
  \centering\CaptionFontSize
  \includegraphics[width=\linewidth]{arguments/build/comprehensive.contrib.pdf}
  \caption[Contributing Factors to the EA Debate]{Contributing Factors to the EA Debate}
  \label{fig-args-contrib}
\end{sidewaysfigure}

The government, and particularly \acl{LE}, argues that encryption is handcuffing their investigational capacity. The
\ac{FBI} has branded strong encryption as ``warrant-proof'' and states that ``the government often cannot obtain the
electronic evidence necessary to investigate and prosecute threats to public and national safety'' \cite{fbi_2020}. The
pro-\ac{EA} argument is typically rooted in public safety: investigators need access to evidence to fulfill their
commission to catch and convict lawbreakers, and encryption is making that too difficult. Five-eyes nations regularly
put out joint statements expressing their frustration with encryption \cite{ministerial_2018} \cite{goodale_2017}, and
were joined in 2020 by India and Japan in a statement emphasizing the growing danger of \ac{CSAM} \cite{intl_2020}.
Child pornography is one the original \ac{horsemen} that some argue are used to scare people into supporting backdoors
\cite{schneier_scaring_2019}, but it is also a problem growing to astonishing proportions. The \textit{New York Times}'s
2019 investigation on the matter quoted one law enforcement officer as estimating that 400,000 New Jerseyans, more than
4\% of the state's population, could be charged with violating child exploitation material laws
\cite{keller_internet_2019}.

Unfortunately, shocking assertions such as this have not been independently confirmed or backed up with hard data.
Intelligence agencies have a long history or misrepresenting positions and overstepping bounds
\cite{johnson_congressional_2004} \cite{shamsi_2011}, and this has led to lack of institutional trust undercutting their
claims that they need \ac{EA}. Indeed, the \ac{FBI} has already been caught exaggerating by several times how many
mobile devices they could not access due to \acl{DE} \cite{devlin_2018}. As Rozenshtein says on this subject, ``It is
impossible to know the precise extent to which encryption frustrates law-enforcement investigations, both because
law-enforcement agencies are only beginning to collect accurate statistics, and because one can never be sure of how an
investigation would have proceeded in the absence of encryption'' \cite{rozenshtein_wicked_2018}, but it is still
crucial to have an accurate depiction of the problem in order to come to justified and helpful solutions. This argument
is analyzed further in the next section.

Information security is a the remaining central issue in the debate. As described in \mysec{sec-crypto-basics},
\ac{cryptography} in various forms plays a foundational technical role in nearly every aspect of security, and
information confidentiality itself is one of the primary properties security practitioners fight to protect. Efforts in
the past have sought to undermine the cryptographic foundations of encryption, though this is not a feature of proposals
today, as that is universally seen as too risky. \mysec{sec-tech-approaches} introduced several alternative technical
approaches to \ac{EA}, but experts still proclaim loud and clear that the current state of the art is far from capable
of providing the type of access \acl{LE} in an acceptably secure manner \cite{abelson_2015} \cite{abelson_risks_1997}.
Security was an afterthought in early computing and networking designs, and the field of cybersecurity is still more of
an art the a science; hobbling systems with a mandate to provide \ac{EA} would inevitably diminish security to some
degree \cite{abelson_2015}.

Finally, one may argue that \ac{EA}, depending on its implementation, could have positive auxiliary use cases. It could
enable malware scanning, administrator access in a business setting, or password recovery. Typically these use cases
have other solutions, however, and to combine the requirements of these uses with those of any reasonable \ac{EA}
proposal would likely fatally weaken it.


\section{Going Dark vs. The Golden Age}

% FIXME: I need to address \cite{koepke_2020} in these maps.

A significant portion of the disconnect between government and technical community representatives is disagreement over
whether law enforcement has \ii{too little} or \ii{too much} access to data. The argument for \ii{too little} is
well-represented by proponent former \ac{FBI} Director James Comey in a 2014 speech titled ``Going Dark''
\cite{comey_2014} (though he did not coin the phrase \cite{swire_encryption_2011}). The argument is represented in
\myfig{fig-arg-going-dark}, also informed by critiques \cite{rogaway_moral_2015}.

\begin{figure}[t!]
  \centering\CaptionFontSize
  \includegraphics[width=\linewidth]{arguments/build/comprehensive.goingdark.pdf}
  \caption{A ``Going Dark'' Argument Map}
  \label{fig-arg-going-dark}
\end{figure}

The ``Going Dark'' argument goes that privacy and safety are both desirable goods, but they inherently conflict, and we
need balance. Individuals must give up some of their personal good of privacy to make room for the public good of
safety. Encryption tips the scales too far towards privacy, upsetting the balance of the status quo. \ac{EA} is needed
to restore the balance and enable law enforcement agencies to do their jobs and protect the public.

The argument has a few blind spots. Depicting privacy and safety as competing in a zero-sum tradeoff ignores all the
ways in which privacy directly enhances safety. Data privacy makes certain crimes more difficult, such as stalking or
identity theft. Privacy is also a public good to the extent that it precludes mass surveillance, an argument explored
more deeply in the ``Golden Age'' side of the argument.

Most importantly, the ``Going Dark'' argument hinges on encryption being responsible for failure of law enforcement
investigations. As described in \mysec{sed-arg-contrib}, there is a lack of data on the extent to which encryption is
itself to blame for failed cases. One can certainly understand the argument, but the lack of evidence is an issue. The
highest-profile case of \ac{the-cw2}, Apple vs. FBI, ended with the \ac{FBI} breaking into the phone but finding nothing
of value. Tellingly, each of Comey's examples in his 2014 speech were not cases where encryption inhibited
investigations, but where cases hypothetically \ii{could} have been inhibited if encryption was a factor
\cite{comey_2014}.

Citing lack of evidence only gets you so far, however. In most cases, it is impossible to know what would have happened
in an investigation unimpeded by strong encryption. This is part of why it is a \ac{wicked-prob}. Indeed, when the
encryption curtain is pulled back, there is often much to see. Unencrypted Facebook Messenger is has approximately 20\%
market share in active monthly users \cite{statista_2020} but accounts for 65\% of \ac{CSAM} reports
\cite{keller_internet_2019}, and European law enforcement's infiltration of encrypted messaging service Encrochat
exposed crime rings and led to a massive raids \cite{cox_2020}.

Aside from encryption entirely, a 2018 study found that law enforcement's primary challenges with digital evidence were
identifying service providers and getting the sought after data from them \cite{carter_2018}. This is in the context of
current legal frameworks and access capabilities. The report is fittingly titled ``Low-Hanging Fruit,'' and also lists
resource limitations and training needs among top priorities. Indeed, many current initiatives are underfunded. Major
anti-\ac{CSAM} legislation passed in 2008, but has been funded at only 50\% of authorized levels, the Justice Department
task force has produced only two of five biennial reports, and a senior executive position within the Justice Department
was never created \cite{keller_internet_2019}. Federal entities commissioned to improve communication between law
enforcement and industry as well as to train law enforcement on managing digital evidence are similarly underfunded
\cite{carter_2018}.

% Golden age

The argument for law enforcement having \ii{too much} access to data claims that instead of law enforcement ``Going
Dark,'' they are living in the ``Golden Age for Surveillance'' \cite{swire_encryption_2011}. This argument goes that
although encryption makes certain data completely unaccessible, technological change on the whole has given authorities
much more digital evidence than encryption has taken away. Paired with the dangers of mass surveillance, encryption is
a necessary defense, and any \ac{EA} implementation would compromise encryption's protection. The argument is mapped in
\myfig{fig-arg-golden-age}.

\begin{figure}[p!]
  \centering\CaptionFontSize
  \includegraphics[width=\linewidth]{arguments/build/comprehensive.goldenage.pdf}
  \caption{A ``Golden Age for Surveillance'' Argument Map}
  \label{fig-arg-golden-age}
\end{figure}

The ``Golden Age'' argument revolves around surveillance, its undesirability, and technology's role in it. Cryptographer
Phillip Rogaway writes at length about the negative impacts of mass surveillance in his essay ``The Moral Character of
Cryptographic Work'' \cite{rogaway_moral_2015}. Rogaway argues that ``pervasive collection \ii{itself} chills
free-speech and threatens liberal democracy'' (emphasis his) through the way its mere existence affects the subject. He
argues that it is fundamentally a tool of power, and though I would add that power from the people created through
representative political process is valid power, clear abuses have undercut reasonable confidence in these institutions.

The next element is that technology has increased the government's surveillance powers. This can hardly be contested.
Going back to Comey's ``Going Dark'' examples once more, each case he cited was cracked by digital evidence that would
not have been available even twenty years ago \cite{comey_2014}. In response to the danger of mass surveillance and the
scale of modern surveillance capabilities, encryption is one of the only privacy-saving tools. (Opting out may be
possible for some, but is not a realistic option for society as a whole.)

While much stronger than the ``Going Dark'' argument, the ``Golden Age for Surveillance'' argument suffers from one
major flaw. It focuses strongly on the abilities of and dangers posed by agencies like the \ac{NSA} and ignores the
problems of local, state, and sometimes-surprisingly-cash-strapped federal law enforcement. The boom in the existence of
digital evidence is clear, but as shown, law enforcement already has trouble acquiring the evidence with the help of
tech and communications companies, and does not have the funding or capability to get it on its own \cite{carter_2018}.
Exacerbating the situation is the ``tech effect,'' which is increasing jurors' expectations of hard evidence in cases
where it may be suspected to exist \cite{shelton_study_2006}.

Still, the fact that the tools of mass surveillance are out of reach for most law enforcement must not be relied upon.
That is, most likely, a temporary situation. A safer criticism of the ``Golden Age'' framing of \ac{EA} is that \ac{EA}
without mass surveillance is conceivable. \ac{EA} implementations that enable law enforcement but thwart mass
surveillance by remote powers subvert most of the ``Golden Age'' argument. Means for \ac{EA} to do so are explored in
future argument maps.


\section{Eliminating Fallacious Arguments}

Analyzing debates in the \ac{argmap} format invites one to seriously consider the merits of opposing arguments. Part of
that consideration includes identifying and eliminating fallacious arguments. In heated, partisan debates, fallacious
arguments spread easily. \myfig{fig-arg-fallacies} shows those used in the encryption and \ac{EA} debate.

% TODO: Dulimarta: Orange/green boxes for consistency? Decide when I make a key.

\begin{figure}[t!]
  \centering\CaptionFontSize
  \includegraphics[width=\linewidth]{arguments/build/comprehensive.fallacies.pdf}
  \caption{Fallacious Arguments of the EA Debate}
  \label{fig-arg-fallacies}
\end{figure}

Let us begin with bad arguments used to attack \ac{EA}. The first is the most common: ``\ac{EA} is a bad idea because
backdoors are insecure.'' It appears on the map as a straw man argument due to the way the term ``backdoor'' is used.
``Backdoor'' is essentially technical shorthand for ``insecure hack that should never be used in production''; when it
is used as a basket term for all \ac{EA} proposals, the audience is primed to think them all stupid and helplessly
dangerous. Thus, the arguer is presenting their opponent's request for some form of \ac{EA} in the worst possible light.

Another common argument is that implementing \ac{EA}---or even researching it---moves us inexorably down a slippery
slope, where government demands will never be satisfied. This argument can be used even if one thinks judicious
hypothetical use of \ac{EA} tools would be a good thing. Going too far and too fast is certainly a danger, but it is
both cynical and fallacious to declare the permanent destruction of privacy as the inevitable end of \ac{EA} research.

It is highly tempting to declare government calls for \ac{EA} disingenuous due to hypocritical behavior in their
treatment of the issues. For example, if combatting \ac{CSAM} is a government priority, how come Congress hasn't funded
it and the Justice Department hasn't prioritized it \cite{keller_internet_2019}? This question, and others like it,
demands an answer, but it ultimately does not impact the validity (or invalidity) of pro-\ac{EA} arguments. The absence
of government funding doesn't mean technical anti-\ac{CSAM} measures are unnecessary.

The final two anti-\ac{EA} fallacies are examples of false dichotomies, presenting the situation as if there are only
two choices. \Acp{wicked-prob} have an unlimited set of possible responses, so reducing it to two (and often, presenting
one as a straw man) is misleading. One false dichotomy is that the only acceptable solutions are perfect \ac{EA} or no
\ac{EA}. This leaves no room for risk-based approaches, the typical security strategy outside the realm of cryptography.
Another false dichotomy is that regulators must either allow strong cryptography or we will live in a mass surveillance
dystopia. This one carries hints of ``slippery slope'' and appeal to emotion as well, framed as a choice between only
two futures. Framing the situation in all or nothing terms harms the chances for successful collaborative debate.

Fallacious arguments used to support \ac{EA} rely heavily on appeal to emotion. Politicians and law enforcement agents
commonly appeal to pity for child abuse victims or fear of terrorists, drug dealers, and kidnappers to make their point.
Public safety is a core value in the debate and the technical community needs to and does take these concerns seriously
\cite{schneier_scaring_2019}. These appeals become fallacious when they are used to manipulate the audience into
supporting measures incommensurate with the problems, or to manipulate the audience into thinking that tech somehow
actually does not care about these issues.

Another argument used to subvert anti-EA arguments from experts goes along the lines of, since we put a man on the moon,
we can surely create secure \ac{EA} \cite{cushing_moon_2018}. This is a weak analogy. The problem of landing an
astronaut on the moon is different from the problem of encryption and \ac{EA} in every way except that it was hard. The
Apollo program solved mostly tame problems, and it had enormous government backing. Resolving the encryption debate has
neither of these factors. Many similar technological-progress based arguments suffer the same faults.

Lastly, government officials often pose \ac{EA} as a problem that security experts simply have not researched enough. If
they just ``nerd harder,'' they can find a solution \cite{schneier_2019}. This misses the point of research done up to
this point. Encryption and \ac{EA} is a \ac{wicked-prob} for which tame, technical-only solutions will not work
\cite{rozenshtein_wicked_2018}. Even on the technical side, experts have stated time and again that depending how you
look at it, the technical problem is solved---\ac{EA} is easy from a purely cryptographic point of view. The hard part
is the security of the interfaces with the human users and administers of the system \cite{abelson_risks_1997}
\cite{abelson_2015}. This may be an area of anemic academic research, but to frame that as the primary roadblock to
progress utterly misses the point.


\section{EA and Alternatives}

Moving on from problem framing and meritless arguments, we next turn to actions that can be taken in response to the
situation. \myfig{fig-arg-measures} breaks the actions down into the current capabilities, legal measures, and \ac{EA}.
Current capabilities can be implemented today, and include maintaining the status quo and increasing investment in
current programs. Legal measures require some change in legal or political direction, but do not require fundamentally
new technical research. These include compelling passwords, which requires legal clarification, and sanctioning lawful
hacking, which requires a strategic pivot and an oversight framework. (These non-\ac{EA} approaches were first
introduced in \mysec{sec-alt-approaches}.) At this level, \ac{EA} is analyzed in general. Specific EA approaches are
addressed in the next map.

\begin{sidewaysfigure}
  \centering\CaptionFontSize
  \includegraphics[width=\linewidth]{arguments/build/comprehensive.measures.pdf}
  \caption{EA and its Alternatives}
  \label{fig-arg-measures}
\end{sidewaysfigure}

Each measure is considered with reference to five metrics. These metrics represent a generalization of metrics from
several sources, including two separate diverse committees gathered to analyze the encryption debate
\cite{committee_decrypting_2018} \cite{group_2019} \cite{varia_2018}. They also align closely to the four central issues
of security, safety, privacy, and trust. The five metrics used to analyze response measures are minimization of
increased security risk, utility to law enforcement, protection of civil liberties---particularly important as after the
analysis of the ``Golden Age for Surveillance'' argument---and economic impact. Economic impact is not as much of a
primary concern as the others, but it does help determine practical viability of a proposal.

Beginning with current capabilities, the first choice is to do nothing. One may come to the conclusion that the current
state of affairs actually does represent an acceptable balance of interests. If technology and government agree on this
approach, then \ac{the-cw2} can end much like the first. However, legislative action is a risk to be mitigated in
itself, and if the technical community ``decides'' on this approach and government continues to reject it, we could be
forced in an undesirable direction.

We could also decide to increase investment in current technologies and investigative techniques. As already shown,
encryption is not the greatest barrier in law enforcement's use of digital evidence \cite{carter_2018}. Even when
encryption is involved, traditional sleuthing can often achieve access. Security expert Bruce Schneier and cyberlaw
expert Orin Kerr have compiled a list of ``encryption workarounds'' that do not rely on \ac{EA}, including finding the
key, guessing the key, accessing plaintext while the device is in use, and finding another copy of the plaintext
\cite{kerr_encryption_2017}. Though probabilistic and time consuming in comparison to \ac{EA}, none of these methods
require new legal or technical capability. These methods are effective \cite{greenberg_2018}, and paired with investment
in current digital evidence capabilities and anti-\ac{CSAM} (for example) task forces, they represent a safe response.

Compelled password disclosure is a proposal to simply require defendants to hand over passwords and \acp{PIN} to their
devices. The legality of this approach is working its way through the courts \cite{bittenbender_2019} \cite{sobel_2019},
as it rubs against the Fifth Amendment right against self-incrimination. Even so, its strongest argument in favor is
that it is cheap. Schneier and Kerr point out that this approach requires the password holder to be known and available
to investigators, the prosecution has to overcome several legal hurdles even if the basic approach is ruled
Constitutionally legal, and even then the defendant may choose to withhold the password and be held in contempt rather
than be charged for crime evidenced by the plaintext \cite{kerr_encryption_2017}.

\Ac{lawful-hacking} is the primary alternative argued for besides investment or \ac{EA}, though it is universally seen
as a sub-optimal compromise \cite{bellovin_lawful_2013} \cite{hennessey_lawful_2016} \cite{rozenshtein_wicked_2018}
\cite{kerr_encryption_2017} \cite{soesanto_2018}. Its advantages: it is effective against those for whom \ac{EA} would
not necessarily work, and, well, it's a technical route that isn't \ac{EA} itself. \Ac{lawful-hacking} has the advantage
over \ac{EA} at being effective against organized crime and terror groups because while they would inevitably use
encryption tools to evade any \ac{EA} scheme, their operational security would fail at some point, letting law
enforcement or intelligence agencies into their networks and devices. This approach is already in use to some extent
\cite{cox_2020}, most famously to bring down cartel kingpin El Chapo \cite{feuer_chapo_2019}.

The real change that this policy would take would be a sanctioning and formalization of this strategy. One downside is
that it would be of little use to ill-resourced departments, nullifying its usefulness for more commonplace crimes. Its
major downside is the altered relation is would create between law enforcement and tech companies. Instead of
cooperation, they are suddenly thrust into competition, with law enforcement incentivized to hoard rather than disclose
vulnerabilities it discovers. Prominent proposals suggest mandating prompt disclosure of discovered vulnerabilities
\cite{bellovin_lawful_2013} \cite{hennessey_lawful_2016}. Theoretically, the supply of vulnerabilities is very large,
and new ones could be found at a rate that maintains law enforcement access at constant levels while improving security
as a positive side effect. The government would source these vulnerabilities from a combination of the public domain,
the commercial exploit market, and a central ``Vulnerability Lab'' \cite{bellovin_lawful_2013}.

The availability and cost of exploits ebbs and flows. On one hand, January 2019 sported a \$2 million price on the
exploit market for an Apple iOS jailbreak bug \cite{goodin_zeroday_2019}. On the other hand, an October 2020 report
shows that law enforcement agencies can extract data from nearly every mobile phone on the market for less than \$2000 a
unit \cite{koepke_2020}. As the exploit arms race continues, exploitability will be inconsistent. In the end, law
enforcement would face periods where it struggles for access, and would need to develop costly exploits in the lab.
Mandatory vulnerability disclosure is key to a \ac{lawful-hacking} proposal; however, based on the \ac{FBI}'s historical
abuses of power \cite{shamsi_2011} and Congress's distaste for funding even initiatives it has passed
\cite{keller_internet_2019} or providing strong oversight \cite{johnson_congressional_2004}, one cannot imagine that the
government would actually give up expensive vulnerabilities easily when they are the pillar of their access strategy.

The final proposal is \ac{EA} itself. Its advantage, generally speaking, is that it would provide reliable access to law
enforcement in a reliable manner. It could serve as a compliment to \ac{lawful-hacking}, blunting the incentive to hoard
vulnerabilities because it would be unnecessary for \ac{EA} compliant systems, which would presumably include mainstream
technology. In that situation, \ac{EA} would combat common crime and \ac{lawful-hacking} would combat organized crime
and terror groups. While impact on civil liberties and mass surveillance depends on implementation, any proposal would
be costly to introduce and threaten U.S. product competitiveness due to perceived insecurity. Indeed, risk to security
is the largest weakness of \ac{EA}. Any proposal has to overcome significant challenges to provide acceptable levels of
risk. The next map analyzes this more closely.


\section{Zooming in on EA}

\myfig{fig-arg-classes} lists several classes of \ac{EA} and arguments in their favor and disfavor. Classes applicable
to both \ac{DIM} and \ac{DAR} include using weak cryptography, trusted-party key escrow, and distributed key escrow.
Using cryptographic puzzles and adding a ghost user apply to the case of \ac{DIM}, and device key escrow applies to
\ac{DAR}.

\begin{sidewaysfigure}[p!]
  \centering\CaptionFontSize
  \includegraphics[width=\linewidth]{arguments/build/comprehensive.classes.pdf}
  \caption{Classes of EA}
  \label{fig-arg-classes}
\end{sidewaysfigure}

It should be noted that the \ac{argmap} format works best when displaying the debate surrounding a single conclusion or
proposal. That leaves room for points and counterpoints to be elaborated in detail, as opposed to creating a tangled web
of un-elaborated connections. For the sake of brevity, this thesis considers \ac{EA}'s alternatives and variations at a
high level. For an excellent, thorough discussion of \ac{EA}'s alternatives and variations, see the National Academies
of Sciences, Engineering, and Medicine's 2018 report titled \ii{Decrypting the Encryption Debate: A Framework for
Decision Makers} \cite{committee_decrypting_2018}.

The first \ac{EA} class is to simply use weak cryptographic ciphers or short encryption keys. This was the approach
taken before \ac{the-cw1}, when strong cryptography was not highly available and subject to export controls. No party
seriously supports this approach today, as it is irreconcilably contradictory to strong security on many levels.

Trusted-party key escrow relies on the an entity or small group of entities to store a key or key recovery information.
There are a wide variety of implementations \cite{denning_taxonomy_1996}, but by definition this class of \ac{EA}
carries a crushing weakness: the centralization of extremely sensitive information. Proponents argue that software
companies' protection of code-signing keys in hardware security modules is evidence that they can protect such sensitive
data when needed \cite{ozzie_2018}, but opponents point out that such keys are accessed quite rarely used (especially
when compared to the likely frequency of \ac{EA} requests) and yet they indeed still leak \cite{green_2018}. Once the
escrowed keys are stolen, as they inevitably would be, every device or message encrypted with them would be at risk.
This is an example of a case when the \ac{argmap} format doesn't do an argument justice---the argument against any
centralized access mechanism is extremely powerful.

Distributed key escrow differs from trusted-party in that it takes strong steps to remove centralized trust. This is
achieved by using distributed systems to make key extraction difficult and inherently public \cite{phan_key_2017}
\cite{servan_schreiber_jje_2020}. If the distributed protocols hold up, one advantage of distribution is that this
approach is that it is more likely to fail by making data unrecoverable than by making unintended data vulnerable,
though more research into this area is needed. The downside of these systems is their complexity, which could make it
costly and hard to update.

One class of \ac{DIM} \ac{EA} involves using strong cryptography, but including cryptographic puzzle pieces as message
metadata. These pieces are designed to reveal the encryption key after the surveiller spends considerable computational
power \cite{bellare_translucent_1996} \cite{wright_crypto_2018}. This approach precludes \ii{mass} surveillance, but it
also enables \ii{arbitrary} surveillance by anyone with enough computing power. Use in common cases would be impractical
due to high cost, but use in high profile cases would be less effective due to the likelihood of \ac{EA} workarounds
employed by sophisticated adversaries. Additionally, the calibration of puzzle difficulty is dependent on the state of
computing. Since opponents can record data and decrypt it later when computational capabilities have changed, the data
becomes steadily less secure over time.

Another \ac{DIM} proposal is to ``conference call'' authorities in as a ghost participant in the conversation. It was
notably suggested by \ac{GCHQ} officials Ian Levy and Crispin Robinson \cite{levy_robinson_2018}. Their writeup begins
with some core ideas of this thesis:

\begin{displayquote}
In any discussion of cyber security, details matter.

Unfortunately, it's the details that are missing from the discussion around lawful access to commodity end-to-end
encrypted services and devices (often called the ``going dark'' problem). Without details, the problem is debated as a
purely academic abstraction concerning security, liberty, and the role of government.

There is a better way that doesn’t involve, on one side, various governments, and on the other side lawyers,
philosophers, and vendors' PR departments continuing to shout at each other. If we can get all parties to look at some
actual detail, some practices and proposals---without asking anyone to compromise on things they fundamentally believe
in---we might get somewhere.
\cite{levy_robinson_2018}
\end{displayquote}

As goodwill participants in the conversation, trying to spur discussion around specific proposals ``without people being
vilified for having a point of view or daring to work on this as a problem,'' they deserve credit and thanks.

Unfortunately, the proposal they share is indeed problematic. The ghost user proposal prides itself on not compromising
strong encryption. This is a good property, but compromising a messaging app's authorization protocol is as dangerous as
compromising its encryption \cite{callas_1_2019}. Fundamentally, it suffers from the same weakness as trusted-party key
escrow; the introduction of an authorization vulnerability in the messaging service provider's platform amounts to a
highly risky centralized access capability \cite{schneier_ghost_2019}. It has the same nature, if a different form, as
rejected key escrow proposals.

% FIXME: add note about how device security actually totally sucks

Finally, one \ac{DAR}-specific \ac{EA} class is device key escrow. In this scheme, key recovery material exists on the
device itself. While not necessary to classify as device key escrow, most of these proposals include physical possession
requirements and additionally ``brick'' the device or make it absolutely clear that \ac{EA} has been performed
\cite{savage_lawful_2018} \cite{ozzie_2018}. Such features preclude mass surveillance and ensure transparency to the
device user. This approach relies on secure hardware and a method of authorizing the recovery request to the device
itself. The authentication step can be paired with other \ac{EA} strategies, such as engaging with trusted-parties or
distributed systems. This is where the device escrow shows its weaknesses. Secure hardware enclaves, though improving,
are not totally reliable, and authentication to the hardware device is susceptible to the same attacks as traditional
escrow \ac{EA}.

Device key escrow's greatest weaknesses, however, still represent signs of progress. It is true that it relies on a
device's secure enclave, but devices already do---it is the same hardware device that manages device unlock and
encryption functionality in the first place. Adding functionality increases the attack surface, but it does not add a
completely new threat vector. It is also true that the process is subject to the same problems as traditional key escrow
after the device has been obtained, but that is precisely the progress that has been made---\ii{after the device has
been obtained}. Leveraging advances in secure hardware design has meaningfully changed the \ac{EA} risk profile.

In 2019, Carnegie Mellon assembled an ideologically diverse group of policy and security experts to engage in the kind
of cross-disciplinary debate this thesis advocates. After considering all the technical corners of the situation, their
report goes into detail on why \ac{EA} for domestic law enforcement (i.e., common cases instead of sophisticated
adversaries) focusing on \ac{DAR} in mobile phones using device key escrow requiring physical access is the most
tractable technical niche to consider \cite{group_2019}. By now it should be clear why: traditional investigation mixed
with a dose of lawful hacking is best suited for advanced opponents, and device key escrow represents actual progress as
a path towards lower-risk \ac{EA} for typical cases.

A strong argument against device key escrow is that device encryption, particularly in mobile phones, may actually pose
the smallest impediment to investigation of any encryption technology. The previously cited report into law enforcement
agencies' ability to access mobile phones clearly demonstrates the current state of affairs: device manufacturers are
losing the exploit arms race, private companies are commodifying the \ac{lawful-hacking} approach for agencies large and
small, and the lack of regulatory strategy has led to pervasive data collection with little oversight
\cite{koepke_2020}. This fact does not undermine the worthiness of research into device-oriented \ac{EA}. First of all,
it underscores the lessons of \mychap{chap-policy}---inaction is an action when facing \acp{wicked-prob}, and in this
case, inaction has led to an undesirable position. Second of all, the current circumstances where device manufacturers
can't keep attackers out is temporary; when law enforcement faces real difficulty again, this issue will immediately
resurface. Law enforcement's anticipation of this is likely why they continue to push for \ac{EA} in spite of present
circumstances. Third of all, regardless of criminal abuse, formalized capability and process can reduce governmental
abuse, which is the clearer threat to privacy and civil liberties.

Despite device key escrow's tractability as a technical niche of \ac{EA}, it still has a long way to go. There are few
proposals, what few there are are high level, and questions of scaling and administration have not been addressed.
However, as \ac{incrementalism}'s Lindblom and even \ac{GCHQ}'s Levy and Robinson have pointed out, focusing on specific
proposals has the opportunity to identify mutually agreeable solutions---or at least refine the problem understanding
enough that the next round of debate can be better informed.

It is this task that we turn to next. The following chapter analyzes one particular device-escrow proposal in detail,
Stefan Savage's ``Lawful Device Access without Mass Surveillance Risk: A Technical Design Discussion''
\cite{savage_lawful_2018}.
