\chapter{Threat Model}
\label{chap-threatmodel}

This chapter consists of a threat model and analysis of a specific device key escrow \ac{EA} proposal, Stefan Savage's
``Lawful Device Access without Mass Surveillance Risk: A Technical Design Discussion'' \cite{savage_lawful_2018}. The
proposal is specific to \acl{DAR} for mobile devices. Due to the length of its title, this proposal will be referred to
by its acronym, \ldawmsR. This chapter assumes that the proposal is accompanied by a legal framework regulating its
application and use, though the legal framework is not the focus of this analysis.

% Note that the creators of the proposal intentionally chose the phrase ``lawful access'' over ``\acl{EA}'' in order to
% emphasize the role of legal process and dispel the negative stigma that accompanies \ac{EA}. I refer to \ldawmsr as an
% \ac{EA} proposal, but use \ac{EA} in ... [that spirit].


\section{Developing a Threat Model}

``What are we building?'' and ``What can go wrong?'' are the essential threat modeling questions. The process of
answering these questions begins with setting goals, identifying threat actors, and declaring scope. The \ldawmsr
proposal describes a threat model against which the proposal was designed. This threat model takes cues from the
\ldawmsr model, but is intended to be more generally applicable for any \ac{DAR} \ac{EA} proposal.

\newcommand{\modelstart}[0]{\begin{itemize}}
\newcommand{\modelitem}[2]{ % Name, description
    \item \textbf{#1} \nopagebreak

    \vspace{0.5\baselineskip} \parbox{\linewidth}{#2} \vspace{0.5\baselineskip}
}
\newcommand{\modelend}{\end{itemize}}

% \newcommand{\modelstart}{\begin{itemize}}
% \newcommand{\modelitem}[2]{\item \textbf{#1.} #2}
% \newcommand{\modelend}{\end{itemize}}

\subsection{Goals}

The goals of an \ac{EA} cryptosystem are taken from the five metrics used to judge \ac{EA} alternatives and variations
in \mychap{chap-arguments}. Each goal is listed according to priority, though no goal has absolute priority over the
others.

\modelstart

\modelitem{Security}{The system should minimize security risk relative to the current baseline. Risk is considered with
respect to both individual devices and the entire class of devices.}

\modelitem{Protection of civil liberties}{The system should include measures to prevent \ac{masssurv} and abuse by
authoritarian regimes. This includes technologically enforcing the fundamental right to privacy outside the context of
warranted search under the rule of law.}

\modelitem{Transparency}{The system should be auditable by the public to allow for verification that its power is being
used responsibly. In the case of \ac{DAR}, access should be apparent to the data owner.}

\modelitem{Law enforcement utility}{The system should be useful to law enforcement in terms of reliability, speed, and
cost.}

\modelitem{Economic impact}{The system should consider global competitiveness of devices using the cryptosystem and the
distribution of costs associated with its development and administration. Even though this is a security-oriented threat
model, a system's design affects its economics, and its economics determines its ultimate feasibility.}

\modelend

\subsection{Threat Actors}

\ac{EA} threat models include the full slate of traditional threat actors.

\modelstart

\modelitem{Criminals: ordinary, organized, cyber}{Criminals threaten the \ac{EA} system by using it to access plaintext
without authority. Ordinary thieves may spy on targets or steal and resell phones. They will have physical access but
only simple tools that use ordinary device interfaces. Organized criminals will have the same motives but considerably
more advanced technical capabilities, including full control over all interfaces. Cyber criminals have a wide variety of
of motivations and capabilities. They will target the backend systems that operate the \ac{EA} system in order to abuse
or sell whatever access capabilities they acquire.}

\modelitem{Insider threat}{Insider threats involve attackers with roles inside the \ac{EA} recovery process who seek to
abuse the system for their own purposes. They could work in law enforcement, a device vendor, or a digital service
provider. They may have the same motivations and skills of any other criminal category, but they have the advantage of
privileged access at some stage in the process.}

\modelitem{Foreign intelligence}{Foreign intelligence agencies and \acp{APT} are constantly looking for ways to escalate
their privilege and tamper with or steal information. They have world-class expertise and computing power, which they
can apply to both individual devices and backend systems. (Here I am referring to \ii{foreign} foreign intelligence
agencies, as opposed to \ii{domestic} foreign intelligence agencies such as the \acs{CIA} or \acs{NSA} in the U.S.,
which are assumed to operate within---though push the boundaries of---the legal framework.)}

\modelitem{Authoritarian regimes}{Governments that do not adhere to rule of law will try to compel administrators of an
\ac{EA} system to provide access upon demand. Legal coercion may or may not be combined with state-backed hacking
capability.}

\modelend

Two non-traditional threats must be considered to make sense of an \ac{EA} proposal in the face of the stated goals and
such a formidable list of threat actors. Understanding these threats requires viewing security with a broader than usual
perspective.

\modelstart

\modelitem{The platform abuser}{The device user him or herself may actually be a threat in the larger safety context.
Therefore, the end user's will is not the platform's top priority.\\

All technologies have embedded values \cite{rogaway_moral_2015}, and at the top of each value system is one top
priority. Traditional device security threat models prioritize the will of end user. This leads to robust design
decisions and honors the user's rights and autonomy.\\

It is dangerous to stray from this rule, but many systems already do. Auto-updating software values the vendor's update
policy over the user's preferences. Digital Rights Management software values corporations' data rights over the user's
(sometimes to extremes \cite{eff_2020}). Unencrypted e-mail software values the e-mail provider's ability to collect
personal information over the user's privacy. \Acl{EA} software values lawful investigation over the user's absolute
privacy. Intentional subversion of the user's will violates a security practitioner's instincts, but it is a frequent
reality.\\

In the broader threat model, the platform abuser uses encryption to hide illicit activities. He or she is a threat to
public safety.}

\modelitem{Hawkish lawmakers}{In the pursuit of security and privacy for society as a whole, aggressive lawmakers that
have the power to \ii{mandate} arbitrary data access present perhaps the largest threat of all. Crypto-anarchists will
encrypt their data above the compromised layer regardless, but above-the-table organizations and most individuals who
use default products will abide by U.S. law.\\

Hawkish lawmakers threaten the security of a cryptosystem (whether it uses \ac{EA} or not) because they may judge the
system as too inhibitive to law enforcement. Therefore, they may outlaw its use and mandate something weaker in its
place.}

\modelend

\subsection{Out of Scope}

The following considerations are beyond the scope of this threat model.

\modelstart

\modelitem{Encyption workarounds}{Encryption workarounds, such as finding a copy of plaintext or guessing a password,
are always a risk. Defending against such workarounds is not the role of the \ac{EA} system itself.}

\modelitem{\ac{EA} workarounds}{The user can evade \ac{EA} mechanisms by encrypting data at a higher level in the tech
stack, for example by encrypting files before saving them to disk. Additionally, investigators or attackers can often
bypass current lockout mechanisms. This has already been discussed, and is not relevant when evaluating the \ac{EA}
system itself.}

\modelitem{Supply chain attacks}{It is necessary to protecting device hardware and software supply chains in order to
prevent surreptitious, trivially exploitable backdoors. For the purposes of this threat model, device hardware and
software are assumed to be uncompromised, aside from the standard amount of bugs and side-channels.}

\modelitem{Manipulation of internal hardware}{Foreign intelligence agencies may have the capability to perform
hyper-advanced hardware analysis and manipulation. Defending against these attacks is not the role of the \ac{EA} system
itself.}

\modelitem{Breakdown in (or absence of) rule of law}{This threat model assumes legitimacy of the legal process used to
obtain the warrant. All forms of government search require oversight. Transparency via auditability, preferably ensured
via technical mechanism, should be a goal for \ac{EA} proposals. However, rule of law is an absolute prerequisite for
which no \ac{EA} mechanism can compensate.}

\modelend


\section{Basic Data at Rest}
\label{sec-basic-dar}

Understanding the \ldawmsr proposal and comparing it to current mobile device encryption technology requires an
understanding of current technology. Apple iPhones are among the most secure consumer mobile phones and serve as the
point of reference for \ldawmsR. Because this analysis is limited to a specific proposal, it is also limited to this
reference architecture. In \myfig{fig-dfd-iphone}, a \ac{DFD} depicts the iPhone's unlock and decryption process
according to Apple's public documentation \cite{apple_2020}.

\begin{figure}[h]
    \centering\CaptionFontSize
    \includegraphics[width=\linewidth]{dfds/build/DAR-level-1-crypto-iphone.png}
    \caption{The basic encrypted mobile phone data flow diagram}
    \label{fig-dfd-iphone}
\end{figure}

This \ac{DFD}, and all that follow, presents the system at a specific level of abstraction. The system representation is
simplified in the spirit of ``all models are wrong, but some are useful.'' The \acp{DFD} exclude some details, but are
accurate for the purposes of communication and threat elicitation.

As the diagram illustrates, several steps occur between the \ac{PIN} being entered and the device being unlocked. The
operating system forwards the \ac{PIN} to the Secure Enclave Processor, which combines the \ac{PIN} with the
device-specific Hardware \ac{UID} to generate the Class key. The Class key is used to decrypt the Volume key, which is
passed to the Encryption Module. The Encryption Module performs encryption and decryption at a hardware level between
the operating system and the encrypted storage.

The \ac{UID} is not depicted in key storage because it is burned into the secure processor silicon and cannot be read by
software. The Volume key is encrypted by the Class key before it is stored. When a user updates his \ac{PIN}, the
encrypted Volume key in storage is replaced with the copy encrypted with the new Class key. Application processors do
not handle any keys or secret information besides the \ac{PIN}. Due to inline encryption in the Encryption Module,
persistent storage does not handle \ac{plaintext} data.


\section{The \ldawmsr Proposal}

\ldawmsr introduces device key escrow, an unexposed hardware interface that mediates \ac{EA} requests, and a
vendor-mediated authorization process. To achieve its goals, the proposal relies on the concepts of self-escrow, time
vaulting, authorization, and transparency. These concepts are summarized in \mytab{table-ldawmsr-concepts}.

\begin{table}[h]
  \caption{Central Concepts in the \ldawmsr Proposal}
  \label{table-ldawmsr-concepts}
  \FlushLeft
  \small
  \begin{tabular}{ |l|p{6.4cm}|p{6.4cm}| }
    \hline
    \thead{Concept} & \thead{Implementation} & \thead{Outcome} \\ \hline
    Self-escrow
    & The Class key is escrowed in encrypted form in the device's Secure Enclave (or equivalent) using a write-only
      component; i.e., software can update the key, but only an unexposed hardware interface can read it.
    & Since the Class key itself is being stored instead of the encryption scheme being changed, there is no change to
      the security of the underlying cryptographic protocols. Physical possession and partial disassembly is required,
      which introduces practical barriers to \ac{masssurv}.
    \\ \hline
    Time vaulting
    & The hardware interface responds to requests only after proof of sustained possession for a ``lockup period (e.g.,
      72 hours).''
    & The waiting period precludes ``sneak and peak'' attacks and further reduces the utility for \ac{masssurv}.
    \\ \hline
    Authorization
    & After the lockup period, the requestor must provide evidence of authorization. This comes from a shared secret
      between the device and the manufacturer which can be obtained via legal process.
    & Physical possession is now not enough; law enforcement (or attackers) must provide this secret information to the
      device to unlock it.
    \\ \hline
    Transparency
    & In addition to the device disassembly, the escrow agent modifies the device (e.g., burns a fuse) when it has been
      unlocked. The device firmware detects this modification.
    & The device user has evidence that the device has been unlocked, preventing covert usage.
    \\ \hline
  \end{tabular}
\end{table}

Device key escrow is considered the most promising technical \ac{EA} direction because of the unique capabilities that
secure hardware offers---namely, physical possession requirements and strong transparency. The physical possession
requirement mitigates the risk of \ac{masssurv}. As Savage adds, it also ``provides a more intuitive compatibility with
common under-standings of the governmentâ€™s reasonable law enforcement powers (e.g., the ability to seize physical
property under court order) than more information-centric approaches, which may appear covert by comparison''
\cite{savage_lawful_2018}. Transparency is also rooted in the physicality of the approach, wherein the device cannot be
unlocked without making irreversible and detectable changes, reducing the risk of both \ac{masssurv} and common criminal
abuse.

One clear weakness in the design is its reliance on the secret used in the authorization protocol shared between the
device and the manufacturer. Although the key is stored on the device, anyone could access the key if they know the
shared secret. This is similar to trusted-party key escrow. The vendor is the trusted party, and they store the
authorization key rather than the encryption key itself. Due to this similarity, the problem of centralized risk is not
fully addressed. This is discussed further in \mysec{sec-prop-threats}.

\ldawmsR's full data flow is illustrated in \myfig{fig-dfd-ldawmsr}. The proposal offers a few variations of the
self-escrow and authorization protocols. This figure uses the asymmetric key pair approach for Class key encryption in
the Secure Enclave, which creates strict hardware requirements. However, Savage offers a symmetric key variant that
achieves the same purposes. The asymmetric key variant was chosen for analysis because it is semantically simpler.

\begin{figure}[p]
    \centering\CaptionFontSize
    \includegraphics[width=0.9\linewidth]{dfds/build/DAR-level-1-crypto-iphone-LDAMSR.png}
    \caption{The LDAWMSR data flow diagram}
    \label{fig-dfd-ldawmsr}
\end{figure}

When law enforcement needs access to a device, it first obtains a warrant to conduct the search. The warrant uniquely
identifies the suspect's mobile device. Law enforcement obtains the device, disassembles it to reveal the unexposed
\ac{EA} hardware interface, and begins the time-vaulted access request. After the lockout period is completed, the
device offers its Device ID only. The law enforcement agency's digital forensics department digitally signs the Device
ID and sends it to the device vendor, alongside the warrant and accompanying proof of legal authorization. The vendor's
access compliance department audits the legal documents and submits the digitally signed Device ID to a secure computing
environment such as a \ac{HSM}. The secure environment authenticates the digital signature, looks up the device's
private Device Seal Key and authorization token, and encrypts them with the law enforcement agency's public key. These
encrypted artifacts are returned to the agency, which decrypts and submits them to the device through the dedicated
interface. First, the authorization token is hashed and compared to the stored hash. If the hash matches, the device
accepts and uses the private Device Seal Key to decrypt the Class key, which was escrowed after being encrypted but the
public Device Seal Key. Once the Class key is decrypted, the escrow agent burns a fuse, and the device is unlocked for
forensic investigation.

This above process is a summary of the system in the \ldawmsr proposal. However, complete proposals must account for the
entire information lifecycle. In order to establish such a system, vendors and law enforcement must build mechanisms to
populate and update the device and \ac{HSM} key stores and databases. \myfig{fig-dfd-ldawmsr-setup} depicts a \ac{DFD}
for these scenarios.

\begin{figure}[H]
  \centering\CaptionFontSize
  \includegraphics[width=\linewidth]{dfds/build/DAR-level-1-crypto-iphone-LDAMSR-setup.png}
  \caption{The LDAWMSR maintenance data flow diagram}
  \label{fig-dfd-ldawmsr-setup}
\end{figure}


\section{Discussion of Threats}
\label{sec-prop-threats}

The next step in threat modeling is to elicit threats based on the system's goals, threat actors, scope, and design.
Recall from \mysec{sec-crypto-basics} that security can be expressed in terms of authentication, integrity,
non-repudiation, confidentiality, availability, and authorization. Threats are often expressed as the opposite of these
properties: spoofing, tampering, repudiation, information disclosure, \acl{DOS}, and elevation of privileged
\cite{shostack_threat_2014}. This section analyzes \ldawmsr according to these categories. Threats that could fall into
multiple categories, such as tampering for the effect of repudiation, are listed only once.

To save space, the tables use shorthand for \acf{LE}, \acf{LEO}, \acf{LEA}, \acf{HSM}, \acf{DID}, \acf{DSK}, \acf{SN},
and \acf{DOS}.

\newcommand{\threattablesettings}{\FlushLeft \small}

\newcommand{\threattablebegin}[3]{
  \begin{FlushLeft}
    \small
    \singlespacing
    \begin{longtable}{ lp{3cm}p{5.2cm}p{6cm} }
      \caption{#1 Threats}
      \label{table-#2}
      \\ \toprule
      \thead{ID} & \thead{#3} & \thead{Effect} & \thead{Mitigation}
      \\ \midrule
      \endfirsthead
      \caption[]{#1 Threats (continued)}
      \\
      \toprule
      \thead{ID} & \thead{#3} & \thead{Effect} & \thead{Mitigation}
      \\
      % \midrule
      \endhead
      \endfoot
      \bottomrule
      \endlastfoot
}

\newcommand{\threattableend}{
    \end{longtable}
  \end{FlushLeft}
}

\subsection{Spoofing}

Spoofing threats are listed in \mytab{table-spoofing}. Notably, \ii{S2} is Eran Tromer's attack \cite{tromer_2018} on
computer scientist Ray Ozzie's related \ac{DAR} \ac{EA} protocol called CLEAR \cite{ozzie_2018}. Savage acknowledges the
influence that CLEAR had on \ldawmsR, and specifically included a note that this proposal is technically vulnerable to
the same threat. This threat is not particularly severe, as the difficulty of such an attack is so high that it is
unlikely to be attempted. Even so, the mitigations listed here would also help.

\threattablebegin{Spoofing}{spoofing}{Spoof}
  S1 & Device is spoofed to LE via plant
  & Attackers plant a device to get LE to unlock it for them.
  & Require the device to be in the forensics department itself the entire time it is unlocked.
  \\ \hline
  S2 & Device is spoofed to LE via forged DID
  & Attackers rig a device to report a different DID and record the entered unlock artifacts, allowing them into a
    target device.
  & Add a hardware integrity check or alternatively unlock the device in a Faraday cage (to prevent telemetry), extract
    its data, and destroy it (to prevent recovering stored data).
  \\ \hline
  S3 & LEO is spoofed to LEA
  & Attackers pose as a LEO while the LEA relays back unlock artifacts.
  & Require the device to be in the forensics department itself the entire time it is unlocked.
  \\ \hline
  S4 & LEA is spoofed to vendor during key exchange
  & Attackers pose as an LEA in order to spoof future access requests.
  & Vendor key exchange process involves thorough in-person verification. Assume only a handful of digital forensics
    laboratories nationwide are authorized to participate.
  \\ \hline
  S5 & LEA is spoofed to vendor during access request
  & Attackers pose as a LEA and submit an access request. Requires forged legal documents and a stolen LEA private key
    (unless attacker is an insider or has executed a spoofed key exchange).
  & Vendor independently verifies all legal documents. Vendor supports a key revocation and update process that involves
    the same level of in-person verification. Assume only a handful of digital forensics laboratories nationwide are
    authorized to participate.
  \\ \hline
  S6 & Manufacturer is spoofed to vendor
  & Attackers pose as the manufacturer to inject malicious data into the DID-DSK database. Must be combined with other
    attacks to be of use.
  & Vendor authenticates data transfers between manufacturing and corporate (does not address a compromised manufacturer
    network or an inside threat).
\threattableend

\subsection{Tampering}

Tampering threats are listed in \mytab{table-tampering}. Note that execution of \ii{S2} above relies on a tampering
attack such as \ii{T1}.

\threattablebegin{Tampering}{tampering}{Tamper}
  T1 & Platform abuser corrupts DSK, DID, or token
  & LE attempts at perform \ac{EA} will fail due to corrupt data. Requires compromise of the Secure Enclave or advanced
    hardware manipulation tools.
  & Since these values are known at manufacturing time and never change, they can be made read-only. (The symmetric key
    variant of \ldawmsr requires updating the symmetric equivalent of the public DSK, and is therefore more vulnerable
    to this threat.)
  \\ \hline
  T2 & Platform abuser destroys the \ac{EA} hardware interface
  & LE attempts to perform \ac{EA} will fail due to damaged hardware.
  & Manufacture the device to require destructive disassembly to access the interface. This increases the cost
    associated with deploying and using the system.
  \\ \hline
  T3 & LE insider tampers with DID before digital signature
  & LEA receives an unauthorized device's unlock artifacts. Can be combined with other attacks to compromise a device.
  & Randomize DIDs to make them unguessable, meaning a target device must be in possession in order for the attacker to
    know what DID to use. Input to the vendor's \ac{HSM} could also include data from the legal documents, such as
    device S/N; the \ac{HSM} would append the S/N to the DID and hash the result, verifying a match with the same stored
    hash before returning the unlock artifacts.
  \\ \hline
  T4 & Attacker tampers with hardware transparency mechanism
  & The device user is unaware that the device was unlocked. Highly implementation dependent, but certainly requires
    advanced hardware manipulation tools.
  & Manufacture the device to require destructive disassembly to access the interface.
\threattableend

\subsection{Repudiation}

Repudiation threats are listed in \mytab{table-repudiation}.

\threattablebegin{Repudiation}{repudiation}{Repudiation}
  R1 & Attacker or authoritarian government repudiates unlock attempt
  & The user is unaware that someone tried to access their device.
  & Manufacture the device to require destructive disassembly to access the interface, or use the same hardware
    transparency mechanism to mark mere access attempts as well.
  \\ \hline
  R2 & Authoritarian government repudiates demanding vendor assistance
  & Governments not respecting the legal framework governing the system can bully the vendor and try to force access
    while maintaining deniability.
  & This is close to being an out of scope threat under the ``rule of law'' exception. However, one could design the
    system to require requests and responses to be recorded on a public ledger. This creates several new difficulties.
  \\ \hline
  R3 & LEA repudiates having unlocked a device
  & The device is undeniably unlocked, but the LEA claims it was not them, allowing possible violations of civil
    liberties and harming transparency.
  & At a high level, the system should require a long paper trail before access can be granted. At a low level, the
    escrow agent could require and store some identifying information before unlocking, such as the LEA's public key
    digitally signed by the vendor, which provides non-repudiation assuming independent access to the device. See also
    the mitigation in \ii{R2}.
  \\ \hline
  R4 & Vendor repudiates having responded to an access request
  & The device is undeniably unlocked, but the vendor claims they did not provide the unlock artifacts, allowing the
    vendor to cover up leaks or distasteful policy decisions by suggesting the device was instead hacked. Harms
    transparency.
  & Assuming independent access to the device, the hardware transparency mechanism should confirm whether the \ac{EA}
    process was used, and the same identifying information used in \ii{R3} would implicate the vendor. See also the
    mitigation in \ii{R2}.
\threattableend

\subsection{Information Disclosure}

Information disclosure threats are listed in \mytab{table-disclosure}. In addition to the threats listed, any attack
aimed at gaining unauthorized access to a device is an information disclosure threat. Most spoofing attacks aim to
disclose information intended for another party.

\threattablebegin{Information Disclosure}{disclosure}{Information \\ Disclosed}
  I1 & Attacker discloses the DSK, DID, the encrypted class key, or hashed token
  & By design, none of the information stored on the phone is sensitive. The most consequential information that could
    be stolen is the DID, which could be paired with other attacks. Disclosing the DID requires either disassembly and
    time vaulting or advanced hardware inspection tooling.
  & Sensitivity of this data has already been mitigated as much as possible.
  \\ \hline
  I2 & Attacker intercepts unlock artifacts between LEA \ac{HSM} and device
  & The attacker is able to unlock the target device alone. Must be combined with a spoofed DID to be of use to other
    devices (see \ii{S2}). The attacker could record the values to replay them after the phone has been returned.
  & See \ii{S2}. If choosing not to destroy the device, to prevent replay attacks, a new token could be generated and
    stored in the vendor HSM, with the new hash installed during the unlock process.
  \\ \hline
  I3 & Attacker steals the LEA private key
  & The attacker is now able to spoof the LEA and decrypt returned unlock artifacts. Without the devices (which are
    already in LE possession), the artifacts are not useful. See \ii{S4} and \ii{S5} for LEA spoofing attacks.
  & The key is stored in an \ac{HSM}, which has extensive security measures. See \ii{S5} for a revocation and update
    mitigation.
  \\ \hline
  I4 & Attacker steals the DID-DSK database
  & This is the big prize, the largest source of centralized risk. With the database, attackers could directly
    compromise any mobile device using this system in their possession, after disassembly, and after the time vault.
    They may also try to sell access to the data.
  & \ii{R3} defines a mitigation that requires use of a vendor private key to create a digital signature as part of the
    authentication process. If used, that key would have to be compromised as well for the database to be of use.
    However, if the database is compromised, that key probably is too. Savage argues that \acp{HSM}, though imperfect,
    actually do provide very strong assurance. Responses could be rate-limited, and leaking an entire database once it's
    in the \ac{HSM} could not go unnoticed. Getting the data in may be harder---see \ii{I5}.
  \\ \hline
  I5 & Attacker steals device unlock artifacts between manufacturing and vendor \ac{HSM}
  & Intercepting the unlock artifacts at the source achieves the same effect as \ii{I4}, only the data set is not
    complete. Instead of granting the ability to unlock any device, including a specific target, this is suited for
    getting access down the line or for sale.
  & The unlock artifacts generation process must be treated as sensitively as the \ac{HSM} itself. The artifacts should
    be encrypted immediately and periodically transported to the corporate \ac{HSM} on physical media. This threat is
    difficult to definitively mitigate.
  \\ \hline
  I6 & Attacker steals device \ac{plaintext} from LEA after unlock process
  & Assuming the attacker doesn't care that the LEA gets access to plaintext, they could ``help'' the LE investigation
    in order to access the data later either when it comes out as public evidence or through compromising the LEA
    itself. This may be useful to authoritarian regimes, foreign intelligence, and organized crime.
  & LEAs must have strong information security of their own. Disclosure of evidence is a natural side effect of
    prosecution, so LEAs must practice discretion in choosing which devices to unlock in case mere information discovery
    poses a great risk in itself.
\threattableend

\subsection{Denial of Service}

\Ac{DOS} threats are listed in \mytab{table-dos}. In addition to the threats listed, \ii{S4} can be used for \ac{DOS} by
surreptitiously invalidating a LEA's identity key, and \ii{T1} and \ii{T2} are tampering attacks designed to deny LEAs
from using the \ac{EA} mechanism.

\threattablebegin{Denial of Service}{dos}{Service Denied}
  D1 & Unlock artifacts recovery
  & \ii{S6} could be used to inject corrupt data to the DID-DSK database, potentially overwriting actual unlock artifact
    data.
  & Verify integrity of new data before entering it into the database, and disallow overwriting entirely.
  \\ \hline
  D2 & Unlock artifacts recovery
  & Determined adversaries could physically destroy the medium storing the DID-DSK database.
  & The \ac{HSM} should be in a physically secure and guarded facility, and the storage medium should be stable and
    persistent.
\threattableend

\subsection{Elevation of Privilege}

Elevation of privilege are listed in \mytab{table-privilege}. Spoofing to usurp a entity's privilege or using any attack
to unlock a device without authorization can be seen as escalation of privilege.

\threattablebegin{Elevation of Privilege}{privilege}{Privilege Gained}
  E1 & Foreign intelligence or organized criminals recruit an insider
  & The primary attacker gains inside access through coercion or bribery, making any other attack easier.
  & Limit the employees, accounts, and computers involved in any element of the system. Perform background checks on
    each employee and maintain detailed logs.
  \\ \hline
  E2 & Unexposed hardware interface allows access to Secure Enclave
  & The attacker gains access to Secure Enclave operations and data, undermining the device and achieving unlock without
    following the \ac{EA} protocol.
  & The time vaulting protocol and all communication over the interface must be thoroughly tested, and if possible,
    formally proven to be logically sound. Analysis must include side channel attacks to affect the time vaulting or
    leak internal data.
  \\ \hline
  E3 & An \ac{HSM} vulnerability allows access to protected data
  & This is a technical route to achieving \ii{I4}, disclosure of the DID-DSK database.
  & The \ac{HSM} should be on an air-gapped network disconnected to the internet, physically guarded, and regularly
    patched. There is no defense against an unknown vulnerability, so security ultimately comes down to incident
    detection and response.
\threattableend


\section{Risk Analysis}

The amount of risk \ldawmsr introduces depends on the number of suggested mitigations that are implemented. Some
possible attacks introduce inherently little risk due to their difficult nature and low pay off. Others introduce
greater risk but can be reasonably addressed. Some threats specifically target transparency, and therefore are difficult
to address without trust. Finally, there are some risks that cannot be safely mitigated. Each of these classes of
threats are discussed in turn.

\ii{S6}, \ii{T1}, \ii{T3}, \ii{I1}, \ii{I3}, \ii{I6}, \ii{D1}, \ii{D2}, and \ii{E1} \ii{E2} are each low-risk. They
either are preventable, unuseful, or already present in the baseline depicted in \mysec{sec-basic-dar}. Although these
threats are not fatal flaws to a design, it is important for a designer to consider and mitigate the risk they pose.
Unless they appear in combination with other threats, they do not deserve more discussion.

\ii{S1}, \ii{S2}, \ii{S3}, \ii{S4}, \ii{S5}, \ii{T2}, \ii{T4}, \ii{R1}, and \ii{I2} are all higher-risk threats to the
security, trustworthiness, and effectiveness of the proposal. However, they can be mitigated through a set of related
requirements: require destructive disassembly of the device to access the \ac{EA} hardware interface, require the device
to be physically present on LEA premises the entire duration it is unlocked, and grant only a handful of LE facilities
the lawful right to use the \ac{EA} mechanism. Requiring destructive disassembly entirely precludes certain attacks.
Requiring the device to be on LEA premises prevents attackers from manipulating LE into achieving the attackers' ends.
Limiting the number of LE facilities that can participate in the \ac{EA} process prevents LE impersonation attacks.
Together, these mitigations make the proposal more resistant to attacks.

\ii{R2}, \ii{R3}, and \ii{R4} are repudiation attacks that belie the system's potential for abuse. The system relies on
legal processes and cooperation of several parties. Even in the U.S., the legal process may involve secret courts,
secret investigations, and secrecy orders on the vendor \cite{shamsi_2011}. Under these conditions, transparency is
difficult to achieve. The destructive disassembly requirement enables transparency at a device level. Auditable logs of
device access \ii{requests and responses} would enable transparency at a system level. \ldawmsr does not create such a
log, though other \ac{DAR} \ac{EA} proposals do \cite{phan_key_2017} \cite{servan_schreiber_jje_2020}
\cite{goldwasser_public_2017}. Unfortunately, building this feature into a proposal makes it potentially vulnerable the
hawkish lawmaker, who may consider too much transparency to be an anti-feature.

Finally, there are the threats of \ii{I4}, \ii{I5}, and \ii{E3}, which each represent the disclosure of unlock artifact
data (the DID-DSK database). These threats create a large amount of risk that cannot be safely mitigated. Storing so
much sensitive data in a central database creates a high-value target for foreign intelligence and cyber criminals. The
vendor needs to protect this database from the most advanced attackers in the world while also regularly updating and
accessing it. \Acp{HSM} and robust security policies would make that a difficult task. The data will almost certainly
leak eventually. The effects of such an event would depend on who stole the unlock artifacts. Criminals would use the
data for personal and financial gain; foreign intelligence and authoritarian regimes would use it to spy on their
enemies. In the worst-case scenario, anyone with specialized tools and disregard for the law could get into any
compliant device after disassembling it and waiting through the time vault.

It is important to give \ldawmsr (and similar \ac{DAR} \ac{EA} proposals) its due. The worst case scenario still
precludes \ac{masssurv} and includes non-repudiation that access occurred. This is a significant gain for \ac{EA}
proposals in terms of transparency and protection of civil liberties.


\section{Achievement of Goals}

This chapter began with a list of goals by which \ac{DAR} \ac{EA} proposals can be measured, including security,
protection of civil liberties, transparency, law enforcement utility, and economic impact. In this section \ldawmsr is
measured against each of these goals.

\paragraph*{Security} Security has already been discussed at length in this chapter. \ldawmsr introduces significant
risk in the DID-DSK database itself, but performs well in many other respects, especially if the recommended mitigations
are implemented. When the unlock artifacts are disclosed, the system becomes simple to attack. However, even in these
conditions, attackers are limited to devices in their physical possession and cannot hide access from their victims.

\paragraph*{Protection of civil liberties} This goal was defined as defending against \ac{masssurv} and abuse by
authoritarian regimes. \ldawmsr successfully protects against \ac{masssurv} due to the physical possession and
destructive disassembly requirements. It is not as effective against authoritarian regimes, which would put intense and
possibly coercive legal pressure on vendors to unlock devices. In the case of an unlock artifacts leak, regimes could
broadly abuse the system. This technology would be unwelcome to those living in countries that do not respect rule of
law.

\paragraph*{Transparency} \ldawmsr provides transparency to the device user, but does not provide transparency to the
public. As discussed in the previous section, the destructive disassembly requirement would result in transparency at
the device level. However, access to a device can only be confirmed if the device is available. Neither the user nor the
public can detect if a device has been unlocked under secretive conditions, whether lawfully or criminally. This creates
potential for government abuse.

\paragraph*{Law enforcement utility} \ldawmsr includes a few tradeoffs between security and law enforcement utility. The
requirements to have physical possession of the device, to wait through the time vault, and to limit the number of
authorized law enforcement laboratories all create barriers to usability. The physical possession requirement is too
important for security to be compromised for utility. Additionally, search and seizure law is already designed for
physical evidence; maintaining the possession requirement makes the system operate within well-understood norms. The
time vault prevents against time-sensitive attacks, though destructive disassembly (not part of the original proposal)
may be enough to cover these cases. The time vault period could be decreased without significant impact. Limiting the
number of laboratories that can use the system reduces the risk of spoofing attacks; local law enforcement would have to
cooperate with one of these special laboratories, such as a regional \ac{FBI} office, to unlock a device. In the end,
law enforcement still has a reliable way to get into lawfully seized devices. \ldawmsr upholds its end, but the
government must fund the \ac{FBI} operation and cultivate cooperation between local and federal agencies.

\paragraph*{Economic impact} Expenses to the vendor fall into three categories---the costs of implementing the design,
running the system, and absorbing lost business. Even if a proposal like \ldawmsr was refined enough to be implemented,
the vendor would need to update hardware designs and create the software systems to get it started. Once in use, the
vendor would face considerable costs in running it securely due to the difficulty of safely accessing and updating the
unlock artifacts. Finally, the vendor would certainly lose privacy-conscious customers to small businesses, foreign
competitors, or resellers offering pre-\ac{EA} devices. The scale of these costs relative to device manufacturer's large
size is unclear. Costs to the government include the \ac{FBI} laboratory cost and the cost of law enforcement resources
and training. \acs{CALEA} includes provisions for government reimbursement of vendor compliance costs, and a similar
provision could be applied to a \ac{DAR} \ac{EA} regulation \cite{edwards_hr4922_1994}.
