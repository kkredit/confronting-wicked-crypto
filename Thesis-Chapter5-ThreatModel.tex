\chapter{Threat Model}
\label{chap-threatmodel}

This chapter consists of a threat model and analysis of a specific device key escrow \ac{EA} proposal, Stefan Savage's
``Lawful Device Access without Mass Surveillance Risk: A Technical Design Discussion'' \cite{savage_lawful_2018}.
Lacking a concise name, this proposal will be referred to by its acronym, \ldawmsR. Note that the creators of the
proposal intentionally chose the phrase ``lawful access'' over ``\acl{EA}'' in order to emphasize the role of legal
process and dispel the negative stigma that accompanies \ac{EA}. I refer to \ldawmsr as an \ac{EA} proposal, but use the
term entirely in the spirit of their paper.

% TODO: remove this paragraph if I end up changing EA to LA


\section{Developing a Threat Model}

The essential threat modeling questions are ``what are we building'' and ``what can go wrong.'' The first step to
answering those questions is to establish goals for the former and a list of threats in anticipation of the latter. The
\ldawmsr proposal describes a threat model against which it was designed. This model takes cues from that one but is
intended to be more generally applicable for any \ac{DAR} \ac{EA} proposal.

\newcommand{\modelstart}[0]{\begin{itemize}}
\newcommand{\modelitem}[2]{ % Name, description
    \item \textbf{#1} \nopagebreak

    \vspace{0.5\baselineskip} \parbox{\linewidth}{#2} \vspace{0.5\baselineskip}
}
\newcommand{\modelend}{\end{itemize}}

% \newcommand{\modelstart}{\begin{itemize}}
% \newcommand{\modelitem}[2]{\item \textbf{#1.} #2}
% \newcommand{\modelend}{\end{itemize}}

\subsection{Goals}

The goals of an \ac{EA} cryptosystem are taken from the metrics of \mychap{chap-arguments}. Their justification stems
from the preceding arguments. Each goal is listed according to priority, though none are absolute.

\modelstart

\modelitem{Security}{The system should minimize increased security risk with reference to the current state of the art.
Risk is considered both with respect to individual devices and to the integrity of the entire class of devices.}

\modelitem{Protection of civil liberties}{The system should include measures to prevent mass surveillance and abuse by
political regimes that violate civil rights. This includes technologically enforcing the fundamental right to privacy
but upon warranted search pursuant to the rule of law.}

\modelitem{Transparency}{The system should be auditable by the public to enable trust that this significant power is
being used responsibly. In the case of \ac{DAR}, the subject of the search should be aware of the access.}

\modelitem{Law enforcement utility}{The system should actually be useful to law enforcement in terms of reliability,
speed, and cost.}

\modelitem{Economic impact}{The system should consider global competitiveness of devices using the cryptosystem as well
as the distribution of costs associated with its development and administration. Even though this is a security-oriented
threat model, architectural decisions determine the system's economics, and economics determines the system's ultimate
feasibility.}

\modelend

\subsection{Threat Actors}

\ac{EA} threat models necessarily include the full cast of traditional threat actors.

\modelstart

\modelitem{Criminals: ordinary, organized, cyber}{Criminals represent a threat to the \ac{EA} system by trying to use it
to gain access without authority. Ordinary thieves may want to spy on a target or steal and resell phones. They will
have physical access but only simple tools, using ordinary device interfaces. Organized criminals will have the same
motives but considerably more advanced technical capabilities, exerting full control over all interfaces. Cyber
criminals have a wide spectrum of motivations and capabilities. Their significant contribution to the threat landscape
is that they will target the backend systems that operate the \ac{EA} system in order to steal and likely sell whatever
access capabilities they can find.}

\modelitem{Insider threat}{The insider threat is someone within the \ac{EA} recovery process, whether at the law
enforcement agency or a vendor, that seeks to abuse the system for their own purposes. They may represent the
motivations and capabilities of any of the criminal categories, but they begin with privileged access somewhere in the
process.}

\modelitem{Foreign intelligence}{Foreign intelligence agencies and \acp{APT} are always looking for means to escalate
access and tamper with and steal information. They have world-class expertise and computing power, which they will apply
to both individual devices and backend systems.}

\modelitem{Authoritarian regimes}{States that do not respect lawful process will try to compel administers of an \ac{EA}
system to provide access upon demand. Legal coercion may or may not be combined with state-backed hacking capability.}

\modelend

To make sense of an \ac{EA} proposal in the face of the stated goals and such a formidable list of threat actors, one
must include two non-traditional threats. To do so is to step back and look at the situation from a broader view than
security experts usually take.

\modelstart

\modelitem{The platform abuser}{Why bother with \ac{EA} at all? Because the device user may actually be a threat in the
larger safety context. The end user is not the most important thing. This is a crucial point.

All technologies have embedded values \cite{rogaway_moral_2015}, and at the top of this value system is some most
important ``thing.'' Traditional device security threat models make the end user the most important thing. This is a
very good rule. It leads to good security priorities and more importantly, honors the user's rights and autonomy.

To stray from this rule is dangerous, but---make no mistake---it is already done on a regular basis. Software that can
force updates values the vendor's judgement over the user's (even if it is a good idea). Software that enforces Digital
Rights Management values corporations' rights over the user's (sometimes to extremes \cite{eff_2020}). Software that
doesn't encrypt user communications at all says the service provider's ability to scrape personal information to create
targeted ads is more important than the user's privacy. Software that enables \ac{EA} values lawful investigatory
process over the user's ultimate privacy. Subversion of the user's will is not a pleasant concept, but a spade is a
spade.

In the broader threat model, the platform abuser is someone who is using the device encryption for cover of illicit
activities. They represent a threat to public safety.}

\modelitem{Hawkish lawmakers}{If one's very highest priorities are security and privacy for society as a whole, then
aggressive lawmakers that have the power to \ii{mandate} arbitrary data access represent perhaps the largest threat of
all. Crypto-anarchists can encrypt their data above the compromised layer all they want, but the vast majority of
individuals using default products and all above-the-table organizations will abide by U.S. law.

The hawkish lawmaker is a threat to the security of a cryptosystem (\ac{EA} or not) in that they may judge it too
inhibitive to law enforcement and outlaw its very use, mandating something weaker in its place.}

\modelend

\subsection{Out of Scope}

The following considerations are out of scope for this threat model.

\modelstart

\modelitem{Encyption workarounds}{Encryption workarounds are always in play for essentially any threat actor at any
time. Discussion for defending against those is out of scope.}

\modelitem{\ac{EA} workarounds}{The user is capable of evading \ac{EA} mechanisms by encrypting data at a higher level
in the tech stack, e.g. by encrypting files before saving them to disk. This has already been discussed, and it out of
scope for evaluating the \ac{EA} system itself.}

\modelitem{Supply chain attacks}{Protecting device hardware and software supply chains is necessary to prevent
surreptitious, trivially exploitable backdoors. For the purposes of this threat model, device hardware and software are
considered to be as-intended, though they are assumed to contain the standard amount of bugs and side-channels.}

\modelitem{Manipulation of internal hardware}{Hyper-advanced hardware analysis and manipulation is a real threat from
foreign intelligence agencies. Defending against these attacks is a separate problem.}

\modelitem{Breakdown in (or absence of) rule of law}{This threat model assumes that the legal process used to obtain the
warrant is valid. Additionally, all forms of surveillance, even when protected from mass surveillance, require
oversight. Transparency via auditability, preferably ensured via technical mechanism, is a goal for good \ac{EA}
proposals. However, rule of law is an absolute prerequisite for which no \ac{EA} mechanism can compensate.}

\modelend

% What are we building?: proposal DFDs
% What can go wrong?: elicitation of threats


\section{Basic Data at Rest}

Answering ``what are we building'' and comparing it with the state of the art requires an understanding of the state of
the art. Apple iPhones are among the most secure consumer mobile phones, and serve as the point of reference for
\ldawmsR. \myfig{fig-dfd-iphone} is a \ac{DFD} depicting the iPhone's unlock and decryption process according to their
public documentation \cite{apple_2020}.

\begin{figure}[h]
    \centering\CaptionFontSize
    \includegraphics[width=\linewidth]{dfds/build/DAR-level-1-crypto-iphone.png}
    \caption{The basic encrypted mobile phone data flow diagram.}
    \label{fig-dfd-iphone}
\end{figure}

This \ac{DFD}, and all that follow, is at a specific level of abstraction, simplified in the spirit of ``all models are
wrong, but some are useful.'' The \acp{DFD} are intended to be useful for communication and threat elicitation only, but
are accurate in that capacity.

As the diagram illustrates, several steps occur between the user entering her \ac{PIN} and unlocking of the device. The
operating system forwards the \ac{PIN} to the Secure Enclave Processor, which combines it with the device-specific
Hardware \ac{UID} to generate the Class key. The Class key is used to decrypt the Volume key, which is finally handed to
the Encryption Module to perform encryption and decryption at a hardware level between the operating system and actual
encrypted storage.

The \ac{UID} is not depicted in key storage because it is actually burned into the secure processor silicon, and cannot
be read by software. The Volume key is stored encrypted by the Class key. When a user updates his \ac{PIN}, the
encrypted Volume key in storage is replaced with the copy encrypted with the new Class key. Application processors never
handle any keys or secret information besides the \ac{PIN}, and due to inline encryption in the Encryption Module,
persistent storage never handles and \ac{plaintext} data.


\section{The \ldawmsr Proposal}

\ldawmsr introduces device key escrow, an unexposed hardware interface that mediates \ac{EA} requests, and a vendor
mediated authorization process. To achieve its goals, the proposal relies on the concepts of self-escrow, time vaulting,
authorization, and transparency. These concepts are summarized in \mytab{table-ldawmsr-concepts}; see the original paper
for full detail \cite{savage_lawful_2018}.

\begin{table}[h]
  \caption{Central Concepts in the \ldawmsr Proposal}
  \label{table-ldawmsr-concepts}
  \FlushLeft
  \small
  \begin{tabular}{ |l|p{6.4cm}|p{6.4cm}| }
    \hline
    \thead{Concept} & \thead{Implementation} & \thead{Outcome} \\ \hline
    Self-escrow
    & The Class key is escrowed in the device's Secure Enclave (or equivalent) using a write-only component; i.e.,
      software can update the key, but only an unexposed hardware interface can read it.
    & Since the Class key itself is being stored, there is no change to the security of the underlying cryptographic
      protocols. Physical possession and partial disassembly is required, which introduces practical barriers to mass
      surveillance.
    \\ \hline
    Time vaulting
    & The hardware interface responds to requests only after proof of sustained possession for a ``lockup period (e.g.,
      72 hours).''
    & The waiting period precludes ``sneak and peak'' attacks and further reduces the utility for mass surveillance.
    \\ \hline
    Authorization
    & After the lockup period, the requestor must provide evidence of authorization. This comes from a shared secret
      between the device and the manufacturer which can be obtained via legal process.
    & Physical possession is now not enough; law enforcement (or attackers) must provide this secret information to the
      device to unlock it.
    \\ \hline
    Transparency
    & In addition to the device disassembly, the escrow agent modifies the device (e.g., burns a fuse) when it has been
      unlocked. The device firmware detects this modification.
    & The device user has evidence that the device has been unlocked, preventing covert usage.
    \\ \hline
  \end{tabular}
\end{table}

Device key escrow is considered the most promising technical \ac{EA} direction because of the unique capabilities that
secure hardware offers, and \ldawmsr demonstrates this capabilities perfectly. The greatest of these capabilities are
physical possession requirements and strong transparency. Physical possession requirements strongly mitigate mass
surveillance and, as Savage puts it, ``provides a more intuitive compatibility with common under-standings of the
governmentâ€™s reasonable law enforcement powers (e.g., the ability to seize physical property under court order) than
more information-centric approaches, which may appear covert by comparison'' \cite{savage_lawful_2018}. Transparency is
also rooted in the physicality of the approach, wherein the device cannot be unlocked without making irreversible and
detectable changes, mitigating both mass surveillance and common criminal abuse.

One clear weakness in the design is the shared secret between the device and the manufacturer used in the authorization
protocol. The key may be stored on the device, but one can access it if they have this shared secret. This is very much
like trusted-party key escrow where the vendor is the trusted party, only they store the authentication key instead of
the unlock key itself. Due to this similarity, one of the biggest \ac{EA} problems of centralized risk is not fully
addressed. This is discussed further in \mysec{sec-prop-threats}.

\ldawmsR's full data flow is illustrated in \myfig{fig-dfd-ldawmsr}. The proposal offers a few variations of the
self-escrow and authorization protocols. This figure uses the asymmetric key pair approach for Class key encryption in
the Secure Enclave, which has stricter hardware requirements; however, Savage offers a symmetric key variant that
achieves the same purposes. The asymmetric key pair approach was chosen here because it is semantically clearer and
easier to illustrate.

\begin{figure}[p]
    \centering\CaptionFontSize
    \includegraphics[width=0.9\linewidth]{dfds/build/DAR-level-1-crypto-iphone-LDAMSR.png}
    \caption{The LDAWMSR data flow diagram.}
    \label{fig-dfd-ldawmsr}
\end{figure}

The lawful access use case operates as follows: law enforcement obtains a warrant to conduct a search, including the
suspect's mobile device. They obtain the phone, disassemble it to expose the \ac{EA} hardware interface, and begin the
time-vaulted access request. After the lockout period is completed, the device offers its Device ID only. The law
enforcement agency's digital forensics department digitally signs the Device ID and sends it to the device vendor,
alongside the warrant and accompanying proof of legal authorization. The vendor's access compliance department audits
the legal documents and submits the digitally signed Device ID to a secure computing environment such as a \ac{HSM}. The
secure environment authenticates the digital signature, looks up the device's private Device Seal Key and authorization
token, and encrypts them with the law enforcement agency's public key. These encrypted artifacts are returned to the
agency, which decrypts and submits them to the device through the dedicated interface. First is the authorization token,
which is hashed and compared to the stored hash. If that values match, the device accepts and uses the private Device
Seal Key to decrypt the Class key, which was escrowed after being encrypted but the public Device Seal Key. Once the
Class key is decrypted, the escrow agent burns a fuse, and the device is unlocked for forensic investigation.

This concludes an summarized overview of the system as described in the proposal. However, in a real system, the entire
information lifecycle matters. In order to establish such a system, vendors and law enforcement must establish
mechanisms to populate and update the device and \ac{HSM} key stores and databases. \myfig{fig-dfd-ldawmsr-setup} is a
\ac{DFD} for these scenarios.

\begin{figure}[p!]
  \centering\CaptionFontSize
  \includegraphics[width=\linewidth]{dfds/build/DAR-level-1-crypto-iphone-LDAMSR-setup.png}
  \caption{The LDAWMSR maintenance data flow diagram.}
  \label{fig-dfd-ldawmsr-setup}
\end{figure}


\section{Discussion of Threats}
\label{sec-prop-threats}

The proposal has been illustrated. What threats does it introduce? Recall from \mysec{sec-crypto-basics} that security
can be expressed in the properties of authentication, integrity, non-repudiation, confidentiality, availability, and
authorization. Threats are often expressed as the negative of these properties: spoofing, tampering, repudiation,
information disclosure, denial of service, and elevation of privileged \cite{shostack_threat_2014}. This section
analyzes \ldawmsr using these categories. Threats that fit under multiple categories, such as tampering for the effect
of repudiation, are listed only once.

To save space, the tables use shorthand for law enforcement (LE); law enforcement officer (LEO); law enforcement agency
(LEA); Device ID (DID);

% TODO: Check list of acronyms up to date here ^^

\newcommand{\threattablesettings}{\FlushLeft \small}

\newcommand{\threattablebegin}[3]{
  \begin{FlushLeft}
    \small
    \begin{longtable}{ lp{3cm}p{5.2cm}p{6cm} }
      \caption{#1 Threats}
      \label{table-#2}
      \\ \toprule
      \thead{ID} & \thead{#3} & \thead{Effect} & \thead{Mitigation}
      \\ \midrule
      \endfirsthead
      \caption[]{#1 Threats (continued)}
      \\
      \toprule
      \thead{ID} & \thead{#3} & \thead{Effect} & \thead{Mitigation}
      \\
      % \midrule
      \endhead
      \endfoot
      \bottomrule
      \endlastfoot
}

\newcommand{\threattableend}{
    \end{longtable}
  \end{FlushLeft}
}

\subsection{Spoofing}

Spoofing threats are listed in \mytab{table-spoofing}. Notably, \ii{S2} is Eran Tromer's attack \cite{tromer_2018} on
computer scientist Ray Ozzie's related \ac{DAR} \ac{EA} protocol called CLEAR \cite{ozzie_2018}. Savage acknowledges the
influence that CLEAR had on \ldawmsR, and specifically included a note that while this proposal is technically
vulnerable to the same threat, the mitigations listed here would help, and furthermore the likelihood of such an attack
is low and the difficulty high.

\threattablebegin{Spoofing}{spoofing}{Spoof}
  S1 & Device is spoofed to LE via plant
  & Attackers plant a device to get LE to unlock it for them.
  & Require the device to be in the forensics department itself the entire time it is unlocked.
  \\ \hline
  S2 & Device is spoofed to LE via forged DID
  & Attackers rig a device to report a different DID and record the entered unlock artifacts, allowing them into a
    target device.
  & Add a hardware integrity check or alternatively unlock the device in a Faraday cage, extract its data, and destroy
    it.
  \\ \hline
  S3 & LEO is spoofed to LEA
  & Attackers pose as a LEO while the LEA relays back unlock artifacts.
  & Require the device to be in the forensics department itself the entire time it is unlocked.
  \\ \hline
  S4 & LEA is spoofed to vendor during key exchange
  & Attackers pose as an LEA in order to spoof future access requests.
  & Vendor key exchange process involves thorough in-person verification.
  \\ \hline
  S5 & LEA is spoofed to vendor during access request
  & Attackers pose as a LEA and submit an access request. Requires forged legal documents and a stolen LEA private key
    (unless attacker is an insider or has executed a spoofed key exchange).
  & Vendor independently verifies all legal documents. Vendor supports a key revocation and update process that involves
    the same level of in-person verification.
  \\ \hline
  S6 & Manufacturer is spoofed to vendor
  & Attackers pose as the manufacturer to inject malicious data into the DID-Seal database. Must be combined with other
    attacks to be of use.
  & Vendor authenticates data transfers between manufacturing and corporate (does not address a compromised manufacturer
    network or an inside threat).
\threattableend

\subsection{Tampering}

Tampering threats are listed in \mytab{table-tampering}.

\threattablebegin{Tampering}{tampering}{Tamper}
  T1 & Defensive user corrupts DSK, DID, or token
  & LE attempts at perform \ac{EA} will fail due to corrupt data. Requires compromise of the Secure Enclave or advanced
    hardware manipulation tools.
  & Since these values are known at manufacturing time and never change, they can be made read-only. (The symmetric key
    variant of \ldawmsr requires updating the symmetric equivalent of the public DSK, and is therefore more vulnerable
    to this threat.)
  \\ \hline
  T2 & Defensive user destroys the \ac{EA} hardware interface
  & LE attempts at perform \ac{EA} will fail due to damaged hardware.
  & Manufacture the device to require destructive disassembly to access the interface. This increases the cost
    associated with deploying and using the system.
  \\ \hline
  T3 & LE insider tampers with DID before digital signature
  & LEA receives an unauthorized device's unlock artifacts. Can be combined with other attacks to compromise a device.
  & Randomize DID's to make them unguessable, meaning a target device must be in possession in order for the attacker to
    know what DID to use. Input to the vendor's \ac{HSM} could also include data from the legal documents, such as
    device S/N; the \ac{HSM} would hash the value and verify a match before returning the unlock artifacts.
  \\ \hline
  T4 & Attacker tampers with hardware transparency mechanism
  & The device user is unaware that the device was unlocked. Highly implementation dependent, but certainly requires
    advanced hardware manipulation tools.
  & Manufacture the device to require destructive disassembly to access the interface.
\threattableend

\subsection{Repudiation}

Repudiation threats are listed in \mytab{table-repudiation}.

\threattablebegin{Repudiation}{repudiation}{Repudiation}
  R1 & Attacker or authoritarian government repudiates unlock attempt
  & The user is unaware that someone tried to access their device.
  & Manufacture the device to require destructive disassembly to access the interface, or use the same hardware
    transparency mechanism to mark mere access attempts as well.
  \\ \hline
  R2 & Authoritarian government repudiates demanding vendor assistance
  & Governments not respecting the legal framework governing the system can bully the vendor and try to force access
    while maintaining deniability.
  & This is close to being an out of scope threat under the ``rule of law'' exception. However, one could design the
    system to require requests to be recorded on a public ledger. This opens up several new difficulties.
  \\ \hline
  R3 & LEA repudiates having unlocked a device
  & The device is undeniably unlocked, but the LEA claims it was not them, allowing possible violations of civil
    liberties and harming transparency.
  & ...
  \\ \hline
  R4 & Vendor repudiates having responded to an access request
  & The device is undeniably unlocked, but the vendor claims they did not provide the unlock artifacts, allowing the
    vendor to cover up leaks or unsavory policy decisions by suggesting the device was instead hacked. Harms
    transparency.
  & ...
\threattableend

\subsection{Information Disclosure}

Information disclosure threats are listed in \mytab{table-disclosure}.

\threattablebegin{Information Disclosure}{disclosure}{Information \\ Disclosed}
  I1 & .
  & .
  & .
  \\ \hline
  I2 & .
  & .
  & .
\threattableend

\subsection{Denial of Service}

Denial of service threats are listed in \mytab{table-dos}.

\threattablebegin{Denial of Service}{dos}{Service Denied}
  D1 & .
  & .
  & .
  \\ \hline
  D2 & .
  & .
  & .
\threattableend

\subsection{Elevation of Privilege}

Elevation of privilege are listed in \mytab{table-privilege}.

\threattablebegin{Elevation of Privilege}{privilege}{Privilege Gained}
  E1 & .
  & .
  & .
  \\ \hline
  E2 & .
  & .
  & .
\threattableend


\section{Response to Frameworks}

% Or just, relationship to my goals?

% How does it answer (or not) committee_decrypting_2018's framework questions? What needs improvement?

% Reflection on how much progress this represents



%%%%%%%%%%%%
% Old notes for reference
% -----------------------
% Chapter 4, threat models
% (how to be specific enough to be useful but generic enough to apply to many systems? Focus on the EA type (DAR v DIM),
%   then apply to specific systems)
% DAR, DIM threat models (make sure to cover abelson_2015)
% Basic proposals
%  --> mappings onto threat models
% At work: 3 example systems analyzed with this threat model
% 1. IM (E2E IM too?) -- in motion
% 2. Cloud storage -- at rest
% 3. Mobile phone -- at rest, but way different scenario than cloud
%  --> include Ozzie's CLEAR, since it was higher profile
%%%%%%%%%%%%
