\chapter{Threat Model}
\label{chap-threatmodel}

This chapter consists of a threat model and analysis of a specific device key escrow \ac{EA} proposal, Stefan Savage's
``Lawful Device Access without Mass Surveillance Risk: A Technical Design Discussion'' \cite{savage_lawful_2018}.
Lacking a concise name, this proposal will be referred to by its acronym, \ldawmsR. Note that the creators of the
proposal intentionally chose the phrase ``lawful access'' over ``\acl{EA}'' in order to emphasize the role of legal
process and dispel the negative stigma that accompanies \ac{EA}. I refer to \ldawmsr as an \ac{EA} proposal, but use the
term entirely in the spirit of their paper.

% TODO: remove this paragraph if I end up changing EA to LA


\section{Developing a Threat Model}

The essential threat modeling questions are ``what are we building'' and ``what can go wrong.'' The first step to
answering those questions is to establish goals for the former and a list of threats in anticipation of the latter. The
\ldawmsr proposal describes a threat model against which it was designed. This model takes cues from that one but is
intended to be more generally applicable for any \ac{DAR} \ac{EA} proposal.

\newcommand{\modelstart}[0]{\begin{itemize}}
\newcommand{\modelitem}[2]{ % Name, description
    \item \textbf{#1} \nopagebreak

    \vspace{0.5\baselineskip} \parbox{\linewidth}{#2} \vspace{0.5\baselineskip}
}
\newcommand{\modelend}{\end{itemize}}

% \newcommand{\modelstart}{\begin{itemize}}
% \newcommand{\modelitem}[2]{\item \textbf{#1.} #2}
% \newcommand{\modelend}{\end{itemize}}

\subsection{Goals}

The goals of an \ac{EA} cryptosystem are taken from the metrics of \mychap{chap-arguments}. Their justification stems
from the preceding arguments. Each goal is listed according to priority, though none are absolute.

\modelstart

\modelitem{Security}{The system should minimize increased security risk with reference to the current state of the art.
Risk is considered both with respect to individual devices and to the integrity of the entire class of devices.}

\modelitem{Protection of civil liberties}{The system should include measures to prevent mass surveillance and abuse by
political regimes that violate civil rights. This includes technologically enforcing the fundamental right to privacy
but upon warranted search pursuant to the rule of law.}

\modelitem{Transparency}{The system should be auditable by the public to enable trust that this significant power is
being used responsibly. In the case of \ac{DAR}, the subject of the search should be aware of the access.}

\modelitem{Law enforcement utility}{The system should actually be useful to law enforcement in terms of reliability,
speed, and cost.}

\modelitem{Economic impact}{The system should consider global competitiveness of devices using the cryptosystem as well
as the distribution of costs associated with its development and administration. Even though this is a security-oriented
threat model, architectural decisions determine the system's economics, and economics determines the system's ultimate
feasibility.}

\modelend

\subsection{Threat Actors}

\ac{EA} threat models necessarily include the full cast of traditional threat actors.

\modelstart

\modelitem{Criminals: ordinary, organized, cyber}{Criminals represent a threat to the \ac{EA} system by trying to use it
to gain access without authority. Ordinary thieves may want to spy on a target or steal and resell phones. They will
have physical access but only simple tools, using ordinary device interfaces. Organized criminals will have the same
motives but considerably more advanced technical capabilities, exerting full control over all interfaces. Cyber
criminals have a wide spectrum of motivations and capabilities. Their significant contribution to the threat landscape
is that they will target the backend systems that operate the \ac{EA} system in order to steal and likely sell whatever
access capabilities they can find.}

\modelitem{Insider threat}{The insider threat is someone within the \ac{EA} recovery process, whether at the law
enforcement agency or a vendor, that seeks to abuse the system for their own purposes. They may represent the
motivations and capabilities of any of the criminal categories, but they begin with privileged access somewhere in the
process.}

\modelitem{Foreign intelligence}{Foreign intelligence agencies and \acp{APT} are always looking for means to escalate
access and tamper with and steal information. They have world-class expertise and computing power, which they will apply
to both individual devices and backend systems. (Here I am referring to \ii{foreign} foreign intelligence agencies, as
opposed to \ii{domestic} foreign intelligence agencies such as the \acs{CIA} or \acs{NSA} in the U.S., which are assumed
to operate within---though push the boundaries of---the legal framework.)}

\modelitem{Authoritarian regimes}{States that do not respect lawful process will try to compel administers of an \ac{EA}
system to provide access upon demand. Legal coercion may or may not be combined with state-backed hacking capability.}

\modelend

To make sense of an \ac{EA} proposal in the face of the stated goals and such a formidable list of threat actors, one
must include two non-traditional threats. To do so is to step back and look at the situation from a broader view than
security experts usually take.

\modelstart

\modelitem{The platform abuser}{Why bother with \ac{EA} at all? Because the device user may actually be a threat in the
larger safety context. The end user is not the most important thing. This is a crucial point.

All technologies have embedded values \cite{rogaway_moral_2015}, and at the top of this value system is some most
important ``thing.'' Traditional device security threat models make the end user the most important thing. This is a
very good rule. It leads to good security priorities and more importantly, honors the user's rights and autonomy.

To stray from this rule is dangerous, but---make no mistake---it is already done on a regular basis. Software that can
force updates values the vendor's judgement over the user's (even if it is a good idea). Software that enforces Digital
Rights Management values corporations' rights over the user's (sometimes to extremes \cite{eff_2020}). Software that
doesn't encrypt user communications at all says the service provider's ability to scrape personal information to create
targeted ads is more important than the user's privacy. Software that enables \ac{EA} values lawful investigatory
process over the user's ultimate privacy. Subversion of the user's will is not a pleasant concept, but a spade is a
spade.

In the broader threat model, the platform abuser is someone who is using the device encryption for cover of illicit
activities. They represent a threat to public safety.}

\modelitem{Hawkish lawmakers}{If one's very highest priorities are security and privacy for society as a whole, then
aggressive lawmakers that have the power to \ii{mandate} arbitrary data access represent perhaps the largest threat of
all. Crypto-anarchists can encrypt their data above the compromised layer all they want, but the vast majority of
individuals using default products and all above-the-table organizations will abide by U.S. law.

The hawkish lawmaker is a threat to the security of a cryptosystem (\ac{EA} or not) in that they may judge it too
inhibitive to law enforcement and outlaw its very use, mandating something weaker in its place.}

\modelend

\subsection{Out of Scope}

The following considerations are out of scope for this threat model.

\modelstart

\modelitem{Encyption workarounds}{Encryption workarounds are always in play for essentially any threat actor at any
time. Discussion for defending against those is out of scope.}

\modelitem{\ac{EA} workarounds}{The user is capable of evading \ac{EA} mechanisms by encrypting data at a higher level
in the tech stack, e.g. by encrypting files before saving them to disk. This has already been discussed, and it out of
scope for evaluating the \ac{EA} system itself.}

\modelitem{Supply chain attacks}{Protecting device hardware and software supply chains is necessary to prevent
surreptitious, trivially exploitable backdoors. For the purposes of this threat model, device hardware and software are
considered to be as-intended, though they are assumed to contain the standard amount of bugs and side-channels.}

\modelitem{Manipulation of internal hardware}{Hyper-advanced hardware analysis and manipulation is a real threat from
foreign intelligence agencies. Defending against these attacks is a separate problem.}

\modelitem{Breakdown in (or absence of) rule of law}{This threat model assumes that the legal process used to obtain the
warrant is valid. Additionally, all forms of surveillance, even when protected from mass surveillance, require
oversight. Transparency via auditability, preferably ensured via technical mechanism, is a goal for good \ac{EA}
proposals. However, rule of law is an absolute prerequisite for which no \ac{EA} mechanism can compensate.}

\modelend


\section{Basic Data at Rest}
\label{sec-basic-dar}

Answering ``what are we building'' and comparing it with the state of the art requires an understanding of the state of
the art. Apple iPhones are among the most secure consumer mobile phones, and serve as the point of reference for
\ldawmsR. \myfig{fig-dfd-iphone} is a \ac{DFD} depicting the iPhone's unlock and decryption process according to their
public documentation \cite{apple_2020}.

\begin{figure}[h]
    \centering\CaptionFontSize
    \includegraphics[width=\linewidth]{dfds/build/DAR-level-1-crypto-iphone.png}
    \caption{The basic encrypted mobile phone data flow diagram.}
    \label{fig-dfd-iphone}
\end{figure}

This \ac{DFD}, and all that follow, is at a specific level of abstraction, simplified in the spirit of ``all models are
wrong, but some are useful.'' The \acp{DFD} are intended to be useful for communication and threat elicitation only, but
are accurate in that capacity.

As the diagram illustrates, several steps occur between the user entering her \ac{PIN} and unlocking of the device. The
operating system forwards the \ac{PIN} to the Secure Enclave Processor, which combines it with the device-specific
Hardware \ac{UID} to generate the Class key. The Class key is used to decrypt the Volume key, which is finally handed to
the Encryption Module to perform encryption and decryption at a hardware level between the operating system and actual
encrypted storage.

The \ac{UID} is not depicted in key storage because it is actually burned into the secure processor silicon, and cannot
be read by software. The Volume key is stored encrypted by the Class key. When a user updates his \ac{PIN}, the
encrypted Volume key in storage is replaced with the copy encrypted with the new Class key. Application processors never
handle any keys or secret information besides the \ac{PIN}, and due to inline encryption in the Encryption Module,
persistent storage never handles and \ac{plaintext} data.


\section{The \ldawmsr Proposal}

\ldawmsr introduces device key escrow, an unexposed hardware interface that mediates \ac{EA} requests, and a vendor
mediated authorization process. To achieve its goals, the proposal relies on the concepts of self-escrow, time vaulting,
authorization, and transparency. These concepts are summarized in \mytab{table-ldawmsr-concepts}; see the original paper
for full detail \cite{savage_lawful_2018}.

\begin{table}[h]
  \caption{Central Concepts in the \ldawmsr Proposal}
  \label{table-ldawmsr-concepts}
  \FlushLeft
  \small
  \begin{tabular}{ |l|p{6.4cm}|p{6.4cm}| }
    \hline
    \thead{Concept} & \thead{Implementation} & \thead{Outcome} \\ \hline
    Self-escrow
    & The Class key is escrowed in the device's Secure Enclave (or equivalent) using a write-only component; i.e.,
      software can update the key, but only an unexposed hardware interface can read it.
    & Since the Class key itself is being stored, there is no change to the security of the underlying cryptographic
      protocols. Physical possession and partial disassembly is required, which introduces practical barriers to mass
      surveillance.
    \\ \hline
    Time vaulting
    & The hardware interface responds to requests only after proof of sustained possession for a ``lockup period (e.g.,
      72 hours).''
    & The waiting period precludes ``sneak and peak'' attacks and further reduces the utility for mass surveillance.
    \\ \hline
    Authorization
    & After the lockup period, the requestor must provide evidence of authorization. This comes from a shared secret
      between the device and the manufacturer which can be obtained via legal process.
    & Physical possession is now not enough; law enforcement (or attackers) must provide this secret information to the
      device to unlock it.
    \\ \hline
    Transparency
    & In addition to the device disassembly, the escrow agent modifies the device (e.g., burns a fuse) when it has been
      unlocked. The device firmware detects this modification.
    & The device user has evidence that the device has been unlocked, preventing covert usage.
    \\ \hline
  \end{tabular}
\end{table}

Device key escrow is considered the most promising technical \ac{EA} direction because of the unique capabilities that
secure hardware offers, and \ldawmsr demonstrates this capabilities perfectly. The greatest of these capabilities are
physical possession requirements and strong transparency. Physical possession requirements strongly mitigate mass
surveillance and, as Savage puts it, ``provides a more intuitive compatibility with common under-standings of the
government’s reasonable law enforcement powers (e.g., the ability to seize physical property under court order) than
more information-centric approaches, which may appear covert by comparison'' \cite{savage_lawful_2018}. Transparency is
also rooted in the physicality of the approach, wherein the device cannot be unlocked without making irreversible and
detectable changes, mitigating both mass surveillance and common criminal abuse.

One clear weakness in the design is the shared secret between the device and the manufacturer used in the authorization
protocol. The key may be stored on the device, but one can access it if they have this shared secret. This is very much
like trusted-party key escrow where the vendor is the trusted party, only they store the authentication key instead of
the unlock key itself. Due to this similarity, one of the biggest \ac{EA} problems of centralized risk is not fully
addressed. This is discussed further in \mysec{sec-prop-threats}.

\ldawmsR's full data flow is illustrated in \myfig{fig-dfd-ldawmsr}. The proposal offers a few variations of the
self-escrow and authorization protocols. This figure uses the asymmetric key pair approach for Class key encryption in
the Secure Enclave, which has stricter hardware requirements; however, Savage offers a symmetric key variant that
achieves the same purposes. The asymmetric key pair approach was chosen here because it is semantically clearer and
easier to illustrate.

\begin{figure}[p]
    \centering\CaptionFontSize
    \includegraphics[width=0.9\linewidth]{dfds/build/DAR-level-1-crypto-iphone-LDAMSR.png}
    \caption{The LDAWMSR data flow diagram.}
    \label{fig-dfd-ldawmsr}
\end{figure}

The lawful access use case operates as follows: law enforcement obtains a warrant to conduct a search, including the
suspect's mobile device. They obtain the phone, disassemble it to expose the \ac{EA} hardware interface, and begin the
time-vaulted access request. After the lockout period is completed, the device offers its Device ID only. The law
enforcement agency's digital forensics department digitally signs the Device ID and sends it to the device vendor,
alongside the warrant and accompanying proof of legal authorization. The vendor's access compliance department audits
the legal documents and submits the digitally signed Device ID to a secure computing environment such as a \ac{HSM}. The
secure environment authenticates the digital signature, looks up the device's private Device Seal Key and authorization
token, and encrypts them with the law enforcement agency's public key. These encrypted artifacts are returned to the
agency, which decrypts and submits them to the device through the dedicated interface. First is the authorization token,
which is hashed and compared to the stored hash. If that values match, the device accepts and uses the private Device
Seal Key to decrypt the Class key, which was escrowed after being encrypted but the public Device Seal Key. Once the
Class key is decrypted, the escrow agent burns a fuse, and the device is unlocked for forensic investigation.

This concludes an summarized overview of the system as described in the proposal. However, in a real system, the entire
information lifecycle matters. In order to establish such a system, vendors and law enforcement must establish
mechanisms to populate and update the device and \ac{HSM} key stores and databases. \myfig{fig-dfd-ldawmsr-setup} is a
\ac{DFD} for these scenarios.

\begin{figure}[H]
  \centering\CaptionFontSize
  \includegraphics[width=\linewidth]{dfds/build/DAR-level-1-crypto-iphone-LDAMSR-setup.png}
  \caption{The LDAWMSR maintenance data flow diagram.}
  \label{fig-dfd-ldawmsr-setup}
\end{figure}


\section{Discussion of Threats}
\label{sec-prop-threats}

The proposal has been illustrated. What threats does it introduce? Recall from \mysec{sec-crypto-basics} that security
can be expressed in the properties of authentication, integrity, non-repudiation, confidentiality, availability, and
authorization. Threats are often expressed as the negative of these properties: spoofing, tampering, repudiation,
information disclosure, \acl{DOS}, and elevation of privileged \cite{shostack_threat_2014}. This section
analyzes \ldawmsr using these categories. Threats that fit under multiple categories, such as tampering for the effect
of repudiation, are listed only once.

To save space, the tables use shorthand for law enforcement (LE), law enforcement officer (LEO), law enforcement agency
(LEA), Device ID (DID), Device Seal Key (DSK), \acf{DOS}

% TODO: Check list of acronyms up to date here ^^

\newcommand{\threattablesettings}{\FlushLeft \small}

\newcommand{\threattablebegin}[3]{
  \begin{FlushLeft}
    \small
    \begin{longtable}{ lp{3cm}p{5.2cm}p{6cm} }
      \caption{#1 Threats}
      \label{table-#2}
      \\ \toprule
      \thead{ID} & \thead{#3} & \thead{Effect} & \thead{Mitigation}
      \\ \midrule
      \endfirsthead
      \caption[]{#1 Threats (continued)}
      \\
      \toprule
      \thead{ID} & \thead{#3} & \thead{Effect} & \thead{Mitigation}
      \\
      % \midrule
      \endhead
      \endfoot
      \bottomrule
      \endlastfoot
}

\newcommand{\threattableend}{
    \end{longtable}
  \end{FlushLeft}
}

\subsection{Spoofing}

Spoofing threats are listed in \mytab{table-spoofing}. Notably, \ii{S2} is Eran Tromer's attack \cite{tromer_2018} on
computer scientist Ray Ozzie's related \ac{DAR} \ac{EA} protocol called CLEAR \cite{ozzie_2018}. Savage acknowledges the
influence that CLEAR had on \ldawmsR, and specifically included a note that while this proposal is technically
vulnerable to the same threat, the mitigations listed here would help, and furthermore the likelihood of such an attack
is low and the difficulty high.

\threattablebegin{Spoofing}{spoofing}{Spoof}
  S1 & Device is spoofed to LE via plant
  & Attackers plant a device to get LE to unlock it for them.
  & Require the device to be in the forensics department itself the entire time it is unlocked.
  \\ \hline
  S2 & Device is spoofed to LE via forged DID
  & Attackers rig a device to report a different DID and record the entered unlock artifacts, allowing them into a
    target device.
  & Add a hardware integrity check or alternatively unlock the device in a Faraday cage (to prevent telemetry), extract
    its data, and destroy it (to prevent recovering stored data).
  \\ \hline
  S3 & LEO is spoofed to LEA
  & Attackers pose as a LEO while the LEA relays back unlock artifacts.
  & Require the device to be in the forensics department itself the entire time it is unlocked.
  \\ \hline
  S4 & LEA is spoofed to vendor during key exchange
  & Attackers pose as an LEA in order to spoof future access requests.
  & Vendor key exchange process involves thorough in-person verification. Assume only a handful of digital forensics
    laboratories nationwide are authorized to participate.
  \\ \hline
  S5 & LEA is spoofed to vendor during access request
  & Attackers pose as a LEA and submit an access request. Requires forged legal documents and a stolen LEA private key
    (unless attacker is an insider or has executed a spoofed key exchange).
  & Vendor independently verifies all legal documents. Vendor supports a key revocation and update process that involves
    the same level of in-person verification. Assume only a handful of digital forensics laboratories nationwide are
    authorized to participate.
  \\ \hline
  S6 & Manufacturer is spoofed to vendor
  & Attackers pose as the manufacturer to inject malicious data into the DID-DSK database. Must be combined with other
    attacks to be of use.
  & Vendor authenticates data transfers between manufacturing and corporate (does not address a compromised manufacturer
    network or an inside threat).
\threattableend

\subsection{Tampering}

Tampering threats are listed in \mytab{table-tampering}. \ii{S2} relies on tampering similar to \ii{T1}.

\threattablebegin{Tampering}{tampering}{Tamper}
  T1 & Defensive user corrupts DSK, DID, or token
  & LE attempts at perform \ac{EA} will fail due to corrupt data. Requires compromise of the Secure Enclave or advanced
    hardware manipulation tools.
  & Since these values are known at manufacturing time and never change, they can be made read-only. (The symmetric key
    variant of \ldawmsr requires updating the symmetric equivalent of the public DSK, and is therefore more vulnerable
    to this threat.)
  \\ \hline
  T2 & Defensive user destroys the \ac{EA} hardware interface
  & LE attempts to perform \ac{EA} will fail due to damaged hardware.
  & Manufacture the device to require destructive disassembly to access the interface. This increases the cost
    associated with deploying and using the system.
  \\ \hline
  T3 & LE insider tampers with DID before digital signature
  & LEA receives an unauthorized device's unlock artifacts. Can be combined with other attacks to compromise a device.
  & Randomize DIDs to make them unguessable, meaning a target device must be in possession in order for the attacker to
    know what DID to use. Input to the vendor's \ac{HSM} could also include data from the legal documents, such as
    device S/N; the \ac{HSM} would append the S/N to the DID and hash the result, verifying a match with the same stored
    hash before returning the unlock artifacts.
  \\ \hline
  T4 & Attacker tampers with hardware transparency mechanism
  & The device user is unaware that the device was unlocked. Highly implementation dependent, but certainly requires
    advanced hardware manipulation tools.
  & Manufacture the device to require destructive disassembly to access the interface.
\threattableend

\subsection{Repudiation}

Repudiation threats are listed in \mytab{table-repudiation}.

\threattablebegin{Repudiation}{repudiation}{Repudiation}
  R1 & Attacker or authoritarian government repudiates unlock attempt
  & The user is unaware that someone tried to access their device.
  & Manufacture the device to require destructive disassembly to access the interface, or use the same hardware
    transparency mechanism to mark mere access attempts as well.
  \\ \hline
  R2 & Authoritarian government repudiates demanding vendor assistance
  & Governments not respecting the legal framework governing the system can bully the vendor and try to force access
    while maintaining deniability.
  & This is close to being an out of scope threat under the ``rule of law'' exception. However, one could design the
    system to require requests and responses to be recorded on a public ledger. This creates several new difficulties.
  \\ \hline
  R3 & LEA repudiates having unlocked a device
  & The device is undeniably unlocked, but the LEA claims it was not them, allowing possible violations of civil
    liberties and harming transparency.
  & At a high level, the system should require a long paper trail before access can be granted. At a low level, the
    escrow agent could require and store some identifying information before unlocking, such as the LEA's public key
    digitally signed by the vendor, which provides non-repudiation assuming independent access to the device. See also
    the mitigation in \ii{R2}.
  \\ \hline
  R4 & Vendor repudiates having responded to an access request
  & The device is undeniably unlocked, but the vendor claims they did not provide the unlock artifacts, allowing the
    vendor to cover up leaks or distasteful policy decisions by suggesting the device was instead hacked. Harms
    transparency.
  & Assuming independent access to the device, the hardware transparency mechanism should confirm whether the \ac{EA}
    process was used, and the same identifying information used in \ii{R3} would implicate the vendor. See also the
    mitigation in \ii{R2}.
\threattableend

\subsection{Information Disclosure}

Information disclosure threats are listed in \mytab{table-disclosure}. In addition to the threats listed here, all
attacks aimed at gaining unauthorized access to a device constitute information disclosure threats. Most spoofing
attacks are aimed at disclosing information intended for another party.

\threattablebegin{Information Disclosure}{disclosure}{Information \\ Disclosed}
  I1 & Attacker exposes the DSK, DID, the encrypted class key, or hashed token
  & By design, none of the information stored on the phone is sensitive. The most consequential information that could
    be stolen is the DID, which could be paired with other attacks. Disclosing the DID requires either disassembly and
    time vaulting or advanced hardware inspection tooling.
  & Sensitivity of this data has already been mitigated as much as possible.
  \\ \hline
  I2 & Attacker intercepts unlock artifacts between LEA \ac{HSM} and device
  & The attacker is able to unlock the target device alone. Must be combined with a spoofed DID to be of use to other
    devices (see \ii{S2}). The attacker could record the values to replay them after the phone has been returned.
  & See \ii{S2}. If choosing not to destroy the device, to prevent replay attacks, a new token could be generated and
    stored in the vendor HSM, with the new hash installed during the unlock process.
  \\ \hline
  I3 & Attacker steals the LEA private key
  & The attacker is now able to spoof the LEA and decrypt returned unlock artifacts. Without the devices (which are
    already in LE possession), the artifacts are not useful. See \ii{S4} and \ii{S5} for LEA spoofing attacks.
  & The key is stored in an \ac{HSM}, which has extensive security measures. See \ii{S5} for a revocation and update
    mitigation.
  \\ \hline
  I4 & Attacker steals the DID-DSK database
  & This is the big prize, the largest source of centralized risk. With the database, attackers could directly
    compromise any mobile device using this system in their possession, after disassembly, and after the time vault.
    They may also try to sell access to the data.
  & \ii{R3} defines a mitigation that requires use of a vendor private key to create a digital signature as part of the
    authentication process. If used, that key would have to be compromised as well for the database to be of use.
    However, if the database is compromised, that key probably is too. Savage argues that \acp{HSM}, though imperfect,
    actually do provide very strong assurance. Responses could be rate-limited, and leaking an entire database once it's
    in the \ac{HSM} could not go unnoticed. Getting the data in may be harder---see \ii{I5}.
  \\ \hline
  I5 & Attacker steals device unlock artifacts between manufacturing and vendor \ac{HSM}
  & Intercepting the unlock artifacts at the source achieves the same effect as \ii{I4}, only the data set is not
    complete. Instead of granting the ability to unlock any device, including a specific target, this is suited for
    getting access down the line or for sale.
  & The unlock artifacts generation process must be treated as sensitively as the \ac{HSM} itself. The artifacts should
    be encrypted immediately and periodically transported to the corporate \ac{HSM} on physical media. This threat is
    difficult to definitively mitigate.
  \\ \hline
  I6 & Attacker steals device \ac{plaintext} from LEA after unlock process
  & Assuming the attacker doesn't care that the LEA gets access to plaintext, they could ``help'' the LE investigation
    in order to access the data later either when it comes out as public evidence or through compromising the LEA
    itself. This may be useful to authoritarian regimes, foreign intelligence, and organized crime.
  & LEAs must have strong information security of their own. Disclosure of evidence is a natural side effect of
    prosecution, so LEAs must practice discretion in choosing which devices to unlock in case mere information discovery
    poses a great risk in itself.
\threattableend

\subsection{Denial of Service}

\Ac{DOS} threats are listed in \mytab{table-dos}. In addition to the threats listed, \ii{S4} can be used for \ac{DOS} by
surreptitiously invalidating a LEA's identity key, and \ii{T1} and \ii{T2} are tampering attacks designed to deny LEAs
from using the \ac{EA} mechanism.

\threattablebegin{Denial of Service}{dos}{Service Denied}
  D1 & Unlock artifacts recovery
  & \ii{S6} could be used to inject corrupt data to the DID-DSK database, potentially overwriting actual unlock artifact
    data.
  & Verify integrity of new data before entering it into the database, and disallow overwriting entirely.
\threattableend

\subsection{Elevation of Privilege}

Elevation of privilege are listed in \mytab{table-privilege}. Spoofing to usurp a entity's privilege or using any attack
to unlock a device without authorization can be seen as escalation of privilege.

\threattablebegin{Elevation of Privilege}{privilege}{Privilege Gained}
  E1 & Foreign intelligence or organized criminals recruit an insider
  & The primary attacker gains inside access through coercion or bribery, making any other attack easier.
  & Limit the employees, accounts, and computers involved in any element of the system. Perform background checks on
    each employee and maintain detailed logs.
  \\ \hline
  E2 & Unexposed hardware interface allows access to Secure Enclave
  & The attacker gains access to Secure Enclave operations and data, undermining the device and achieving unlock without
    following the \ac{EA} protocol.
  & The time vaulting protocol and all communication over the interface must be thoroughly tested, and if possible,
    formally proven to be logically sound. Analysis must include side channel attacks to affect the time vaulting or
    leak internal data.
  \\ \hline
  E3 & An \ac{HSM} vulnerability allows access to protected data
  & This is a technical route to achieving \ii{I4}, disclosure of the DID-DSK database.
  & The \ac{HSM} should be on an air-gapped network disconnected to the internet, physically guarded, and regularly
    patched. There is no defense against an unknown vulnerability, so security ultimately comes down to incident
    detection and response.
\threattableend


\section{Risk Analysis}

How much risk does \ldawmsr introduce? The answer lies in a range depending on how many mitigations are implemented.
Some threats introduce inherently low risk due to their difficult nature and low pay off. Others are higher risk but can
be reasonably mitigated. Some threats specifically target transparency, and are difficult to address without trust.
Finally, there are some risks that are irreducible. Each of classes are discussed in turn.

\ii{S6}, \ii{T1}, \ii{T3}, \ii{I1}, \ii{I3}, \ii{I6}, \ii{D1}, and \ii{E1} \ii{E2} are each low risk either because they
fail to produce useful results, they can be well mitigated, or they are a threat that is already present in
state-of-the-art designs as depicted in \mysec{sec-basic-dar}. It is crucial for a design to consider and mitigate the
risk posed by these threats as part of the design process, but they do not represent fatal flaws to a design. Except in
combination with other threats, they are not worthy more concern here.

\ii{S1}, \ii{S2}, \ii{S3}, \ii{S4}, \ii{S5}, \ii{T2}, \ii{T4}, \ii{R1}, and \ii{I2} are each higher risk threats to the
security, trustworthiness, and effectiveness of the proposal, but can be addressed through a set of related mitigations:
require destructive disassembly of the device to access the \ac{EA} hardware interface, require the device to be
physically present on LEA premises the entire duration it is unlocked, and grant only a handful of LE facilities the
lawful right to use the \ac{EA} mechanism. Requiring destructive disassembly is a technical measure that entirely
precludes certain attacks; requiring the device to be on LEA premises is a procedural measure that prevents attackers
from manipulating LE into achieving their own ends; limiting the number of LE facilities that can participate prevents
LE impersonation attacks. Together, they make the proposal considerably harder to attack.

\ii{R2}, \ii{R3}, and \ii{R4} are repudiation attacks that belie the system's potential for abuse. The system relies on
legal process and cooperation of several parties. But what if the legal process involves secret courts, secret
investigations, and secrecy orders on the vendor \cite{shamsi_2011}? Destructive disassembly or the weaker hardware
transparency mechanism provide non-repudiation that the device was unlocked, if and only if one has physical access to
the device. Technically enforced transparency into device access requests and responses would grant non-repudiation at a
broader level. \ldawmsr does not include a mechanism for the feature, though other \ac{DAR} \ac{EA} proposals do
\cite{phan_key_2017} \cite{servan_schreiber_jje_2020}. Unfortunately, building this feature into a proposal makes it
potentially vulnerable the hawkish lawmaker, who may consider it an anti-feature.

Finally, there are the threats of \ii{I4}, \ii{I5}, and \ii{E3}, each representing in slightly different ways the
disclosure of unlock artifact data, the DID-DSK database. This is the truly difficult challenge---centralizing so much
sensitive data makes it an extremely high value target for foreign intelligence and cyber criminals. The vendor is in a
position where they need to protect this database from the most advanced attackers in the world while regularly updating
and accessing it. \Acp{HSM} and strong security policies would make that a difficult task, but not impossible, and one
has to assume that the data would leak eventually. What would leaked unlock artifacts mean? It depends who steals it.
Criminals would use it for personal and financial gain; foreign intelligence and authoritarian regimes would use it to
spy on their enemies. In the worst-case scenario, anyone with some specialized tools and a willingness to break the law
could get into any device under the scheme, provided they destructively disassemble it and wait through the time vault.

It is important to give \ldawmsr (and similar \ac{DAR} \ac{EA} proposals) its due. The worst case scenario still
precludes mass surveillance and includes non-repudiation that access occurred. This is a significant gain for \ac{EA}
proposals in terms of transparency and protection of civil liberties.


\section{Achievement of Goals}

% Consider goals, threat actors, and loop-back to out of scope items, because they aaaaactually do matter.

% Economics: vastly increases costs and barrier to entry for vendors.




%%%%%%%%%%%%
% Old notes for reference
% -----------------------
% Chapter 4, threat models
% (how to be specific enough to be useful but generic enough to apply to many systems? Focus on the EA type (DAR v DIM),
%   then apply to specific systems)
% DAR, DIM threat models (make sure to cover abelson_2015)
% Basic proposals
%  --> mappings onto threat models
% At work: 3 example systems analyzed with this threat model
% 1. IM (E2E IM too?) -- in motion
% 2. Cloud storage -- at rest
% 3. Mobile phone -- at rest, but way different scenario than cloud
%  --> include Ozzie's CLEAR, since it was higher profile
%%%%%%%%%%%%
