\chapter{EA Debate Arguments}
\label{chap-arguments}

This chapter will analyze the \ac{encryption} debate using \acp{argmap}. The maps facilitate comprehension of the
debate, but there are two important shortcomings of the maps presented here. First, argument maps should be used simply
as tools in the collaborative pursuit of the problem definition and solution. It is not a replacement for debate arising
from live discussion. Second, \acp{argmap} may deceptively portray the strength of an argument. Argument nodes do not
indicate their strength or validity. If ten unsound arguments were presented against one indisputable argument, the side
with more arguments would, regardless of their integrity, appear stronger. With those qualifications in mind, let us
begin by examining the factors at the center of the conflict.


\section{Contributing Factors}
\label{sed-arg-contrib}

\myfig{fig-args-contrib} maps the central arguments in the EA debate. As previously stated, \ac{encryption}'s dual
contributions to information security and radical privacy are central to the debate. Of course, there is only conflict
when radical privacy is perceived as a negative. The right to privacy is both a strongly held value and an enshrined
legal principle. Many use privacy concerns to argue that \ac{EA} is socially undesirable. The Snowden revelations
\cite{landau_making_2013} unveiled the scale of privacy-eroding U.S. government surveillance enabled by technological
changes, terrorism-motivated policies, and weak oversight \cite{shamsi_2011}. Privacy violations are an abstract worry
to many, but for the most vulnerable, they are frighteningly concrete. For example, Saudi journalist Jamal Khashoggi's
fell
% TODO: bookmark

private communications were surveilled by the Saudi government before he became a victim of politically motivated murder
\cite{liebermann_2019}. At a societal level, the mere presence of surveillance changes behavior and chills free speech
\cite{rogaway_moral_2015}, and government violations of the law degrade institutional trust.

\begin{sidewaysfigure}
  \centering\CaptionFontSize
  \includegraphics[width=\linewidth]{arguments/build/comprehensive.contrib.pdf}
  \caption{Contributing Factors to the EA Debate}
  \label{fig-args-contrib}
\end{sidewaysfigure}

\Acl{LE} argues that encryption handcuffs its investigational capacity. The \ac{FBI} brands strong encryption as
``warrant-proof'' and states that ``the government often cannot obtain the electronic evidence necessary to investigate
and prosecute threats to public and national safety'' \cite{fbi_2020}. The pro-\ac{EA} argument is typically rooted in
public safety: encryption makes it too difficult for investigators to access the evidence needed to catch and convict
law-breakers. Five-eyes nations have regularly published joint statements expressing their frustration with encryption
\cite{ministerial_2018} \cite{goodale_2017}. They were joined in 2020 by India and Japan in a statement emphasizing the
growing danger of \ac{CSAM} \cite{intl_2020}. Child pornography is one of the original \ac{horsemen} used to scare
people into supporting backdoors \cite{schneier_scaring_2019}, but it is also a problem growing to astonishing
proportions. A 2019 investigation by the \textit{New York Times} quoted a law officer's estimate that 400,000 New
Jerseyans, more than 4\% of the state's population, have violated child exploitation material laws
\cite{keller_internet_2019}.

Unfortunately, these shocking claims have not been independently confirmed with hard data. Intelligence agencies have
historically misrepresented statistics and overstepped their bounds \cite{johnson_congressional_2004}
\cite{shamsi_2011}. This undercuts their claims that they need \ac{EA} and has diminished institutional trust. For
example, the \ac{FBI} has already been found to exaggerate the number of mobile devices it could not access due to
\acl{DE} \cite{devlin_2018}. As Rozenshtein points out, ``It is impossible to know the precise extent to which
encryption frustrates law-enforcement investigations, both because law-enforcement agencies are only beginning to
collect accurate statistics, and because one can never be sure of how an investigation would have proceeded in the
absence of encryption'' \cite{rozenshtein_wicked_2018}. However, it is still crucial to have an accurate depiction of
the problem in order to come to justified and helpful solutions. This argument is analyzed further in the next section.

Information security is the remaining central issue in the debate. As described in \mysec{sec-crypto-basics},
\ac{cryptography} plays a foundational role in nearly every aspect of security. Past \ac{EA} regulation efforts sought
to compromise the cryptographic foundations of encryption, though this is not a feature of proposals today, as that is
universally seen as too risky. \mysec{sec-tech-approaches} introduced several alternative technical approaches to
\ac{EA}, but experts still proclaim that the current state of the art is far from capable of providing the type of
access \acl{LE} in an acceptably secure manner \cite{abelson_2015} \cite{abelson_risks_1997}. Security was an
afterthought in early computing and networking designs, and the field of cybersecurity is still equal parts art and
science; mandated \ac{EA} would inevitably diminish security to some degree \cite{abelson_2015}.

Finally, it is arguable that \ac{EA} could have positive alternative applications. It could enable malware scanning,
password recovery, or administrator access in a business setting. Typically these applications have other solutions,
however, and to combine the requirements of these uses with those of any reasonable \ac{EA} proposal would likely
fatally weaken it.


\section{Going Dark vs. The Golden Age}

A significant portion of the disconnect between government and technical community representatives is disagreement over
whether law enforcement has \ii{too little} or \ii{too much} access to data. The argument for \ii{too little} is
well-represented by proponent former \ac{FBI} Director James Comey in his 2014 speech titled ``Going Dark''
\cite{comey_2014} (though he did not coin the phrase \cite{swire_encryption_2011}). The argument is presented in
\myfig{fig-arg-going-dark}.

\begin{figure}[t!]
  \centering\CaptionFontSize
  \includegraphics[width=\linewidth]{arguments/build/comprehensive.goingdark.pdf}
  \caption{A ``Going Dark'' Argument Map}
  \label{fig-arg-going-dark}
\end{figure}

According to the "Going Dark" argument, privacy and safety are both desirable goods, but they conflict with one another;
therefore, they must be balanced. Individuals must sacrifice some of their personal good of privacy to allow for the
public good of safety. Widespread encryption tips the scales too far towards privacy, upsetting the balance that existed
before. \ac{EA} restores the balance and enables law enforcement agencies to fulfill their duty to protect the public.

The ``Going Dark'' argument has a few shortcomings. It oversimplifies the relationship between privacy and safety by
depicting it as a zero-sum conflict. In reality, privacy does not always diminish safety, but sometimes enhances safety.
For example, data privacy makes crimes such as stalking and identify more difficult. The ``Going Dark'' argument also
categorizes privacy as a personal good and safety as a public good. However, privacy can also be a public good when it
precludes \ac{masssurv}. This argument is explored more deeply in the ``Golden Age for Surveillance'' map.

Most importantly, the ``Going Dark'' argument relies on the premise that law enforcement investigations fail due to
encryption. As described in \mysec{sed-arg-contrib}, there is no conclusive data regarding the extent to which
encryption is to blame for failed cases. One can certainly understand the argument, but the lack of evidence is an
issue. The highest-profile case of \ac{the-cw2}, Apple vs. FBI, ended when the \ac{FBI} broke into the phone and found
nothing of value. Tellingly, the examples cited in Comey's 2014 speech were not cases in which encryption inhibited
investigations, but were cases in which encryption \ii{could have} inhibited investigations, had it been a factor.
\cite{comey_2014}. More recently, a 2020 report titled ``Mass Extraction: The Widespread Power of U.S. Law Enforcement
to Search Mobile Phones'' revealed that law enforcement agencies currently have the upper hand on mobile device
encryption and are actually able to extract data from nearly every mobile phone on the market \cite{koepke_2020}.

Citing lack of evidence that encryption is stymieing cases only gets you so far, however. In most cases, it is
impossible to know what would have happened without the interference of strong encryption. Inability to gather data from
controlled tests is a characteristic of \acp{wicked-prob}. When controlled settings are unachievable, another way to
gather data is by observing naturally-occurring conditions in which everything but the variable of interest remain are
constant. These conditions exist for encryption in messaging application ecosystem. Messaging applications WhatsApp,
Facebook Messenger, and Telegram all have large user bases and similar features. Among these services, only Facebook
Messenger does not employ \ac{E2EE}. Globally, Facebook Messenger has approximately 20\% market share as measured by
active monthly users \cite{statista_2020} but accounts for 65\% of \ac{CSAM} reports \cite{keller_internet_2019}. This
indicates that encryption does indeed affect investigations.

% TODO: I still really want to use this!
% European law enforcement's infiltration of encrypted messaging service Encrochat exposed crime rings and led to a
% massive raids \cite{cox_2020}.

Aside from the challenge of encryption entirely, a 2018 study found that law enforcement's primary difficulties with
digital evidence were identifying service providers and getting the sought after data from them \cite{carter_2018}. This
is in the context of current legal frameworks and access capabilities. The report is fittingly titled ``Low-Hanging
Fruit,'' and also lists resource limitations and training needs among top priorities. Indeed, many current initiatives
are underfunded. Major anti-\ac{CSAM} legislation passed in 2008, but has been funded at only 50\% of authorized levels,
the Justice Department task force has produced only two of five biennial reports, and a senior executive position within
the Justice Department was never created \cite{keller_internet_2019}. Federal entities commissioned to improve
communication between law enforcement and industry as well as to train law enforcement on managing digital evidence are
similarly underfunded \cite{carter_2018}.

% Golden age

The argument for law enforcement having \ii{too much} access to data claims that law enforcement is not ``Going Dark'';
rather, they are experiencing the ``Golden Age for Surveillance'' \cite{swire_encryption_2011}. This argument posits
that although encryption makes certain data completely unaccessible, technological change on the whole has given
authorities much more digital evidence than encryption has taken away. Paired with the dangers of \ac{masssurv},
encryption is a necessary defense, and any \ac{EA} implementation would compromise encryption's protection. The argument
is mapped in \myfig{fig-arg-golden-age}.

\begin{figure}[p!]
  \centering\CaptionFontSize
  \includegraphics[width=\linewidth]{arguments/build/comprehensive.goldenage.pdf}
  \caption{A ``Golden Age for Surveillance'' Argument Map}
  \label{fig-arg-golden-age}
\end{figure}

The ``Golden Age'' argument focuses on surveillance, its undesirability, and technology's role in it. Cryptographer
Phillip Rogaway writes at length about the negative impacts of \ac{masssurv} in his essay ``The Moral Character of
Cryptographic Work'' \cite{rogaway_moral_2015}. Rogaway asserts that ``pervasive collection \ii{itself} chills
free-speech and threatens liberal democracy.'' He argues that surveillance is fundamentally a tool of power, and for
this reason it should be resisted. Though power from the people, created through representative political process, is
valid, clear abuses have undercut confidence in these institutions.

After establishing the danger of surveillance, the argument notes how technology has increased the government's
surveillance abilities. This can hardly be contested. Going back to Comey's ``Going Dark'' examples once more, each case
he cited was cracked by digital evidence that would not have been available even twenty years ago \cite{comey_2014}. In
response to the danger of \ac{masssurv} and the scale of modern surveillance capabilities, encryption is one of the only
privacy-saving tools. (Opting out may be possible for some, but is not a realistic option for society as a whole.)

While stronger than the ``Going Dark'' argument, the ``Golden Age for Surveillance'' argument suffers from a significant
flaw. It focuses on the abilities and dangers of agencies like the \ac{NSA} while ignoring the problems of
resource-strapped local, state, and federal law enforcement. It is obvious that the amount of digital evidence is
increasing. However, law enforcement already has trouble acquiring many forms of evidence with the help of tech and
communications companies, and does not have the funding or capability to get it on its own \cite{carter_2018}.
Exacerbating the situation is the ``tech effect,'' which refers to jurors' increased expectations of hard evidence in cases
where it may be suspected to exist \cite{shelton_study_2006}.

Still, law enforcement's inability to access the tools of \ac{masssurv} cannot be taken for granted. It will likely
change---they already have access to mobile devices. A more conservative criticism of the ``Golden Age'' argument rests
in the fact that \ac{EA} without \ac{masssurv} is conceivable. \ac{EA} implementations that enable law enforcement but
thwart \ac{masssurv} by remote powers subvert most of the ``Golden Age'' argument. \ac{EA} proposals that strive for
these properties will be explored in \mysec{sec-ea-types}.


\section{Eliminating Fallacious Arguments}

Using \acp{argmap} to analyze debates allows for consideration of opposing arguments. Part of that consideration
includes identifying and eliminating fallacious arguments. In heated partisan debates, fallacious arguments spread
easily. \myfig{fig-arg-fallacies} shows those most commonly used in the encryption and \ac{EA} debate.

\begin{figure}[t!]
  \centering\CaptionFontSize
  \includegraphics[width=\linewidth]{arguments/build/comprehensive.fallacies.pdf}
  \caption{Fallacious Arguments of the EA Debate}
  \label{fig-arg-fallacies}
\end{figure}

The map begins with fallacious arguments used to attack \ac{EA}. The first is the most common: ``\ac{EA} is a bad idea
because backdoors are insecure.'' It appears on the map as a straw man argument due to the way the term ``backdoor'' is
used. ``Backdoor'' is essentially technical shorthand for ``insecure hack that should never be used in production'';
when it is used as a basket term for all \ac{EA} proposals, the audience is primed to consider them all ill-conceived
and hopelessly dangerous. Thus, the arguer is presenting their opponent's argument for any degree of \ac{EA} in the
weakest possible fashion.

Another common argument is that implementing \ac{EA}---or even researching it---inexorably moves tech policy down a
slippery slope, in which government demands will never be satisfied. This argument can be used to prevent research by
those who think judicious use of \ac{EA} tools could be positive. Going too far and too fast is certainly dangerous, but
it is both cynical and misleading to declare the permanent destruction of privacy as the inevitable end of \ac{EA}
research.

It is tempting to declare government requests for \ac{EA} disingenuous due to their hypocritical behavior towards some
of these issues. For example, if combatting \ac{CSAM} is a government priority, why has Congress underfunded the laws
it's passed, and why has the Justice Department understaffed their its task force \cite{keller_internet_2019}? These
questions demand answers, but they do not change the validity (or invalidity) of pro-\ac{EA} arguments. The absence of
government funding does not mean technical anti-\ac{CSAM} measures are unnecessary.

The final two anti-\ac{EA} fallacies are examples of false dichotomies; they present the situation as if there are only
two options. \Acp{wicked-prob} have unlimited sets of potential responses, so reducing them to two is misleading. One
false dichotomy is that the only acceptable solutions are either perfect \ac{EA} or no \ac{EA}. This leaves no room for
risk-based approaches, the typical security strategy outside the realm of cryptography. Another false dichotomy is that
regulators must either allow strong cryptography or we will live in a \ac{masssurv} dystopia. This one carries hints of
``slippery slope'' and appeal to emotion as well, framed as a choice between only two futures. Framing the situation in
all or nothing terms reduces the chance of a successful collaborative debate.

Some arguments used to support \ac{EA} rely on appeal to emotion. Politicians and law enforcement agents often appeal to
pity for child abuse victims or fear of terrorists, drug dealers, and kidnappers to make their point. Public safety is a
central issue in the debate. The technical community does take these concerns seriously \cite{schneier_scaring_2019}.
These appeals become fallacious when they are used to manipulate the audience into supporting solutions incommensurate
with the problems or to manipulate the audience into believing that the technical community does not care about these
issues.

Another argument used to subvert anti-EA arguments from experts goes along the lines of, since we put a man on the moon,
we can surely create secure \ac{EA} \cite{cushing_moon_2018}. This is a weak analogy. The only similarity between the
challenge of landing an astronaut on the moon and the challenge of building a cryptosystem with secure EA is that they
are difficult. Once the political commitment was made, the Apollo program solved mostly tame problems and had enormous
government backing. Resolving the encryption debate has neither of these advantages. Many similar arguments comparing
\ac{EA} to other feats of technological progress suffer the same faults.

Lastly, government officials often portray \ac{EA} as a problem that security experts simply have not researched enough.
If experts just ``nerd harder,'' as some put it, they can find a solution \cite{schneier_2019}. This misses the point of
research done up to this point. Encryption and \ac{EA} is a \ac{wicked-prob} for which tame, technical-only solutions
will not work \cite{rozenshtein_wicked_2018}. Even on the technical side, experts have stated time and again that,
depending how you look at it, the technical problem is solved---\ac{EA} is easy from a purely cryptographic point of
view. The hard part is the security of the interfaces with the human users and administers of the system
\cite{abelson_risks_1997} \cite{abelson_2015}. This may not be an area of strong academic research, but to frame that
as the primary roadblock to progress utterly misses the point.


\section{EA and Alternatives}

Moving on from problem framing and meritless arguments, we next turn to actions that can be taken in response to the
situation. \myfig{fig-arg-measures} divides potential solutions into the categories of current capabilities, legal
measures, and \ac{EA}. Current capabilities can be implemented today, and include maintenance of the status quo and
increasing investment in current programs. Legal measures require a change in the text or application of the law, but do
not require fundamentally new technical capabilities. These include compelling passwords, which requires legal
clarification, and sanctioning lawful hacking, which requires a strategic pivot and an oversight framework. (These
non-\ac{EA} approaches were first introduced in \mysec{sec-alt-approaches}.) At this level, \ac{EA} is analyzed in
general. Specific EA approaches are addressed in the next map.

\begin{sidewaysfigure}
  \centering\CaptionFontSize
  \includegraphics[width=\linewidth]{arguments/build/comprehensive.measures.pdf}
  \caption{EA and its Alternatives}
  \label{fig-arg-measures}
\end{sidewaysfigure}

Each measure is considered according to five metrics. These metrics represent a generalization of metrics from several
sources, including two separate diverse committees gathered to analyze the encryption debate
\cite{committee_decrypting_2018} \cite{group_2019} \cite{varia_2018}. They also align closely to the four central issues
of security, safety, privacy, and trust. The five metrics used to analyze response measures are (1) minimization of
increased security risk, (2) utility to law enforcement, (3) protection of civil liberties---particularly important as
after the analysis of the ``Golden Age for Surveillance'' argument---(4) transparency, and (5) economic impact. Economic
impact is not as central an issue as the others, but it does help determine practical viability of a proposal.

Beginning with current capabilities, the first choice is to do nothing. Some may conclude that the current state of
affairs actually does represent an acceptable balance of interests. If technology and government agree on this approach,
then \ac{the-cw2} can end much like the first. However, legislative action itself is a risk to be mitigated. If the
technical community ``decides'' on this approach and government continues to reject it, we could be forced in an
undesirable direction.

We could also decide to increase investment in current technologies and investigative techniques. As previously
discussed, encryption is not the most significant barrier in law enforcement's use of digital evidence
\cite{carter_2018}. Even when encryption is involved, traditional sleuthing can often lead to access. Security expert
Bruce Schneier and cyberlaw expert Orin Kerr have compiled a list of ``encryption workarounds'' that do not rely on
\ac{EA}. These include finding the key, guessing the key, accessing plaintext while the device is in use, and finding
another copy of the plaintext \cite{kerr_encryption_2017}. Though probabilistic and time-consuming in comparison to
\ac{EA}, these methods do not require new legal or technical capability. These methods are effective
\cite{greenberg_2018}; investment in current digital evidence capabilities and anti-\ac{CSAM} task forces, they are also
safe.

Compelled password disclosure is a potential solution that simply requires defendants to surrender passwords and
\acp{PIN} to their devices. Questions regarding the legality of this approach have been working their way through the
courts \cite{bittenbender_2019} \cite{sobel_2019} because of the apparent conflict with the Fifth Amendment right
against self-incrimination. Even so, affordability is the strongest argument in its favor. Schneier and Kerr point out
that this approach requires the password-holder to be available to investigators, the prosecution has to overcome
several legal hurdles even if the basic approach is ruled Constitutionally legal, and even then the defendant may choose
to withhold the password and be held in contempt rather than be charged for crime evidenced by the plaintext
\cite{kerr_encryption_2017}.

\Ac{lawful-hacking} is the most prominent proposed alternative to \ac{EA} \cite{bellovin_lawful_2013}
\cite{hennessey_lawful_2016} \cite{rozenshtein_wicked_2018} \cite{kerr_encryption_2017} \cite{soesanto_2018}.
\Ac{lawful-hacking}'s support may be due in part to the fact that it is a technical approach that isn't \ac{EA} itself.
However, its effectiveness against criminals for whom \ac{EA} would not work is its obvious benefit. This is because,
while organized crime and terror groups would still use encryption tools to evade an \ac{EA} scheme, their operational
security would fail at some point, letting law enforcement or intelligence agencies into their networks and devices.
This approach is already in use \cite{cox_2020}, most famously to bring down cartel kingpin El Chapo
\cite{feuer_chapo_2019}.

The real change that \ac{lawful-hacking} would take would be a sanctioning and formalization of this strategy.
% TODO: tie to paragraph above?

Despite its strengths \ac{lawful-hacking} is a sub-optimal compromise. Because it requires time and specialized skills,
it is not useful for small departments and commonplace crimes. It would also alter the relationship between law
enforcement and tech companies. Law enforcement agencies would be forced into competition with tech companies if they
were incentivized to conceal the vulnerabilities they discover. Prominent proposals suggest mandating disclosure of
discovered vulnerabilities to mitigate this issue \cite{bellovin_lawful_2013} \cite{hennessey_lawful_2016}.
Theoretically, there are enough vulnerabilities that, even though these discovered vulnerabilities would be disclosed and
patched, new ones could be found quickly enough to enable steady levels of access. Government could source these
vulnerabilities from a combination of the public domain, the commercial exploit market, and a central ``Vulnerability
Lab'' \cite{bellovin_lawful_2013}.

The availability and cost of exploits fluctuates. For example, in January 2019, an Apple iOS jailbreak bug was valued at
\$2 million on the exploit market \cite{goodin_zeroday_2019}. In contrast, a 2020 report revealed that cracking mobile
devices cost law enforcement a mere \$2000 per unit \cite{koepke_2020}. As the exploit arms race continues,
exploitability will be inconsistent. If law enforcement relies on \ac{lawful-hacking} as its strategy, it would face
periods where it struggles for access, and would need to develop costly exploits in the lab. Mandatory vulnerability
disclosure is necessary to avoid competition between law enforcement and tech companies. However, based on the
\ac{FBI}'s historical abuses of power \cite{shamsi_2011} and Congress's reluctance to fund initiatives it has passed
\cite{keller_internet_2019} and failure to provide strong oversight \cite{johnson_congressional_2004}, it seems unlikely
that government would readily forfeit expensive vulnerabilities.

The final proposal is \ac{EA} itself. \ac{EA} would provide a standardized method for law enforcement to reliably access
\ac{plaintext}. It could serve as a compliment to \ac{lawful-hacking}by eliminating the incentive to conceal
vulnerabilities because it would be unnecessary for \ac{EA}-compliant systems, which would presumably include mainstream
technology. In that situation, \ac{EA} would combat common crime and \ac{lawful-hacking} would combat organized crime
and terror groups. While \ac{EA}'s impact on civil liberties and \ac{masssurv} would depend on its implementation, any
proposal would be costly to introduce and would threaten U.S. product competitiveness due to perceived insecurity. Risk
to security is the largest weakness of \ac{EA}. Any proposal must overcome significant challenges to minimize risk. The
next map analyzes this more closely.


\section{Zooming in on EA}
\label{sec-ea-types}

\myfig{fig-arg-classes} lists several classes of \ac{EA} and arguments in their favor and disfavor. The \ac{EA} classes
applicable to both \ac{DIM} and \ac{DAR} include weak cryptography, trusted-party key escrow, and distributed key
escrow. Using cryptographic puzzles and adding a ghost user apply to the case of \ac{DIM}, and device key escrow applies
to \ac{DAR}.

\begin{sidewaysfigure}[p!]
  \centering\CaptionFontSize
  \includegraphics[width=\linewidth]{arguments/build/comprehensive.classes.pdf}
  \caption{Classes of EA}
  \label{fig-arg-classes}
\end{sidewaysfigure}

% TODO: move this up? Applies to previous map as well.
It should be noted that the \ac{argmap} format works best when it displays the debate surrounding just one conclusion or
proposal. This allows adequate room for elaboration on points and counterpoints. When a map includes multiple
conclusions or proposals, it becomes a tangled web of connections, leaving no room for additional detail. For the sake
of brevity, this thesis compares several \ac{EA} variations in a single map. For an thorough discussion of \ac{EA}'s
alternatives and variations, see the National Academies of Sciences, Engineering, and Medicine's 2018 report titled
\ii{Decrypting the Encryption Debate: A Framework for Decision Makers} \cite{committee_decrypting_2018}.

The first \ac{EA} class is to simply use weak cryptographic ciphers or short encryption keys. This was the approach
taken before \ac{the-cw1}, when strong cryptography was not readily available and subjected to export controls. No party
seriously supports this approach today, as it contradicts security on many levels.

Trusted-party key escrow relies on an entity or a small group of entities to store a key or key recovery information.
There are a wide variety of implementations \cite{denning_taxonomy_1996}. This class of \ac{EA} has a crushing weakness:
it centralizes extremely sensitive information. Some argue software companies are capable of protecting such sensitive
data, citing their current practice of storing code-signing keys in hardware security modules \cite{ozzie_2018}.
However, others point out that such keys are quite rarely used (especially when compared to the likely frequency of
\ac{EA} requests), and yet they still leak \cite{green_2018}. Once the escrowed keys were stolen, as they inevitably
would be, every device or message encrypted with them would be at risk. This is an example of a case when the
\ac{argmap} format doesn't do an argument justice---the argument against any centralized access mechanism is extremely
powerful.

Distributed key escrow differs from trusted-party in that it takes strong steps to remove centralized trust. This is
achieved by using distributed systems to make key extraction difficult and publicly observable \cite{phan_key_2017}
\cite{servan_schreiber_jje_2020}. One advantage of distribution is that this approach is that it is more likely to fail
by making data unrecoverable than by making unintended data vulnerable, though more research into this area is needed.
Unfortunately, these systems would likely be costly to deploy and difficult to update due to their complexity.

One class of \ac{DIM} \ac{EA} involves using strong cryptography, but including cryptographic puzzle pieces as message
metadata. These pieces are designed to reveal the encryption key after the surveiller spends considerable computational
power \cite{bellare_translucent_1996} \cite{wright_crypto_2018}. This approach precludes mass surveillance, but it also
enables arbitrary surveillance by anyone with enough computing power. Using this class of \ac{DIM} \ac{EA} in common
cases would be impractical due to its high cost. However, it would be less effective in high-profile cases due to the
ability of sophisticated adversaries to employ \ac{EA} workarounds. Additionally, the calibration of puzzle difficulty
is dependent on the state of computing. Since opponents can record data and decrypt it later when computational
capabilities have changed, the data becomes steadily less secure over time.

Another \ac{DIM} proposal is to ``conference call'' authorities in as ghost participants in the conversation. This was
notably suggested by \ac{GCHQ} officials Ian Levy and Crispin Robinson \cite{levy_robinson_2018}. Their writeup begins
with some core ideas of this thesis:

\begin{displayquote}
In any discussion of cyber security, details matter.

Unfortunately, it's the details that are missing from the discussion around lawful access to commodity end-to-end
encrypted services and devices (often called the ``going dark'' problem). Without details, the problem is debated as a
purely academic abstraction concerning security, liberty, and the role of government.

There is a better way that doesnâ€™t involve, on one side, various governments, and on the other side lawyers,
philosophers, and vendors' PR departments continuing to shout at each other. If we can get all parties to look at some
actual detail, some practices and proposals---without asking anyone to compromise on things they fundamentally believe
in---we might get somewhere.
\cite{levy_robinson_2018}
\end{displayquote}

Although this proposal was raised with good intentions, it is nevertheless problematic. The ghost user proposal prides
itself on not compromising strong encryption. Although this is a good property, compromising a messaging app's
authorization protocol is as dangerous as compromising its encryption \cite{callas_1_2019}. Fundamentally, this proposal
suffers from the same weakness as trusted-party key escrow---it introduces an authorization vulnerability in the
messaging service provider's platform, resulting in dangerous centralized access capability \cite{schneier_ghost_2019}.
It has the same nature, if a different form, as rejected key escrow proposals.

Finally, one \ac{DAR}-specific \ac{EA} class is device key escrow. In this scheme, key recovery material exists on the
device itself. While not necessary to classify as device key escrow, most of these proposals include physical possession
requirements and additionally ``brick'' the device or make it absolutely clear that \ac{EA} has been performed
\cite{savage_lawful_2018} \cite{ozzie_2018}. Such features preclude \ac{masssurv} and ensure transparency to the device
user. This approach relies on secure hardware and a method of authorizing the recovery request to the device itself. The
authentication step can be paired with other \ac{EA} strategies, such as engaging with trusted-parties or distributed
systems. This is where the weakness of the device escrow is revealed. Secure hardware enclaves, though improving, are
not totally reliable. Therefore, authentication to the hardware device is susceptible to the same attacks as traditional
escrow \ac{EA}.

Device key escrow's greatest weaknesses, however, are still signs of progress. It is true that it relies on a device's
secure enclave, but devices already do---it is the same hardware device that manages device unlock and encryption
functionality in the first place. Additional functionality increases the attack surface, but it does not add a
completely new threat vector. It is also true that the process is subject to the same problems as traditional key escrow
after the device has been obtained, but that is precisely the progress that has been made---\ii{after the device has
been obtained}. Advances in secure hardware design have meaningfully changed the \ac{EA} risk profile.

In 2019, Carnegie Mellon assembled an ideologically diverse group of policy and security experts to engage in the kind
of cross-disciplinary research. After describing every technical branch of the situation, their report goes into detail
on why \ac{EA} for domestic law enforcement (i.e., common cases instead of sophisticated adversaries) focusing on
\ac{DAR} in mobile phones using device key escrow requiring physical access is the most tractable technical niche to
consider \cite{group_2019}. By now it should be clear why: traditional investigation mixed with a dose of lawful hacking
is best suited for advanced opponents, and device key escrow represents actual progress as a path towards lower-risk
\ac{EA} for typical cases.

A strong argument against device key escrow is that device encryption, particularly in mobile phones, may actually pose
the smallest impediment to investigation of any encryption technology. The previously cited report into law enforcement
agencies' ability to access mobile phones clearly demonstrates the current state of affairs: device manufacturers are
losing the exploit arms race, private companies are commodifying the \ac{lawful-hacking} approach for agencies large and
small, and the lack of regulatory strategy has led to pervasive data collection with little oversight
\cite{koepke_2020}. This fact does not undermine the worthiness of research into device-oriented \ac{EA}. First of all,
it underscores the lessons of \mychap{chap-policy}---inaction is an action when facing \acp{wicked-prob}, and in this
case, inaction has led to an undesirable position. Second of all, the current circumstances where device manufacturers
can't keep attackers out is temporary; when law enforcement faces real difficulty again, this issue will immediately
resurface. Law enforcement's anticipation of this is likely why they continue to push for \ac{EA} in spite of present
circumstances. Third of all, regardless of criminal abuse, formalized capability and process can reduce governmental
abuse, which is the clearer threat to privacy and civil liberties.

Despite device key escrow's tractability as a technical niche of \ac{EA}, it still has a long way to go. There are few
proposals, what few there are high level, and questions of scaling and administration have not been addressed. However,
as \ac{incrementalism}'s Lindblom and even \ac{GCHQ}'s Levy and Robinson have pointed out, focusing on specific
proposals has the opportunity to identify mutually agreeable solutions---or at least refine the problem understanding
enough that the next round of debate can be better informed.

It is this task that we turn to next. The following chapter analyzes one particular device-escrow proposal in detail,
Stefan Savage's ``Lawful Device Access without Mass Surveillance Risk: A Technical Design Discussion''
\cite{savage_lawful_2018}.
