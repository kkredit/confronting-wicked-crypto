===
title: >
    Security, Safety, Privacy, and Trust
subTitle: Arguments Regarding Encryption and Exceptional Access
author: Kevin Kredit
date: August 2, 2020
color:
    colorScheme: colorbrewer-category9
    tagColors:
        pro-ea: 0
        anti-ea: 1
        neutral: 7
        fact: 5
        fallacy: 5
        fallacious: 6
        value: 2
        action: 8
dot:
    measureLineWidth: true
    group:
        lineWidth: 125
    argument:
        lineWidth: 125
        minWidth: 0
    statement:
        lineWidth: 125
        minWidth: 0
model:
    removeTagsFromText: true
mode: strict

## Preview configs start

## Contributing Factors
#group:
#    groupDepth: 3
#selection:
#    selectedSections:
#        - Central Issues
#        - Exceptional Access
#        - Response Measures
#        - Arguments for Exceptional Access

## Going Dark
#group:
#    groupDepth: 3
#selection:
#    selectedSections:
#        - Exceptional Access
#        - Central Issues
#        - Going Dark Conclusions
#        - Going Dark Argument
#        - Going Dark Non Core

## Golden Age
#group:
#    groupDepth: 3
#selection:
#    selectedSections:
#        - Exceptional Access
#        - Central Issues
#        - Going Dark Conclusions
#        - Golden Age Argument
#        - Golden Age Non Core

## Fallacies
#dot:
#    graphVizSettings:
#        rankdir: LR
#selection:
#    selectedSections:
#        - Exceptional Access
#        - Fallacies
#        - Fallacious Arguments

## Response Measures
#group:
#    groupDepth: 3
#selection:
#    selectedSections:
#        - Response Measures
#        - Exceptional Access
#        - Current Capabilities
#        - Legal Measures
#        - Central Issues
#        - Arguments for Measures

## Types of EA
#group:
#    groupDepth: 3
#selection:
#    selectedSections:
#        - Central Issues
#        - Exceptional Access
#        - DAR EA Classes
#        - DIM EA Classes
#        - Arguments for EA Types

## EA Proposals
#group:
#    groupDepth: 3
#selection:
#    selectedSections:
#        - Central Issues
#        - Exceptional Access
#        - DAR EA Proposals
#        - DIM EA Proposals
#        - Arguments for EA Proposals

## Preview configs end
===

/**
 * Comprehensive set of arguments in the problem space of security, safety, privacy, and trust, in which EA is a
 * proposed measure.
 *
 * Possible ways to group statements:
 *  - central issues -- the root problems
 *  - desireable outcomes?
 *  - measures? (and sub-measures, like types of EA)
 */

# Central Issues

[Information Security]: Information security is critical for modern digital infrastructure. #core

[Public Safety]: The ability to investigate, interrupt, and litigate wrongdoing is central to law enforcement's
mandate. #core

[Data Privacy]: Individuals in a free society have the right to a reasonable expectation of privacy. #core

[Institutional Trust]: Governments and corporations have an obligation to honor their citizens' and customers'
trust. #core

# Response Measures

<!-- [Unregulated use of Encryption]: Let technological progress proceed as it will. #anti-ea
    <+ [Information Security]
    >< [Exceptional Access] -->

## Current Capabilities

[Do Nothing]: Conclude that the status quo is, indeed, okay. #action

[Increase Investment]: Invest in traditional investigative techniques. #action
<!-- From kerr_encryption_2017: find the key, guess the key, access plaintext while device in use, find another copy -->

## Legal Measures

[Forced Password Disclosure]: Establish legal authority to compel password disclosure. #action
<!-- From kerr_encryption_2017: compel the key -->

[Lawful Hacking]: Establish legal authority for law enforcement to offensively hack access to data. #action
<!-- From kerr_encryption_2017: exploit a technical flaw (possibly through vendor) -->

## Exceptional Access

[Exceptional Access]: Broadly deploy cryptosystems with some form of exceptional access. #action

[EA is bad]: Opposite of @[Exceptional Access] {isInMap: false}
    >< [Exceptional Access]

<!-- [Cryptographic EA]: Exceptional access achieved through altering cryptographic protocols. #action

[System Design EA]: Exceptional access achieved through system implementation. #action -->

### DAR EA Classes
<!-- See group_2019 -->

[EA DAR type1] #ea-proposal #action #dar

### DAR EA Proposals
<!-- See denning_taxonomy_1996 -->

[EA DAR prop1] #ea-proposal #action #dar

### DIM EA Classes

[EA DIM type1] #ea-proposal #action #dim

### DIM EA Proposals
<!-- See denning_taxonomy_1996 -->

[EA DIM prop1] #ea-proposal #action #dim

# Arguments for Exceptional Access {isGroup: false}

<Argument from Law Enforcement Need>: Law enforcement needs exceptional access tools to effectively investigate and try
crimes. #pro-ea

(1) Encryption hides evidence of wrongdoing.
(2) Law enforcement requires probable cause to obtain warrants and pursue investigations.
(3) Prosecutors require sufficient evidence to make convictions.
----
(4) Encryption hampers investigations and prosecutions.
    <_ [Institutional Trust]
(5) [Public Safety]
(6) EA remediates encryption's ability to hide wrongdoing.
----
(7) [Exceptional Access]

<Argument from Foreign Intelligence Need>: Intelligence agencies need exceptional access tools to effectively
investigate and prevent statecraft and terrorism. #pro-ea
    +> [Exceptional Access]
    +> [Lawful Hacking]
    <+ [Public Safety]
    <_ [Institutional Trust]

<Argument from Information Security>: Acceptably secure exceptional access is not technically feasible. #anti-ea
    -> [Exceptional Access]
    -> [Lawful Hacking]
    <+ [Information Security]

<Argument from Other Uses>: Exceptional access has positive auxiliary use cases. #pro-ea

(1) EA can be used for malware scanning.
(2) EA can be used for password recovery.
(3) EA can be used for administrator access.
----
(4) EA has positive auxiliary use cases.
    <!-- <_ <Better Ways>: There are other, better ways of fulfilling these use cases. #neutral -->
----
(5) [Exceptional Access]

[Absolute Right to Privacy]: Individuals in a free society have an absolute right to privacy. #value #anti-ea

<Right to Privacy is not Absolute>: An individual's right to privacy is contextual. One's words and actions are subject
to investigation depending on their context and likelihood that they constitute a violation of law. #pro-ea
    -> [Absolute Right to Privacy]

<Argument from Social Desirability>: Exceptional access is not socially desirable. #anti-ea

(1) [Absolute Right to Privacy]
(2) [Institutional Trust]
(3) [Data Privacy]
(4) EA inappropriately shifts power away from citizens and toward the government.
----
(5) [EA is bad]

# Going Dark Conclusions

["Going Dark" Conclusion]: Law enforcement is "Going Dark" due to evidence-hiding encryption. EA is needed to restore
the balance between privacy and safety. #pro-ea  {rank: 'conclusions'}
    +> [Exceptional Access]

["Golden Age" Conclusion]: Technology is enabling a "Golden Age for Surveillance" for which encryption is the strongest
defense. EA would compromise this goal. #anti-ea {rank: 'conclusions'}
    -> [Exceptional Access]
    >< ["Going Dark" Conclusion]

# Going Dark Argument

<"Going Dark" Argument>: Personal privacy and public safety inherently conflict--we need balance. Encryption has upset
this balance, and gives bad actors too much cover. #pro-ea

(1) [Privacy a Personal Good]: Privacy is personal good. It's about protecting your personal data. #neutral
    <+ [Data Privacy]
(2) [Safety a Public Good]: Safety is a public good. It's about living without fear of bad things happening. #neutral
    <+ [Public Safety]
----
(3) [Privacy and Safety in Conflict]: Personal privacy and public safety inherently conflict. We need
    balance. #neutral {isInMap: false}
(4) [Encryption at Fault for Investigatory Failure]: Encryption's strong data protection is enabling bad actors to
    evade detection. #neutral
----
(5) [The Balance is Upset]: Increased privacy is damaging safety, and encryption gives bad actors too much
    cover. #neutral
----
(6) ["Going Dark" Conclusion]

# Going Dark Non Core {isGroup: false}

<Privacy also a Public Good>: Through its role as a defense against mass surveillance, privacy is not only a private
good. #neutral
    <+ [Mass Surveillance Contradicts Privacy]
    _> [Privacy a Personal Good]

<Safety and Privacy not Zero-Sum>: Certain threats to safety directly involve privacy. Increases to privacy increases
safety against those threats. #neutral
    <+ [Data Privacy]
    <+ [Public Safety]
    _> <"Going Dark" Argument>
    <!-- _> [Privacy and Safety in Conflict] -->

<Encryption Not Primary Cause>: Encryption is neither the only nor the most common source of
difficulty. #neutral
    _> [Encryption at Fault for Investigatory Failure]

(1) [Work is Underfunded]: Justice Department positions combating CSAM, for example, are underfunded by Congress and
    underrespected in the Department. #neutral
(2) [Poor Cooperation]: Law enforcement cites identifying and receiving data from service providers as the greatest
    difficulty in accessing digital evidence. #neutral
(3) [Uncertain what Plaintext Holds]: It is uncertain that decrypted data will hold useful evidence. #neutral
----
(4) [Encryption Not the Root Problem] {isInMap: false}

# Golden Age Argument

<"Golden Age" Argument>: Technology-enabled surveillance has emerged as a severe threat. Encryption must be encouraged
    as a desperately needed defense. #anti-ea

(1) [Mass Surveillance Highly Negative]: Mass surveillance violates liberal values. #neutral
(2) [Technology a Boon to Surveillance]: Technology as a whole has enabled unprecedented levels of
    surveillance. #neutral
(3) [Encryption Mitigates Surveillance]: The data protection offered by encryption limits surveillance
    effectiveness. #neutral
----
(4) ["Golden Age" Conclusion]

# Golden Age Non Core {isGroup: false}

<Argument Against Mass Surveillance>: Surveillance is a dangerous tool. Any use must include oversight, and mass
application violates liberal values. #neutral

(1) [Surveillance a Tool of Power]: Power that comes from the people is not bad, but violations and weak oversight have
    diminished trust. #neutral
    <+ [Institutional Trust]
(2) [Surveillance Has Negative Side Effects]: Such as chilling free speech and precluding reform. #neutral
(3) [Mass Surveillance Contradicts Privacy]: Privacy and mass surveillance are mutually exclusive. #neutral
    <+ [Data Privacy]
----
(4) [Mass Surveillance Highly Negative]

<EA Without Mass Surveillance>: EA can be conceived in manners that also preclude mass
    surveillance. #neutral
    _> ["Golden Age" Conclusion]

<Assumes Law Enforcement Has Access>: The data exists, but law enforcement already has trouble accessing it even
via traditional means. #neutral
    _> [Technology a Boon to Surveillance]

# Fallacies

[Hasty Generalization]

[Missing the Point]: The premises of the argument support a conclusion, but not the conclusion drawn. #fallacy

[Post Hoc]

[Slippery Slope]: Arguing that a single step in one direction will inevitably result in sliding all the way to the
extreme. #fallacy

[Weak Analogy]: Arguing by comparison to something that is unalike in relevant aspects. #fallacy

[Appeal to Authority]: Using name recognition of figures that agree with the conclusion as an argument in
itself. #fallacy

[Ad Populum (Bandwagon)]: Using the supposed majority support for the conclusion by some group as an argument in
itself. #fallacy

[Ad Hominem]: Stating that an argument is invalid because the arguer has poor character. #fallacy

[Tu Quoque (Hypocrisy)]: Stating that an argument is invalid because the arguer has hypocritically acted against their
own argument. #fallacy

[Appeal to Emotion]: Attempting to convince the audience by making them feel pity, anger, or fear. #fallacy

[Appeal to Ignorance]: Citing a lack of evidence as support of a positive claim about the truth of a
conclusion. #fallacy

[Straw Man]: Setting up a weak version of the opposing argument in order to tear it down. #fallacy

[Red Herring]

[False Dichotomy]: Presenting a situation as if there are only two choices. #fallacy

[Begging the Question]

[Equivocation]

# Fallacious Arguments {isGroup: false}

<EA is a bad idea because backdoors are insecure> #fallacious #anti-ea
    -> [Exceptional Access]
    <_ [Straw Man]

<!-- <We should not implement EA because security experts are against it> #fallacious #anti-ea
    -> [Exceptional Access]
    <_ [Appeal to Authority] -->

<!-- <We should not implement EA because a majority of the public is against it> #fallacious #anti-ea
    -> [Exceptional Access]
    <_ [Ad Populum (Bandwagon)] -->
<!-- Citation: hanna_2019 -->

<The technical community cannot give any ground on EA because the government will never be satisfied> #fallacious #anti-ea
    -> [Exceptional Access]
    <_ [Slippery Slope]

<Government calls for EA on the basis of CSAM are disingenuous> #fallacious #anti-ea
    -> [Exceptional Access]
    <_ [Tu Quoque (Hypocrisy)]

<The only acceptable choices are no EA and perfect EA, but perfect EA is impossible> #fallacious #anti-ea
    -> [Exceptional Access]
    <_ [False Dichotomy]

<We either have strong encryption or a mass surveillance dystopia> #fallacious #anti-ea
    -> [Exceptional Access]
    <_ [False Dichotomy]

<We need EA now because victims of CSAM are suffering> #fallacious #pro-ea
    +> [Exceptional Access]
    <_ [Appeal to Emotion]

<Without EA we will be victims to terrorists, pedophiles, drug dealers, and kidnappers> #fallacious #pro-ea
    +> [Exceptional Access]
    <_ [Appeal to Emotion]

<If we put a man on the moon, we can make secure EA> #fallacious #pro-ea
    +> [Exceptional Access]
    <_ [Weak Analogy]

<Experts say EA is hard, so it just needs to be researched more> #fallacious #pro-ea
    +> [Exceptional Access]
    <_ [Missing the Point]

<!-- <EA is not needed because we don't have evidence of cases where it would have helped> #fallacious #pro-ea
    -> [Exceptional Access]
    <_ [Appeal to Ignorance] -->

# Arguments for Measures {isGroup: false}

<!--
# Response Measures
## Current Capabilities
    [Do Nothing]
    [Increase Investment]
## Legal Measures
    [Forced Password Disclosure]
    [Lawful Hacking]
## Exceptional Access
    [Cryptographic EA]
    [System Design EA]
-->

<!-- Start with good properties
    See: varia_2018, group_2019, committee_decrypting_2018 -->

[Minimize Increased Security Risk]: Measures should not dramatically increase risk for either specific data or
cybersecurity in general. #neutral {rank: "metrics"}
    <+ [Information Security]

[Law Enforcement Utility]: Measures should actually be useful to law enforcement in terms of accuracy, speed, and
cost. #neutral {rank: "metrics"}
    <+ [Public Safety]
    +> [Increase Investment]

[Protection of Civil Liberties]: Measures must preclude mass surveillance and international abuse
generally. #neutral {rank: "metrics"}
    <+ [Data Privacy]
    <+ [Institutional Trust]
    -> [Forced Password Disclosure]

[Transparency]: Measures should be reasonably auditable to the search target and the public. #neutral {rank: "metrics"}
    <+ [Institutional Trust]

[Economic Impacts]: Measures should consider competitiveness and cost burdens. #neutral {rank: "metrics"}
    -> [Exceptional Access]
    +> [Forced Password Disclosure]
    +> [Do Nothing]

<Relying Current Capabilities a Conservative Choice>: Introduces no new risks to security or liberty. #neutral
    <+ [Minimize Increased Security Risk]
    <+ [Protection of Civil Liberties]
    +> [Do Nothing]
    +> [Increase Investment]

<Lawful Hacking Misaligns Incentives>: Would create an adversarial relationship between law enforcement and
tech. #neutral
    <+ [Minimize Increased Security Risk]
    <+ [Transparency]
    -> [Lawful Hacking]

<Usefulness for Common Crime>: Would local agencies be able to use it at scale? #neutral
    <+ [Law Enforcement Utility]
    -> [Lawful Hacking]
    +> [Exceptional Access]

<Usefulness for Organized Crime>: Would organized threat actors be able to evade the measure? #neutral
    <+ [Law Enforcement Utility]
    -> [Forced Password Disclosure]
    -> [Exceptional Access]
    +> [Lawful Hacking]

<EA Very Difficult to do Securely>: Even accepting some risk, regardless of implementation EA is hard to do
safely. #neutral
    <+ [Minimize Increased Security Risk]
    -> [Exceptional Access]


# Arguments for EA Types {isGroup: false}

<EA DAR type1 is Secure>: DAR type1 is secure #neutral
    <+ [Information Security]
    +> [EA DAR type1]

<EA DIM type1 creates poor trust relationships>: DIM type1 is untrustrowrthy #neutral
    <+ [Institutional Trust]
    -> [EA DIM type1]

# Arguments for EA Proposals {isGroup: false}

<EA DIM prop1 doesn't help local LE>: DIM prop1 not even helpful #neutral
    <+ [Public Safety]
    -> [EA DIM prop1]

<EA DAR prop1 enables surveillance>: DAR enables the baddies #neutral
    <+ [Data Privacy]
    -> [EA DAR prop1]
