\chapter{Background}
\label{chap-background}

The problem of strong encryption and \acl{EA} exists in a technical, historical, and regulatory context. This chapter
introduces cryptography, summarizes the history of encryption and the ``crypto wars,'' lists prominent technical \ac{EA}
proposals, and lastly overviews relevant laws and regulations.



\section{Cryptography Basics}
\label{sec-crypto-basics}

\Ac{cryptography} is the study of techniques used to communicate securely in the presence of third parties. This is
performed by using a \ac{cipher} to translate between \ac{plaintext} and \ac{ciphertext}. A cipher is a tool or
algorithm that performs the translation, plaintext is the original data, and ciphertext is the encoded data.
\Ac{encryption} and \ac{decryption} are the processes for translating from plaintext to ciphertext and back. A
well-designed cipher ensures that only those parties with the correct \ac{key}, or secret information, can perform
encryption or decryption on the text.

% There are two classes of cryptographic ciphers---stream and block

There are two major cryptographic protocol families, symmetric and asymmetric. Symmetric protocols have been around for
thousands of years, but asymmetric protocols were only invented in recent decades. In \ac{sym-crypto}, encryption and
decryption are performed with the same key, and both parties must have this key in order to communicate securely. In
\ac{asym-crypto}, also known as \ac{public-key-crypto}, encryption and decryption are performed with two paired keys,
called the public key and the private key. The public key is not secret, but due to its relationship with the private
key, it can be used to establish identity and encrypted communication. Using this technique, two parties can communicate
privately without requiring previously agreed-upon secret information.

There are also two major cryptographic applications, securing \ac{DIM} and \ac{DAR}. Each application presents different
challenges that require different solutions. \Ac{DIM} typically uses long-lived \ac{asym-crypto} keys to perform
authentication and establish short-lived \ac{sym-crypto} session keys. The session keys perform the actual encryption of
the \acl{DIM}. \Ac{forward-secrecy} and \ac{replay-protection} are two important properties of \ac{DIM} encryption
protocols. \Ac{forward-secrecy} ensures that a leaked private key or session key does not compromise any other private
key or session key; \ac{replay-protection} ensures that messages cannot be replayed by an attacker without detection
\cite{bellovin_thinking_2016}. \Ac{E2EE} for instant messaging services is an example of encryption for \ac{DIM}.

\Ac{DAR} by nature must use long-lived keys for encryption. Instead of being negotiated and randomly generated at
encryption-time, as \ac{DIM} session keys are, these keys are either derived from a user-entered password or are stored
somewhere in computer memory. Secure storage often takes place with the assistance of dedicated hardware.
\Ac{disk-encryption} for laptops and mobile devices is an example of encryption for \ac{DAR}.

Data secrecy is not cryptography's only use, however. Data secrecy is the purpose of encryption, but encryption is only
one application of cryptography. Although encryption is cryptography's ``killer app,'' it is just a part of
cryptography's usefulness to security.

Cryptography is the technical foundation for many forms of computer and network security. Security is defined in terms
of several properties: authentication, integrity, non-repudiation, confidentiality, availability, and authorization
\cite{shostack_threat_2014}. These system-level properties emerge from both the composition of the system's components
(architecture) and the security of the components themselves. Likewise, the security of each component emerges from the
architecture of its subcomponents and the security of the subcomponents themselves. At the end of this chain of
analysis, the security of primitive components commonly relies on cryptography.

\mytab{table-security-and-crypto} connects each security property to its cryptographic basis. While lacking direct
cryptographic foundations, the property of availability indirectly relies on the other properties, and authorization
schemes are typically rooted in authentication.

% Spoofing                  Authentication
% Tampering                 Integrity
% Repudiation               Non-Repudiation
% Information Disclosure    Confidentiality
% Denial of Service         Availability
% Elevation of Privilege    Authorization
\begin{table}[h]
    \caption{The Cryptographic Basis of Security Properties}
    \label{table-security-and-crypto}
    \centering
    \begin{tabular}{ |l|l| }
        \hline
        \thead{Property} & \thead{Cryptographic Basis}           \\ \hline
        Authentication   & Digital certificates                  \\ \hline
        Integrity        & Cryptographic hashes                  \\ \hline
        Non-repudiation  & Digital signatures                    \\ \hline
        Confidentiality  & Encryption                            \\ \hline
        Availability     & \small{\ii{based on architecture}}    \\ \hline
        Authorization    & \small{\ii{rooted in authentication}} \\ \hline
    \end{tabular}
\end{table}

% Cryptographic primitives include symmetric key encryption, symmetric key encryption, one-way hash functions, and digital
% signatures. A few technologies that directly rely on these primitives include \ac{TLS}, \ac{PKI}, \ac{SSO} (e.g.
% Kerberos), \acp{VPN}, secure password storage, disk encryption tools, and secure- and trusted-boot processes. A few
% systems that directly rely on these technologies include the local and global financial systems; industrial control
% systems and critical infrastructure; health information systems; private, government, and military communications; and
% the integrity of the internet as a whole.
% % If I bring this back---this is jumping rather quickly from primitives to huge systems. Scale it more smoothly.
% % Connect little primitives to higher technologies, higher technologies to underpinnings of network computer systems,
% % and network computer systems as critical to these industries.

Violations of cryptographic integrity in primitive components, introduced by design or by accident, could have
catastrophic effects. Compromised digital certificates, hashes, or encryption would enable spoofing, tampering, and
information disclosure done both for their own sake and as tools in general attacks. The importance of neutralizing
these tools is clear when such attacks include interference with elections \cite{mueller_2018}, multi-billion dollar
disruptions of business \cite{greenberg_2018_notpetya}, and hospital network ransoms that disrupt care of patients
\cite{goodin_ransomware_2019}.

% I tried to find examples of high profile bugs or hacks that relied on crypto failures, but most are still
% architectural (exposed databases, default credentials (Mirai botnet)), human (BEC), or insecure code (buffer
% overflows--key to EternalBlue (wannacry and notpetya) and MS08-067 (Conficker)).

Encryption's dual role as an enabler of privacy and cornerstone of security is at the heart of the EA debate.
Cryptography has an absolute, mathematical power---a power that is objectionable in the realm of privacy, but necessary
in the realm of security.


\section{Encryption History}
\label{sec-crypto-history}

The section provides a brief overview of encryption from ancient to modern times.

\subsection{Encryption In the Past}
\label{sec-history-old}

Computerized encryption is a new technology, but the field of cryptography is old, since demand for privacy is as old as
communication itself. The most well-known ancient example of rudimentary encryption is the Caesar cipher, named after
the character substitution technique Julius Caesar used to protect private correspondence
\cite{luciano_cryptology_1987}. Significant developments include the first formal cryptographic study by Arab scholars
in the eighth century, advancements made out of necessity in the twentieth century's world wars, and the application of
computers to cryptographic problems \cite{kahn_codebreakers_1996}. Claude Shannon formalized the modern ``mathematical
analysis of cryptography'' in 1949 \cite{shannon_communication_1949} and Whitfield Diffie and Martin Hellman published
research on \ac{public-key-crypto} in 1976 \cite{diffie_new_1976}. The discovery of \ac{public-key-crypto} was an
important advance. Combined with computer networking and personal computing advances in the 1980s, it put the power of
strong encryption not just in the hands of governments and militaries, but of ordinary people.

However, this power enables very strong individual privacy. Government is inherently uncomfortable with individual
privacy; therefore, the use of encryption for private purposes has a contentious history. In 1587, Mary Queen of Scots
was convicted of treason based on evidence from decrypted letters, and in 1807, the prosecutors who tried Aaron Burr for
treason attempted to force testimony from his secretary on the contents of encrypted messages
\cite{kerr_encryption_2017}.

\subsection{The First Crypto War}
\label{sec-history-cw1}

These circumstances---government discomfort with absolute privacy, rapidly increasing availability of strong encryption,
and a blossoming computer industry foundationally reliant on cryptography---came to a head in what has become known as
the first ``crypto war.''

In 1976, Diffie and Hellmann published their seminal research in public key cryptography. That same year, the U.S.
Congress passed the \ac{AECA} and declared that strong cryptography is subject to export controls
\cite{kehl_right_2015}. \Ac{the-cw1} began in 1991, when the U.S. Senate introduced, but did not pass, a bill mandating
access to plain text contents when authorized by law. In response, Philip Zimmermann released \ac{PGP}, e-mail
encryption software, in order that strong cryptography be ``made available to the American public before it became
illegal to use'' \cite{zimmermann_1996}. In 1993, the Clinton administration introduced the \ac{clipperchip}
\cite{press_1993} with the goal of ``providing the public with strong cryptographic tools without sacrificing the
ability of law enforcement and intelligence agencies to access unencrypted versions of those communications''
\cite{thompson_2015}. Citing the foundational role of cryptography in security---and the potential of human rights
abuses for compromised privacy---industrial and technical leaders reacted negatively to the initiative
\cite{kehl_right_2015} \cite{zimmermann_1996}. When a prominent security researcher discovered flaws that allowed users
to subvert the \ac{clipperchip} mechanisms \cite{blaze_protocol_1994}, the proposal died.

Despite the failure of the \ac{clipperchip}, the debate over export controls and access to strong encryption continued,
primarily focused on various key escrow proposals \cite{thompson_2015}. In 1996, two pro-encryption bills were
introduced in the U.S. Congress, one in the Senate and one in the House. The Senate saw S.1726, the \ac{PROCODEAct} of
1996, which sought to abolish the export controls on encryption software \cite{burns_s1726_1996}. The House saw HR.3011,
the \ac{SAFEAct} of 1996, which similarly sought to remove export controls, but further sought to explicitly allow
arbitrarily strong encryption for all legal activity and preclude mandatory \ac{EA} schemes such as the \ac{clipperchip}
\cite{goodlatte_hr3011_1996}. Zimmermann, the author of PGP, who had by this time endured an investigation by the
Customs Service for publishing his work, testified before the Senate in favor of the \ac{PROCODEAct}
\cite{zimmermann_1996}. In November of 1996, the Clinton administration released an executive order effectively removing
export controls on encryption products along the lines of the \ac{PROCODEAct}, which never came to pass
\cite{clinton_1996}.

From 1996 to 1999, the \ac{SAFEAct} was proposed several times, was discussed at hearings, and gained support
\cite{kehl_right_2015}. By this time, there was ``an overwhelming amount of evidence against moving ahead with any key
escrow schemes'' \cite{thompson_2015}, and in 1999 the Clinton administration abruptly changed course, adopting almost
all \ac{SAFEAct} proposals \cite{kehl_right_2015}. This development marked the end of \ac{the-cw1}.

\subsection{The Second Crypto War}
\label{sec-history-cw2}

Two developments paved the way for \ac{the-cw2}. The first was the result of inaction: when the Clinton administration
changed its encryption policy, the U.S. House dropped the \ac{SAFEAct} \cite{goodlatte_hr3011_1996}. The \ac{PROCODEAct}
and other encryption-related bills went unpassed as well, as elaborated in \mysec{sec-us-reg-fails}. This legislative
failure meant that rather than being written in the pen of law, encryption policy was written in the pencil of executive
order.

The second development was the terror attacks of September 11, 2001. The events of that day occurred in the context of
expanding law enforcement powers fueled for decades by all three branches of government. Presidents promoted the idea of
being ``tough on crime'' and launched a war on drugs; legislators passed bills such as 1978's \ac{FISA}, which provided
broad surveillance powers over foreign nationals, and in some cases U.S. citizens \cite{rodino_1978}; and the judiciary
practiced a ``jurisprudence of crime control'' that gave police broad leeway \cite{gizzi_fourth_2016}.

In this context of expanded surveillance, the scale of the September 11 attacks seemed to justify yet greater
investigatory powers \cite{bloss_escalating_2007}. October of 2001 saw passage of the USA PATRIOT Act, which had several
significant impacts: (1) it weakened the limitation for using \ac{FISA} requests on U.S. citizens; (2) it expanded the
scope of what could be compelled via \ac{FISA} orders; (3) it authorized ``roving'' wiretaps; and (4) it increased the
power of \acp{NSL}, which can be used without judicial review to compel information from digital service providers while
precluding any public disclosure of the event \cite{sensenbrenner_2001} \cite{shamsi_2011}. The government was
performing more surveillance than ever, and even these weakened limitations would be repeatedly violated
\cite{shamsi_2011} \cite{tucker_2020}.

The weakness of data protection laws and absence of encryption protection laws left the door open for a second crypto
war. Increased government surveillance set events in motion toward conflict. These two developments prepared the way,
but it was the 2013 Snowden revelations that constituted the crossing of the threshold. Though policies such as the U.S.
\ac{NSA}'s warrantless wiretapping caused a stir, it was the mass data collection under the agency's \ac{PRISM} and
related programs that caused the real public outcry \cite{landau_making_2013}. With the public interest focused on
digital privacy, encryption promised to be a technical solution. U.S. tech companies responded by introducing default
device encryption for \acl{DAR} and \acl{E2EE} for \acl{DIM}.

The emergence of strong encryption caused \ac{the-cw1}; its proliferation is causing the second.

The U.S. corporate response to Snowden should not be overly construed as a morally motivated defense of civil rights.
Their behavior is a matter of several practical factors, including market pressure, cultural pressure, and the
advancement in available encryption technology \cite{treguer_us_2018}. Another factor is the pursuit of basic digital
security. Recall encryption and cryptography's critical role in security as described in \mysec{sec-crypto-basics}. When
lawmakers question technical leaders about their companies' encryption policies, executives have repeatedly appealed to
the fact that strong cryptography is a necessity for security \cite{schulze_clipper_2017}.

\subsection{Current Context}
\label{sec-history-current}

Several events and arguments have come to characterize \ac{the-cw2}.

\paragraph*{``Security vs. Security''} The relationship between security and privacy is sometimes viewed as
antagonistic, an assumption implicit in the ``nothing-to-hide'' argument. However, discussions in recent years have
shown that the debate is more about ``Security vs. Security'' than ``Security vs. Privacy''
\cite{stalla_bourdillon_privacy_2014}. In this context, there are two types of security. First, public security (often
referred to as ``safety'' in this paper), which is the pursuit of law enforcement. Second, cybersecurity, which the
pursuit of the technical community. Both sides of the debate have by now acknowledged that privacy and public security
are not always in conflict. In fact \ac{EA}'s effects on public security vs. cybersecurity---which in return affects
public security---may be more important \cite{schneier_2019}.

\paragraph*{Apple vs. FBI} The 2015 San Bernardino terror attack resulted in the first major battle of \ac{the-cw2}. The
suspect was killed, leaving behind a locked iPhone. The \ac{FBI} issued an order under the \acrlong{AWA} to compel Apple
to unlock the device, which was among the first generation of Apple's fully encrypted iPhones. Apple objected on grounds
that it was ``unreasonably burdensome'' and would undercut the integrity of all iOS devices \cite{schulze_clipper_2017}.
The case occupied U.S. District courts, the media, and the attention of the political world from February 16, 2016, when
the warrant was issued, to March 28, when the \ac{FBI} announced they had gained access to the phone through alternate
means \cite{novet_2016}. Although the phone proved not to contain any important data \cite{schulze_clipper_2017}, the
high profile case featured two characteristic elements of the new crypto wars---terrorism and device encryption. Shortly
after the case ended, a pair of Republican and Democratic senators jointly released a discussion draft of a bill that
would have forced Apple to comply \cite{burr_2016}. The draft did not make it to the floor, and the unresolved nature of
the court case left the legal debate unresolved.

\paragraph*{The \Ac{horsemen}} In the 1990s, an influential encryption advocate coined the phrase ``\ac{horsemen-full}''
to describe four reasons that governments and law enforcement agencies use to undercut public support for strong
encryption \cite{may_1994}. The original list includes terrorists, pedophiles, drug dealers, and money launderers,
though many substitute kidnappers for money launderers \cite{schneier_scaring_2019}. Reflecting the times, \ac{the-cw1}
emphasized drug trafficking whereas \ac{the-cw2} emphasizes terrorism and child pornography (increasingly referred to as
\ac{CSAM}) \cite{schulze_clipper_2017}. The focus on terrorism is likely a result of the September 11 terror attacks as
well as the San Bernardino terror attack that launched the Apple vs. \ac{FBI} case. The focus on \ac{CSAM} is likely a
result of the growth of the ``dark web'' and a revelatory 2019 investigation by the \textit{New York Times}
\cite{keller_internet_2019}.

\paragraph*{\ac{DIM} vs. \ac{DAR}} As noted in \mysec{sec-crypto-basics}, securing \acl{DIM} and \acl{DAR} are two
different challenges that require different solutions. Therefore, both technical and policy proposals often split their
recommendations along these lines \cite{group_2019} \cite{owen_law_2018}. Discussion of \ac{EA} for \ac{DIM} typically
involves \ac{E2EE}, whereas for \ac{DAR} it typically involves \ac{disk-encryption} of mobile phones. The focus of law
enforcement in the U.S. has pendulated between these several times \cite{schneier_2019}. A research group at Carnegie
Mellon with participants from both sides of the debate has identified \ac{EA} for \ac{DAR} as the more tractable problem
\cite{group_2019}.

\paragraph*{Volatile Politics} Finally, \ac{the-cw2} is taking place amongst a political landscape marked by
uncertainty, extremism, misinformation, and a pandemic that will have unknown long-term impacts. Since government is
part of the broader data security threat model, its behavior is important. Unfortunately, it is difficult for the
technical community to engage productively with policymakers due to present political dynamics and the lack of reliable
data showing what law enforcement agencies need \cite{granick_2018}.

That brings us to where the debate stands today. A December 2019 U.S. Senate Judiciary Committee featured the top two
U.S. parties both expressing anger over whether data should be ``beyond the reach of the law.'' Senators threatened tech
executives with statements such as ``get your act together, or we will gladly get your act together for you''
\cite{geller_2019}. In March 2020, the Republican atop the Senate Judiciary Committee introduced S.3398, the
\ac{EARNITAct} of 2020, which seeks to establish a 16-chair committee with the power to revoke online platforms'
liability protection for user-submitted content if the committee determines the platform is not doing enough to fight
\ac{CSAM} \cite{graham_s3398_2020}. As illustrated by the previously mentioned \textit{New York Times} feature
\cite{keller_internet_2019} that likely triggered the December 2019 hearing, the problem is enormous. However, critics
largely saw the \ac{EARNITAct} as an attempt to indirectly yet effectively outlaw \ac{E2EE} \cite{newman_2020}
\cite{pfefferkorn_2020}. In response, legislators narrowed the focus of the \ac{EARNITAct}, but only after unveiling the
\ac{LAEDAct}

% Could create timeline https://tex.stackexchange.com/questions/196794/how-can-you-create-a-vertical-timeline



\section{Approaches to Exceptional Access}
\label{sec-tech-approaches}

% TODO: Does this read well here? Used to be after Regulatory Environment section.

% There are several types of approaches:
%  My selections here are also rather sparse. Create another appendix? Possibly create table of
% properties below, similar to denning_taxonomy_1996. savage_lawful_2018 has some good citations to mine.
% - Allow strong encryption (anyone with the users' private keys can see it)
% - Disallow encryption (anyone can see it)
% - Make encryption sufficiently weak, e.g. limit key length (anyone with enough CPU can see it)
% - Require use of backdoor-ed algorithms, security via obscurity (anyone with the secret knowledge can see it)
% - Allow any encryption, just be able to provide keys (anyone with the extra keys can see it)
%   - Store extra in govt DBs, in corporate DBs, in third-party DBs, on blockchain, in secure HW on device
%   - Split the key and store it multiple places
%   - See denning_taxonomy_1996
% - Use some alternative path
%   - Coerced passwords, finding unencrypted copies, seizing devices while unlocked, lawful hacking

% Lesson: the problem is _not_ cryptographically storing and splitting key recovery information. It's keeping those keys
%   safe! If you can sit on recorded data and wait for the keys to get leaked, which they will...

% Moving forward, what are the elements that are needed for a feasible EA system? (1) White-box-secure ways of producing
% key recovery information. Do the protocols exist? EES failed. Needs to be rock solid. (2) Dispersed key recovery
% information. (3) A robust, anti-fragile, inherently secure means of protecting those keys, and perhaps decaying them
% over time (https://en.wikipedia.org/wiki/Data_degradation).

There are several technical approaches to \ac{EA}. This section organizes approaches into three
categories---\ac{key-escrow}, cryptographic recovery without a key, or non-cryptographic means of acquiring plaintext.

\newcommand{\propsstart}[0]{\begin{itemize}}
\newcommand{\prop}[2]{ % Name, description
    \item \textbf{#1} \nopagebreak

    \vspace{0.5\baselineskip} \parbox{\linewidth}{#2} \vspace{0.5\baselineskip}
}
\newcommand{\propsend}{\end{itemize}}


\subsection{Types of Key Escrow}

Key escrow is the most obvious way to implement \ac{EA}. It involves storing additional copies of the encryption keys.
Alternatively, rather than directly storing copies, key escrow may involve storing information that can be used to
derive additional copies. Key escrow can be subdivided into various types according to where the escrowed information is
stored.

\propsstart
    \prop{Trusted-party key escrow}{

Any scheme that relies on the fidelity and security of information held by an entity besides the data owner (in the case
of \ac{DAR}) or sender or receiver (in the case of \ac{DIM}) is a ``trusted-party'' key escrow approach. Though there is
a wide variety of implementation options within this category \cite{denning_taxonomy_1996}---secret or open protocol,
hardware-enabled or software-only, single key or split key, government or third-party escrow---the foundation of the
effectiveness of these approaches lies in the security of the trusted party. The \ac{clipperchip} is one example, being
a secret protocol hardware-enabled split key government escrow system \cite{denning_taxonomy_1996}.

}

    \prop{Distributed key escrow}{

Some schemes compensate for the risk of concentrated sensitive information by massively distributing the secret
information. In this arrangement, trust is put in the distributed system, not in any single party. Such systems offer
high data availability while making covert key recovery difficult. This approach was introduced in \ac{the-cw1}
\cite{goos_oblivious_1996} and has modern blockchain \cite{phan_key_2017} and distributed device
\cite{servan_schreiber_jje_2020} variations. These approaches are not as thoroughly explored as trusted-party
\ac{key-escrow}.

}

    \prop{Device key escrow}{

The third type of \ac{key-escrow} is device-based. In device-based \ac{key-escrow}, special key information is held not
by trusted parties or distributed systems, but on the device itself in specialized hardware. Advances in secure hardware
``enclaves'' since \ac{the-cw1} have enabled secure local key storage. Approaches relying on hardware primarily target
\ac{DAR} and may include time elements and split keys with trusted parties as well \cite{savage_lawful_2018}
\cite{ozzie_2018}.

}
\propsend


\subsection{Non-Escrow Cryptographic Data Recovery}

Though key escrow is the most discussed \ac{EA} approach, alternative technical means have been proposed.

\propsstart
    \prop{Translucent cryptography}{

Research in \ac{the-cw1} included the introduction of ``translucent'' cryptography, in which an observer could surveil
some but not all communications using statistical cryptographic methods \cite{bellare_translucent_1996}. Under this
scheme, no keys are escrowed, but law enforcement could recover a predetermined percentage of plaintext data. That
percentage would be designed to balance privacy, security, and safety. This research, though more experimental than key
escrow proposals, was explicitly pursued to demonstrate that alternatives to key escrow do exist
\cite{bellare_translucent_1996}.

}

    \prop{Cryptographic ``crumple zones''}{

A recent proposal adopts the idea of crumple zones from automotive engineering---``in an emergency situation the
construction should break a little bit in order to protect the integrity of the system as a whole and the safety of its
human users'' \cite{wright_crypto_2018}. Similar to the translucent approach, no keys are escrowed and only passive
surveillance is possible. Keys are generated in a manner that makes messages inherently recoverable, but only after
extreme up front costs and significant marginal costs.

}
\propsend


\subsection{Alternative Approaches}
\label{sec-alt-approaches}

The following approaches do not use \ac{EA} at all, but are alternative technical or legal mechanisms that can be used
towards the same goal.

\propsstart
    \prop{\Ac{lawful-hacking}}{

\Ac{lawful-hacking} is one way to access \ac{plaintext} without \ac{EA}. Under \ac{lawful-hacking}, instead of having
access to plaintext data via an alternative means of decryption, law enforcement is allowed to perform otherwise-illegal
hacking activity in order to find the key, compromise a device, or intercept plaintext versions of the data
\cite{kerr_encryption_2017}. While some see this as a viable middle ground \cite{nguyen_lawful_2017}, encouraging law
enforcement to exploit vulnerabilities creates mis-aligned incentives. If law enforcement opposes strong security in
general, it could foster the exploit market while costing ordinary users money and security \cite{soesanto_2018}.

}

    \prop{Compelled password disclosure}{

In some cases, a suspect in custody may have the ability to access the desired encrypted information via a key,
\ac{PIN}, or password. In these cases, authorities sometimes compel the suspect to disclose the password. In the U.S.,
this approach draws debates about the Fifth Amendment right against self-incrimination \cite{bittenbender_2019}
\cite{sobel_2019}. Of course, this approach cannot address \ac{DIM} or situations in which the knowledgeable party is
not in custody.

% these look good: \cite{sacharoff_unlocking_2018}, \cite{fredona_fifth_2016}
% this probably has something to say: kerr_encryption_2017

}

    \prop{Alternative paths to plaintext}{

Simpler methods than computer hacking or legal coercion can be used: encrypted data may exist in plaintext elsewhere, or
authorities may seize equipment while it is unlocked \cite{kerr_encryption_2017}. This approach relies on law
enforcement's skills in investigation and sting operations. This approach is used successfully today. In 2017, an
international law enforcement operation used this technique to take down a large illicit online drug market
\cite{greenberg_2018}. This approach also does not address \ac{DIM} and requires well-executed operations.

}
\propsend



\section{Regulatory Environment}
\label{sec-reg-environment}

The following sections list laws which directly or indirectly affect the use of encryption. Though this thesis is
U.S.--focused, it is worth briefly touching on the regulatory environment of other countries. \Ac{EA} is an
international problem, as digital technology has little respect for political borders.
\mysecrange{sec-us-regs}{sec-us-judicial} describe the regulatory environment in the U.S. and \mysec{sec-world-regs}
describes regulations around the world.

\subsection{Enacted U.S. Regulations}
\label{sec-us-regs}

The following laws and regulations have been applied to cases involving surveillance, cryptography, and access to
encrypted information:

\newcommand{\lawsstart}{\begin{itemize}}
\newcommand{\law}[4]{ % Year, name, citation, description
    \item #1: \textbf{#2} #3 \nopagebreak

    \vspace{0.5\baselineskip} \parbox{\linewidth}{#4} \vspace{0.5\baselineskip}
}
\newcommand{\lawsend}{\end{itemize}}

\lawsstart

    \law{1789}{\acf{AWA}}{\cite{congress_1789}}{

A short law designed to grant federal courts the right to ``issue all writs necessary or appropriate in aid of their
respective jurisdictions and agreeable to the usages and principles of law,'' creating a legal framework for providing
data to law enforcement. The \acs{AWA} was famously cited in the Apple vs. FBI case, though its applicability to \ac{EA}
in general is unsettled \cite{matyas_incommensurability_2018}.

}

    \law{1791}{Bill of Rights: Amendments I, IV, and V}{\cite{madison_1791}}{

The most frequently cited constitutional amendments in the \ac{EA} debate. I: freedom of speech; IV: protection from
unreasonable searches and seizures and requirements for warrants; V: right against self-incrimination.

}

    \law{1976}{\acf{AECA}}{\cite{morgan_hr13680_1976}}{

The \ac{AECA} expanded arms export controls and created the \ac{ITAR} regulations framework. Encryption products were
classified as arms and subjected to export controls \cite{kehl_right_2015}.

}

    \law{1978}{\acf{FISA}}{\cite{rodino_1978}}{

This statute allows the executive branch ``to authorize electronic surveillance for foreign intelligence purposes
without a court order, in some circumstances.'' \acs{FISA} applications take place in secret, and may be conducted
against U.S. citizens if foreign intelligence is the ``primary purpose'' \cite{shamsi_2011}. \acs{FISA} has been the
subject of frequent FBI abuse \cite{shamsi_2011} \cite{tucker_2020}.

% (the FBI almost lost some provisions; follow up on https://apnews.com/110ff653e98478da66765897dde3d613,
%     https://www.washingtontimes.com/news/2020/mar/15/adam-schiff-fisa-reform-intervention-protects-fbi-/,
%     https://saraacarter.com/fisa-senate-passes-measure-extending-surveillance-powers-abuses-not-addressed/)
% May 27: renewal in great doubt; Trump opposed because he sees himself as a victim of FISA abuse
%     (https://apnews.com/c04a5e3bb156774af83b686bbe2ea872)

}

%     \law{1986}{\acf{CFAA}}{\cite{hughes_hr4718_1986}}{
% Criminalized ``knowingly access[ing] a computer without authorization or exceeding authorized access'' and thereby
% violating the confidentiality, integrity, or availability of the system. While presumably intended to target hacking,
% the \acs{CFAA} has been used to prosecute a host of crimes, and suffers from dated language;
% % ---what does it mean to ``access'' a ``computer'' loading a simple webpage may involve dozens of devices---
% whether violating the terms of service constitutes ``exceeding authorized access'' remains an open question
% \cite{wolff_computer_2016}. Importantly for \ac{EA}, the law includes carve-outs for law enforcement and intelligence
% activities.
%
% Follow up: CFAA going before supreme court: https://www.cyberscoop.com/cfaa-will-soon-day-supreme-court/
% }

    \law{1986}{\acf{ECPA}}{\cite{kastenmeier_hr4952_1986}}{

The \ac{ECPA} includes the Stored Communications Act and Pen Register Act, amending the switchboard-era Wiretap Act.
Provides explicit protections for private electronic communications data, and updated definitions to contemporary
technology. It grants law enforcement explicit access to certain data as well; some terminology has aged poorly with
technological evolution, making the access increasingly permissive \cite{shamsi_2011}.

}
% FIXME: make tense for enacted laws present

    \law{1994}{\acf{CALEA}}{\cite{edwards_hr4922_1994}}{

\ac{CALEA} mandates that telecommunications carriers enable the government to ``intercept all of the subscriber's wire
and electronic communications'' in a manner that ``protects the privacy and security'' of communications not authorized
to be intercepted. The law does not authorize law enforcement to compel use of any specific technologies, which meant
that the \ac{clipperchip} proposal issued a year earlier could not be made mandatory through \acs{CALEA}. \acs{CALEA}
specifically excludes ``information services'' from its interception requirement which has included internet platforms,
though that exclusion is currently under attack \cite{pfefferkorn_2019}.

}

    \law{2001}{\ac{USAPATRIOTAct}}{\cite{sensenbrenner_2001}}{

Written in the aftermath of September 11, the \ac{USAPATRIOTAct} broadly expanded U.S. government surveillance powers in
25 sections of ``Title II: Enhanced Surveillance Procedures.'' The act notably expands \acs{FISA} order scope (Section
206), duration (207), and use on U.S. citizens (218). Section 215 enables court orders requiring business records, but
the Snowden leaks revealed that the government had been secretly using a non-standard definition of ``business records''
in order ``to justify requests for domestic telephone metadata delivered in bulk, not individualized requests''
\cite{landau_making_2013}.

}

%     \law{2007}{\acf{PAA}}{\cite{mcconnell_s1927_2007}}{
% Retroactively approved of George W. Bush's warrantless wiretapping policy, a loose interpretation of FISA
% \cite{landau_making_2013}.
% }

    \law{2008}{\acf{FISAAA}}{\cite{reyes_hr6304_2008}}{

Like the \ac{USAPATRIOTAct} before it, \acs{FISAAA} expanded \ac{FISA} powers once again. It additionally provided
``telephone companies retroactive immunity for participating in the warrantless surveillance'' on any international
communication, a policy established in 2001 under another loose, secret interpretation of \ac{FISA}, ``as well as
creating prospective immunity for FISAAA activities'' \cite{landau_making_2013}.

}

    \law{2015}{\ac{USAFREEDOMAct}}{\cite{sensenbrenner_2015}}{

The \ac{USAFREEDOMAct}, introduced by the same U.S. House representative as the \ac{USAPATRIOTAct}, passed the Senate
almost two years to the day after Snowden's leaks began. It contains many reforms to \ac{FISA} and the use of \acp{NSL}.
Most notably, it ends the interpretation of section 215 of the \ac{USAPATRIOTAct} that enabled mass collection of
telephone metadata.

}

\lawsend

\subsection{Unsuccessful U.S. Regulation Attempts}
\label{sec-us-reg-fails}

The following are proposed laws and regulations that did not go into effect or are still in process:

% \cite{burns_s1726_1996} \cite{leahy_s376_1997} \cite{ashcroft_s2067_1998} \cite{goss_hr2616_1999}
% \cite{goss_hr2617_1999} \cite{administration_CESA_1999} \cite{leahy_s3083_2000}

\lawsstart

    \law{1993}{The \ac{clipperchip}}{\cite{press_1993}}{

As described in \mysec{sec-history-cw1}, the \ac{clipperchip} was a voluntary \ac{EA} initiative from the White House.
The initiative targeted \ac{DIM} and established the Escrowed Encryption Standard, which includes an encrypted copy of
the session key in the message \cite{blaze_protocol_1994}. The initiative prompted debate but received a largely hostile
reception \cite{kehl_right_2015}. When a security researcher discovered flaws that allowed users to subvert the
\ac{clipperchip} mechanisms, the proposal died \cite{blaze_protocol_1994}.

}

    \law{1996}{The \acf{SAFEAct}}{\cite{goodlatte_hr3011_1996}}{

The \ac{SAFEAct} would have broadly protected ``use any encryption regardless of the encryption algorithm selected,
encryption key length chosen, or implementation technique or medium used,'' excepting ``the unlawful use of encryption
in furtherance of a criminal act.'' It also would have lifted export controls. The bill grew support as it was
reintroduced in consecutive congresses, but was abandoned when the Clinton administration adopted the act's
pro-encryption policies in 1999 \cite{kehl_right_2015}.

}

    \law{1996}{The \acf{PROCODEAct}}{\cite{burns_s1726_1996}}{

The Senate's \ac{PROCODEAct} was very similar to House's \ac{SAFEAct}, though it focused primarily on removing export
controls, and used slightly weaker language protecting all forms of encryption. Like the \ac{SAFEAct}, it was abandoned
when the Clinton administration adopted the act's export control policies in 1996 \cite{thompson_2015}.

}

%     \law{1997}{Encrypted Communications Privacy Act}{\cite{leahy_s376_1997}}{
% % mix of SE protection and EA guidelines?
% }

%     \law{1998}{Encryption Protects the Rights of Individuals from Violation and Abuse in CYberspace (E-PRIVACY) Act}
%         {\cite{ashcroft_s2067_1998}}{
% % like above?
% }

%     \law{1999}{Encryption for the National Interest Act}{\cite{goss_hr2616_1999}}{
% }

%     \law{1999}{Tax Relief for Responsible Encryption Act}{\cite{goss_hr2617_1999}}{
% % ^^ these two introduced by same rep on same day
% }

    \law{1999}{\ac{CESA}}{\cite{administration_CESA_1999}}{

\Ac{CESA} was a legislative proposal by the Clinton administration introduced alongside the executive order that led to
the abandonment of the \ac{SAFEAct}. Section 102 lays out the government position precisely: encryption is an important
tool for information security, but is also used to ``hide unlawful activity by terrorists, drug traffickers, child
pornographers, and other criminals'' (the \ac{horsemen}), and therefore ``appropriate means must be available to fulfill
these law enforcement objectives.'' The bill would establish a voluntary-participation third-party key escrow system
with ``recovery agents'' that would provide law enforcement with access to \ac{plaintext}. Access would be compelled
through a variety of mechanisms, including warrantless mechanisms through \ac{FISA}. The White House failed to attract a
member of Congress to officially sponsor the bill.

}

    \law{2000}{Enhancement of Privacy and Public Safety in Cyberspace Act}{\cite{leahy_s3083_2000}}{

After \ac{CESA} failed, the White House proposed watered-down legislation that was successfully sponsored by a senator.
This bill would have amended the \ac{ECPA} and \ac{CFAA}. It would have made relatively modest changes to government
data access requirements. Though it received congressional sponsorship, even the sponsor was critical of parts of the
bill, and it died in committee \cite{senate_2000}.

}

    \law{2016}{Compliance with Court Orders Act (discussion draft)}{\cite{burr_2016}}{

Though this bill was not officially proposed, it represents one of the first legislative attempts to regulate encryption
in \ac{the-cw2}. This draft was released shortly after the close of the Apple vs. FBI case, and would have compelled
Apple to unlock the suspect's phone. Though it would not mandate a specific technical approach, the bill would have
mandated that manufacturers and service providers be able to provide \ac{EA}. This mandate notably goes beyond several
regulatory proposals in \ac{the-cw1} by forcing platform and application developers to comply. Previewing a common
phrase in recent \ac{EA} arguments \cite{geller_2019}, the draft's authors both used the phrase ``above the law'' in
promotion of the bill.

}

    \law{2018}{The Secure Data Act}{\cite{lofgren_hr5823_2018}}{

Proposed in reaction to the Compliance with Court Orders Act and anti-encryption sentiment, this bill would have
provided protections against ``mandating the deployment of vulnerabilities in data security technologies'' at the
federal level. It stopped short of explicitly protecting all forms of encryption.

}

    \law{2019}{The \ac{ENCRYPTAct}}{\cite{lieu_hr4170_2019}}{

This bill is designed to ``preempt State data security vulnerability mandates and decryption requirements,'' being a
state-level version of the Secure Data Act. This bill goes further to explicitly disallow \ac{EA} requirements in state
law.

}

%     \law{2020}{The \acf{EARNITAct}}{\cite{graham_s3398_2020}}{

% Introduced by the chair of the Senate Judiciary Committee, one of the outspoken encryption critics during the 2019
% Senate hearing on encryption and \ac{EA}, the \ac{EARNITAct} is designed to address \ac{CSAM} and has received attention
% as a threat to encryption \cite{newman_2020} \cite{pfefferkorn_2020}. As described in \mysec{sec-history-current}, the
% bill would revoke online platforms' liability protection for user-submitted content if it is does not doing enough to
% combat \ac{CSAM}. Critics fear that meeting the regulatory requirements would preclude \ac{E2EE}, and at least one
% popular \ac{E2EE} messaging platform has threatened to pull out of the U.S. market if the bill were to pass
% \cite{lund_2020}.

% % Note: based on the amendment's modifications, it is no longer about encryption. This has become more moderation and
% % CSAM focused, and the LAED Act has taken over the encryption side. A wise split (not that either bill is necessarily
% % good.)
% % https://www.engadget.com/earn-it-act-amendments-pass-senate-judiciary-committee-165030518.html

% }

    \law{2020}{The \acf{LAEDAct}}{\cite{graham_2020}}{

The \ac{LAEDAct} is a direct attack on encryption and the direct successor of the Compliance with Court Orders Act. It
was introduced by the chair of the Senate Judiciary Committee, also sponsor of the \ac{EARNITAct} and one of the
outspoken encryption critics during the 2019 Senate hearing on encryption and \ac{EA}. The \ac{LAEDAct} specifically
addresses \ac{DAR} and \ac{DIM} by forcing device, operating system, and application developers to implement the ability
to decrypt all data stored or passing through the device or software system ``concurrently with their transmission''
``unless the independent actions of an unaffiliated entity make it technically impossible to do so.'' The act neither
mandates nor recommends any technical approach to providing this capability.

}

\lawsend

\subsection{The U.S. Judicial Environment}
\label{sec-us-judicial}

The above history and section on U.S. law encompasses the executive and legislative branches' influence on surveillance
and cryptography. However, a complete portrait of government encryption policy must include the influence of the
judiciary branch. The judiciary branch influences policy through interpretation of laws and creation of legal doctrine.
This section describes this influence, reviews how it has affected cryptography policy, and analyzes where cryptographic
jurisprudence may go from here.

% TODO: find a "con" word that means "denied"! Contested?

The primary judiciary function is to adjudicate the law through the determination of facts and interpretation of
authoritative legal texts. However, whether it is condemned, denied, conceded, or condoned, the judicial branch also
establishes legal doctrine and actively enforces rulings in a manner that amounts to creation of public policy
\cite{feeley_judicial_2000}. Due to Congress's clear authority over telecommunications and federal investigatory powers,
the courts are most likely to exert influence in this area through interpretation of current law. This interpretation
will both determine how present law is enforced and draw constitutional boundaries around any actions the executive or
legislative branches undertake.

Judicial influence on encryption policy is primarily mediated through the Fourth Amendment, particularly regarding the
interpretation of a person's ``effects,'' what is ``reasonable,'' and what defines a ``search.'' The Supreme Court's
interpretation and implementation of the Amendment has changed over time. Legal scholars Craig Curtis and Michael Gizzi
conducted an in-depth analysis of the Court's jurisprudence from the 1960s Warren Court, through the influential 1980s
Rehnquist Court, to the mid-2010s Roberts Court \cite{gizzi_fourth_2016}. Their analysis revealed a deep proclivity
towards crime control that is only recently thawing. This gradual return to decisions favoring civil liberties, caused
by evolution of technology, of the court, and of the justices themselves, has been favorable for data privacy. Recent
cases have increasingly sided with defendants, caused justices to strain to show that they understand technology, and
increased the categories of protected digital data \cite{gizzi_fourth_2016}. 2018's potentially landmark \ii{Carpenter
v. United States} may be the most impactful yet. Though the case only resulted in a narrow decision against unwarranted
cell phone location data tracking, the Court's decision undermines the pre-digital third-party doctrine, which holds
that Fourth Amendment protection is forfeit when the data is willingly given to a third-party \cite{franklin_2018}.

As this relates to \ac{EA}, Fourth Amendment interpretation determines the threshold at which authorities require a
warrant, not what demands they can or cannot make once they have one. As mentioned above, the FBI argued in the San
Bernardino case that the \ac{AWA} grants it authority to demand access, though others argue that \acs{CALEA} explicitly
precludes this kind of demand \cite{gidari_2016}. Since the FBI dropped the case, the matter is not formally settled,
though the consensus is that legislation such as the \ac{LAEDAct} is required before courts would uphold that command.

The second most salient legal issue is the Fifth Amendment right against self-incrimination, which arises in cases of
compelled password disclosure. This question has not yet reached the Supreme Court, and state courts have ruled
compelled disclosure as constitutional in some cases \cite{sobel_2019} \cite{lee_nj_2020} and unconstitutional in others
\cite{lee_its_2020} \cite{vaas_2019}.

That judicial influence on privacy and technology is changing is to be expected. To explain the fluctuating state of
legal interpretation as it relates to \ac{EA}, Matyas et al. make the helpful distinction between legal rules and
principles \cite{matyas_incommensurability_2018}:

\begin{displayquote}
The tension between technical and legal views of sensitive issues such as encryption and surveillance is illuminated by
applying the jurisprudential lens. \dots~Liberal legal systems, manifesting what is generally understood as ``the rule
of law,'' are actually composed of both rules and principles. Legal ``rules'' can be understood as logical propositions
that are expected to yield answers about what is and is not permitted using formal reasoning capabilities. By contrast,
legal ``principles'' articulate values and policies that must be reflected in a legal system but do not necessarily
dictate an unambiguous outcome in any given case.
\end{displayquote}

Rules are the low-level implementation of principles. When the underlying facts of the situation change, as they do by
definition for wicked problems, the rules become out of sync with the principles that bade them. Recent flux in judicial
rulings surrounding surveillance and technology, particularly around the Fourth Amendment, prove that the courts are in
the process of updating interpretations of rules in light of the new facts; which principles they will ultimately favor
remains to be seen, but rulings like \ii{Carpenter} show a willingness to protect privacy.

There are three types of cases through which the judicial branch could have a strong effect on the future of digital
privacy policy. First, Fourth Amendment cases will establish classes of protected data and thresholds for warrants.
Second, a Supreme Court Fifth Amendment case could settle under what circumstances, if any, a password could be
compelled. Third, a surprise \ac{AWA} ruling could open the door to demands for access, though legislation like
\ac{LAEDAct} is more likely to have this effect.



\subsection{Regulations around the World}
\label{sec-world-regs}

This thesis focuses on U.S. policy, but \ac{EA} technologies and policies have international impacts. The following is a
brief account of the regulatory environment in various geographical jurisdictions around the world based primarily on a
2016 analysis by the Law Library of Congress \cite{acosta_government_2016}. A separate 2017 study found that globally,
more than half the world's internet users lived in a country where some form of plaintext recovery is mandated
\cite{lewis_2017}.

\newcommand{\countriesstart}{\begin{itemize}}
\newcommand{\country}[3]{ % Name, citation, description
    \item \textbf{#1} \cite{#2} \nopagebreak

    \vspace{0.5\baselineskip} \parbox{\linewidth}{#3} \vspace{0.5\baselineskip}
}
\newcommand{\countriesend}{\end{itemize}}

% What are the most relevant questions? Can the government---
% - Compel access to---
%   - all data?
%   - data encrypted by a service provider? Who are covered service providers?
% - Compel decryption of---
%   - all data?
%   - data encrypted by a service provider? Who are covered service providers?
% - Perform mass collection?
% - What legal limits are in place (e.g. warrants)?
% - What oversight is in place (e.g. inspectors general, public transparency)?
% - Does the government prescribe technical approaches?
% - Is the government explicitly allowed to engage in hacking?

\countriesstart

    \country{Five Eyes Countries}{acosta_government_2016}{

In 1946 The U.S. formalized an intelligence-sharing operation with the U.K. in the BRUSA (now UKUSA) Agreement. Over the
following 10 years, Australia, Canada, and New Zealand were made full partners to this agreement, which has become known
as ``Five Eyes'' \cite{nsa_2020}. Due to the close relationship between the intelligence and law enforcement agencies of
these countries, the member's encryption policies are relevant to one another.

% Put this in an appendix too? Or its own chapter? Too much detail for the background section.
%
% For more, read donahue_comparative_2018 (Israel and China) and \cite{budish_encryption_2018} (framework for analysis)
%
% Since the enactment of the Regulation of Investigatory Powers Act 2000, the U.K. government had the ability to serve
% written notices requiring mandated decryption. Law enforcement and intelligence agencies also have explicit permission
% to perform ``computer network exploitation,'' and approach this thesis refers to as ``\ac{lawful-hacking}.'' 2016's
% Investigatory Powers Act expanded these capabilities and, among other additions, in section 253 created ``technical
% capability notices'' that the Secretary of State can issue to telecommunications operators mandating \ac{EA}
% \cite{legislature_2016}.

The U.K. government has the explicit ability to force decryption, perform \ac{lawful-hacking}, and mandate \ac{EA}
though ``technical capability notices'' introduced in 2016's Investigatory Powers Act \cite{legislature_2016}. Australia
has weaker powers through a variety of laws, and in 2018 passed the Assistance and Access Act which created very similar
``technical capability notices'' \cite{ag_2018}. Canadian law requires cooperation between telecommunications providers
and law enforcement but does not directly address encryption. Canada has traditionally supported strong encryption, but
the pressure of \ac{the-cw2} is straining that support \cite{parsons_2019}.

}

    \country{European Countries}{acosta_government_2016}{

% It is very important to know who these requirements apply to. This is for telecoms, not Facebook, Google, Signal, or
% WhatsApp. That's a little unclear, but the vagueness is a necessity, since I don't actually know this very well.
% Consider removing the internation section altogether because it's complicated and I'm not sure I'm adding a whole lot
% of value.

Among European countries, France and Russia join the U.K. in having access mandates \cite{lewis_2017}. France, Belgium,
Germany, and Sweden require cooperation between telecommunications providers and law enforcement; for France, Belgium,
and Germany, that includes decrypting network traffic when possible. France, Germany, and Sweden each have some level of
\ac{lawful-hacking} capability. There is no E.U. legislation that requires key disclosure or decryption of network
traffic.

}

    \country{Asian Countries}{acosta_government_2016}{

Japanese authorities require cooperation and can request access to decrypted data, but subjects are not punished for
declining such requests. Taiwanese regulation does not specifically address encryption, but does mandate that
telecommunications providers provide interfaces ``with functions that can cooperate with interception.'' Chinese
authorities have great access to plaintext data by virtue of the political structure of the state, as well as through
explicit requirements in recent anti-terrorism and cybersecurity laws \cite{lewis_2017}.

}

    \country{Other Countries}{acosta_government_2016}{

Brazil, South Africa, and Israel require cooperation between telecommunications providers and law enforcement. Brazil
law does not specifically address encryption, though it does require ``the technological resources necessary to suspend
telecommunications confidentiality in accordance with the law.'' South Africa mandates decryption when possible. Israeli
authorities can issue warrants for access to data or use warrantless orders similar to U.S. \ac{FISA} mechanisms. Israel
also has well developed \ac{lawful-hacking} capabilities and a centralized forensics laboratory
\cite{donahue_comparative_2018}.

}

\countriesend
