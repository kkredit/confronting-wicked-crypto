\chapter{Background}
\label{chap-background}

The problem of strong encryption and \acl{EA} exists in a technical, historical, and regulatory context. This chapter
introduces cryptography, summarizes the history of encryption and the ``crypto wars,'' lists relevant encryption
regulations, and lists prominent technical \ac{EA} proposals. It then introduces argument maps as a logical modeling
tool, and introduces threat modeling with data flow diagrams.



\section{Cryptography Basics}
\label{sec-crypto-basics}

\Ac{cryptography} is the study of techniques for communicating secretly in the presence of third parties. This is
performed by using a \ac{cipher} to translate between \ac{plaintext} and \ac{ciphertext}. A cipher is a tool or
algorithm that performs the translation, plaintext is the original data, and ciphertext is the encoded data. The
processes for translating from plaintext to ciphertext and back are \ac{encryption} and \ac{decryption}. A well-designed
cipher ensures that only those parties with the correct secret information, the \ac{key}, can perform encryption or
decryption on the text.

% There are two classes of cryptographic ciphers---stream and block

There are two major cryptographic protocol families, symmetric and asymmetric. In \ac{sym-crypto}, which was discovered
long ago, encryption and decryption are performed with the same key, and both parties must have this key in order to
communicate securely. In \ac{asym-crypto}, which was discovered recently and is also called \ac{public-key-crypto},
encryption and decryption are performed with two paired keys, called the public key and the private key. The innovation
of \ac{public-key-crypto} is that the public key is not secret, and using this technique, two parties can communicate
securely without requiring a previously agreed upon shared secret.

One can also define two major cryptographic applications---securing \acf{DIM} and \acf{DAR}. Each application is a
different problem that results in different solutions. \Ac{DIM} typically uses long-lived \ac{asym-crypto} keys to
perform authentication and establish short-lived \ac{sym-crypto} session keys; the session keys perform the actual
encryption of the data in transit. Two important properties of \ac{DIM} encryption protocols are \ac{forward-secrecy}
and \ac{replay-protection}. \Ac{forward-secrecy} ensures that a leaked private key or session key does not compromise
any other private key or session key; \ac{replay-protection} ensures that messages cannot be replayed by an
attacker without detection \cite{bellovin_thinking_2016}. \Ac{E2EE} for instant messaging services is an example of
encryption for \ac{DIM}.

\Ac{DAR} by nature must use long-lived keys for encryption. Instead of being negotiated and randomly generated at
encryption-time, as \ac{DIM} session keys are, these keys are either derived from a user-entered password or are stored
somewhere in computer memory, which often takes place with the assistance of dedicated hardware. \Ac{disk-encryption}
for laptops and mobile devices is an example of encryption for \ac{DAR}.

Data secrecy is not cryptography's only purpose, however.

Cryptography is the technical foundation for many forms of computer and network security. Security is defined in terms
of several properties: authentication, integrity, non-repudiation, confidentiality, availability, and authorization
\cite{shostack_threat_2014}. These system-level properties emerge from both the composition of the system's components
(architecture) and the security of the components themselves; likewise, the security of each component emerges from the
architecture of its subcomponents and the security of the subcompenents themselves. At the bottom of this analysis, the
security of primitive components commonly relies on cryptography.

\mytab{table:security-and-crypto} connects each security property to its cryptographic basis. While lacking direct
cryptographic foundations, availability indirectly relies on each other property, and authorization schemes are
typically rooted in authentication.

% TODO: clarify relationship between encryption and cryptography. Use appropriately throughout.

% Spoofing                  Authentication
% Tampering                 Integrity
% Repudiation               Non-Repudiation
% Information Disclosure    Confidentiality
% Denial of Service         Availability
% Elevation of Privilege    Authorization
\begin{table}[h]
    \caption[Security Properties and Cryptography]{The Cryptographic Basis of Security Properties}
    \label{table:security-and-crypto}
    \centering
    \begin{tabular}{|l|l|}
        \hline
        \thead{Property} & \thead{Cryptographic Basis} \\ \hline
        Authentication  & Digital certificates \\ \hline
        Integrity       & Cryptographic hashes \\ \hline
        Non-repudiation & Digital signatures \\ \hline
        Confidentiality & Encryption \\ \hline
        Availability    & \small{\ii{based on architecture}} \\ \hline
        Authorization   & \small{\ii{rooted in authentication}} \\ \hline
    \end{tabular}
\end{table}

% Cryptographic primitives include symmetric key encryption, symmetric key encryption, one-way hash functions, and digital
% signatures. A few technologies that directly rely on these primitives include \ac{TLS}, \ac{PKI}, \ac{SSO} (e.g.
% Kerberos), \acp{VPN}, secure password storage, disk encryption tools, and secure- and trusted-boot processes. A few
% systems that directly rely on these technologies include the local and global financial systems; industrial control
% systems and critical infrastructure; health information systems; private, government, and military communications; and
% the integrity of the internet as a whole.
% % If I bring this back---this is jumping rather quickly from primitives to huge systems. Scale it more smoothly.
% % Connect little primitives to higher technologies, higher technologies to underpinnings of network computer systems,
% % and network computer systems as critical to these industries.

Violations of cryptographic integrity in primitive components, introduced by design or by accident, could have
catastrophic effects. Compromised digital certificates, hashes, or encryption would enable spoofing, tampering, and
information disclosure done both for their own sake and as tools in general attacks. The importance of taking these
tools away is clear when such attacks include interference with elections \cite{mueller_2018}, multi-billion dollar
disruptions of business \cite{greenberg_2018_notpetya}, and hospital network ransoms that disrupt care of patients
\cite{goodin_ransomware_2019}.

% NOTE: tried to find examples of high profile bugs or hacks that relied on crypto failures, but most are still
% architectural (exposed databases, default credentials (Mirai botnet)), human (BEC), or insecure code (buffer
% overflows--key to EternalBlue (wannacry and notpetya) and MS08-067 (Conficker)).

Encryption's dual role as enabler of privacy and cornerstone of security is at the heart of the EA debate. Cryptography
has an absolute, mathematical power---a power that is objectionable in the realm of privacy, but necessary in the realm
of security.


\section{Encryption History}
\label{sec-crypto-history}

The section provides a brief overview of encryption from ancient to modern times.

\subsection{Encryption In the Past}
\label{sec-history-old}

Computerized encryption is a new technology, but the field of cryptography is old, since demand for privacy is as old as
communication itself. The most well known ancient example of rudimentary encryption is the Caesar cipher, named after
the character transposition technique Julius Caesar used to protect private correspondence
\cite{luciano_cryptology_1987}. Significant developments include the first formal cryptographic study by Arab scholars
in the eighth century, advancements made out of necessity in the twentieth century's world wars, and the application of
computers to cryptographic problems \cite{kahn_codebreakers_1996}. Claude Shannon's formalized the modern ``mathematical
analysis of cryptography'' in 1949 \cite{shannon_communication_1949}, and Whitfield Diffie and Martin Hellman published
research on \ac{public-key-crypto} in 1976 \cite{diffie_new_1976}. The discovery of \ac{public-key-crypto} was an
important advance. Combined with computer networking and personal computing advances in the 1980s, it for the first time
put the power of strong encryption not just in the hands of governments and militaries, but of ordinary people.

However, this power enables very strong privacy, and privacy is a property governments aim to regulate. The use of
encryption for for private purposes has a contentious history. In 1587, Mary Queen of Scots was convicted of treason
based on evidence from decrypted letters, and in 1807, prosecutors trying Aaron Burr for treason tried to force
testimony from his secretary on the contents of encrypted messages \cite{kerr_encryption_2017}. Government's natural
stance towards privacy makes it inherently uncomfortable with the rapid increase in availability of strong encryption.

% Electronic encryption must be understood as a technological development embedded in the longer history of privacy and
% human rights.

\subsection{The First Crypto War}
\label{sec-history-cw1}

All these realities---government discomfort with absolute privacy, rapidly increasing availability of strong encryption,
and a blossoming computer industry foundationally reliant on cryptography---came to a head in what has become known as
the first ``crypto war.''

In 1976, the same year Diffie and Hellmann published their research in public key cryptography, the U.S. Congress passed
the \ac{AECA} and declared that strong cryptography is subject to export controls \cite{kehl_right_2015}. The opening
shots of \ac{the-cw1} came in 1991, when the U.S. Senate introduced, but did not pass, a bill mandating access to plain
text contents when authorized by law. In response, Philip Zimmermann released \ac{PGP}, a public key encryption tool to
secure email, in order that strong cryptography be ``made available to the American public before it became illegal to
use'' \cite{zimmermann_1996}. In 1993, the Clinton administration introduced the \ac{clipperchip} \cite{press_1993} with
the goal of ``providing the public with strong cryptographic tools without sacrificing the ability of law enforcement
and intelligence agencies to access unencrypted versions of those communications'' \cite{thompson_2015}. Citing the
foundational role of cryptography in security---and the potential of human rights abuses for compromised
privacy---industry and prominent technical leaders reacted negatively to the initiative \cite{kehl_right_2015}
\cite{zimmermann_1996}. When a prominent security researcher discovered flaws that allowed users to subvert the
\ac{clipperchip} mechanisms \cite{blaze_protocol_1994}, the proposal died.

Despite the failure of the \ac{clipperchip}, the debate over export controls and access to strong encryption continued,
primarily focused on various key escrow proposals \cite{thompson_2015}. In 1996, two pro-encryption bills were
introduced in the US Congress. In the Senate, it was S.1726, the \ac{PROCODEAct} of 1996, to abolish the export controls
on encryption software \cite{burns_s1726_1996}. In the House, it was HR.3011, the \ac{SAFEAct} of 1996, to explicitly
allow arbitrarily strong encryption for all legal activity \cite{goodlatte_hr3011_1996}. Indeed, the \ac{SAFEAct} went
further, including ``provisions that would have barred the government from creating a mandatory key escrow system and
would also have removed export restrictions on most generally available software and hardware containing encryption''
\cite{kehl_right_2015}. Zimmermann, the author of PGP, who had by this time endured an investigation by the Customs
Service for publishing his work, testified before the Senate in favor of the \ac{PROCODEAct} \cite{zimmermann_1996}. In
November of that year, the Clinton administration released an executive order effectively removing export controls on
strong encryption products along the lines of the \ac{PROCODEAct}, which never came to pass \cite{clinton_1996}.

From 1996 to 1999, the \ac{SAFEAct} was proposed several times, had hearings, and gained support \cite{kehl_right_2015}.
By this time, there was ``an overwhelming amount of evidence against moving ahead with any key escrow schemes''
\cite{thompson_2015}, and in 1999 the Clinton administration abruptly changed course, adopting almost all \ac{SAFEAct}
proposals \cite{kehl_right_2015}. This development marks the end of \ac{the-cw1}.

\subsection{The Second Crypto War}
\label{sec-history-cw2}

Two developments paved the way for \ac{the-cw2}. The first was actually a non-development: when the Clinton
administration changed its encryption policy, the U.S. House dropped the \ac{SAFEAct} \cite{goodlatte_hr3011_1996}. The
\ac{PROCODEAct} and other encryption-related bills went unpassed as well, as elaborated in \mysec{sec-us-reg-fails}.
This legislative failure meant that rather than being written in the pen of law, encryption policy was written in the
pencil of executive order.

The second development was the events of and reaction to the morning of September 11, 2001. These events occurred in the
context of decades of all three branches of government expanding law enforcement powers. Presidents promoted the idea of
being ``tough on crime'' and launched a war on drugs; legislators passed bills such as 1978's \ac{FISA}, which provided
broad surveillance powers over foreign nationals, and in some cases U.S. citizens \cite{rodino_1978}; and the judiciary
practiced a ``jurisprudence of crime control'' that gave police broad leeway \cite{gizzi_fourth_2016}.

In this context of expanded surveillance, the scale and audacity of the September 11 attacks seemed to justify yet
greater investigatory powers \cite{bloss_escalating_2007}. October of 2001 saw passage of the USA PATRIOT Act, which had
several significant impacts: it weakened the limitation for using \ac{FISA} requests on U.S. citizens; it expanded the
scope of what could be compelled via \ac{FISA} orders; it authorized ``roving'' wiretaps; and it increased the power of
\acp{NSL}, which can be used without judicial review to compel information from digital service providers while
precluding any public disclosure of the event \cite{sensenbrenner_2001} \cite{shamsi_2011}. The government was
performing more surveillance than ever, and even these weakened limitations would be repeatedly violated
\cite{shamsi_2011} \cite{tucker_2020}.

The weakness of data protection laws and absence of encryption protection laws left the door open for a second crypto
war, and increased government surveillance set events in motion toward conflict, but it was the 2013 \ac{snowden}
revelations that constituted the crossing of the threshold. Though policies such as the U.S. \ac{NSA}'s warrantless
wiretapping caused a stir, it was the mass data collection under the agency's \ac{PRISM} and related programs that
caused the real public outcry \cite{landau_making_2013}. With the public interest focused on digital privacy, encryption
promised a technical solution. Benefiting from advancements in underlying technologies and under pressure from both the
human rights field and from ordinary users demanding improved privacy, U.S. tech companies responded by introducing
default device encryption for \acl{DAR} and \acl{E2EE} for \acl{DIM} \cite{treguer_us_2018}.

The emergence of strong encryption caused \ac{the-cw1}; its proliferation is causing the second.

The U.S. corporate response to \ac{snowden} should not be overly construed as a morally motivated defense of civil
rights, as their behavior is a matter of several practical factors \cite{treguer_us_2018}, not least of which is the
pursuit of basic digital security. Recall encryption and cryptography's critical role in security as described in
\mysec{sec-crypto-basics}, and that encryption's dual role as enabler of strong privacy and cornerstone of computer
security is a central conflict in the \ac{EA} debate. When questioned by lawmakers, technical leaders and executives
have repeatedly appealed to the fact that strong cryptography is a necessity for security \cite{schulze_clipper_2017}.

\subsection{Current Context}
\label{sec-history-current}

Several events and arguments have come to characterize \ac{the-cw2}.

\paragraph*{``Security vs. Security''} The relationship between security and privacy is sometimes viewed as
antagonistic, an assumption implicit in in the ``nothing-to-hide'' argument, but discussions in recent years have shown
that the debate is more about ``Security vs. Security'' than ``Security vs. Privacy''
\cite{stalla_bourdillon_privacy_2014}. In this context, there are two types of security: public security, the pursuit of
law enforcement, and cybersecurity, the pursuit of the technical community. Both sides of the debate have by now
acknowledged that privacy and public security are not always in conflict, and in fact \ac{EA}'s effects on public
security vs. cybersecurity---which in return affects public security---may be more important \cite{schneier_2019}.

\paragraph*{Apple vs. FBI} The 2015 San Bernardino terror attack in which the suspect was killed, leaving behind a
locked iPhone, resulted in the first major battle of \ac{the-cw2}. The \ac{FBI} issued an order under the \acrlong{AWA}
to compel Apple to unlock the device, which was among the first generation of Apple's fully encrypted iPhones; Apple
objected on grounds that it was ``unreasonably burdensome'' and would undercut the integrity of all iOS devices
\cite{schulze_clipper_2017}. The case occupied U.S. District courts, the media, and the political world's attention from
February 16, 2016, when the warrant was issued, to March 28, when the \ac{FBI} announced they had gained access to the
phone through alternate means \cite{novet_2016}. Even though the phone proved not to have any important data
\cite{schulze_clipper_2017}, the high profile case featured two characteristic elements of the new crypto
wars---terrorism and device encryption. Shortly after the case ended, a pair of Republican and Democratic senators
% (https://www.chicagomanualofstyle.org/qanda/data/faq/topics/HyphensEnDashesEmDashes/faq0002.html)
jointly released a discussion draft of a bill that would have forced Apple to comply \cite{burr_2016}. The draft did not
make it to the floor, and the unresolved nature of the court case left the legal debate unresolved.

\paragraph*{\Ac{horsemen}} In the 1990s, an influential encryption advocate coined the phrase ``\ac{horsemen-full}'' to
describe four reasons that governments and law enforcement agencies use to undercut public support for strong encryption
\cite{may_1994}. The traditional list includes terrorists, pedophiles, drug dealers, and money launderers, though
sometimes kidnappers are substituted for money launderers \cite{schneier_scaring_2019}. Reflecting the times,
\ac{the-cw1} emphasized drug trafficking whereas \ac{the-cw2} is emphasizing terrorism and child pornography
\cite{schulze_clipper_2017}. The focus on terrorism is likely a result of culture that emerged from the September 11
terror attacks as well as the San Bernardino terror attack that launched the Apple vs. \ac{FBI} case; the focus on child
pornography is likely a result of the growth of the ``dark web'' and a revelatory 2019 investigation by the \textit{New
York Times} \cite{keller_internet_2019}.

\paragraph*{\ac{DIM} vs. \ac{DAR}} As noted in \mysec{sec-crypto-basics}, securing \acl{DIM} and \acl{DAR} are two
different problems that result in different solutions. Therefore, both technical and policy proposals often split their
recommendations along these lines \cite{group_2019} \cite{owen_law_2018}. The focus from law enforcement in the U.S. has
pendulated between each of these applications a few times \cite{schneier_2019}. The typical \ac{DIM} application is
\ac{E2EE} in instant messaging applications, whereas the typical \ac{DAR} application is \ac{disk-encryption} of mobile
phones. A research group at Carnegie Mellon with participants from both sides of the debate has identified \ac{EA} for
\ac{DAR} as the more tractable problem \cite{group_2019}.

\paragraph*{Volatile Politics} Finally, \ac{the-cw2} is taking place amongst a political landscape marked by
uncertainty, extremism, misinformation, and most recently, a pandemic that will have unknown impacts. Since legislature
is part of the broader data security threat model, its behavior is important. Unfortunately, the dynamics of present
leadership and the lack of reliable data on what law enforcement agencies need make it difficult for the technical
community to engage productively with policy makers \cite{granick_2018}.

That brings us to where the debate stands today. A December 2019 U.S. Senate Judiciary Committee featured the top two
U.S. parties both expressing anger over whether data should be ``beyond the reach of the law'' and expressed threats
such as ``get your act together, or we will gladly get your act together for you'' \cite{geller_2019}. In March 2020,
the Republican atop the Senate Judiciary Committee introduced S.3398, the \ac{EARNITAct} of 2020, which seeks to
establish a 16-chair committee with the power to revoke online platforms' liability protection for user-submitted
content if the committee determines the platform is not doing enough to fight \ac{CSAM}, a legal synonym for child
pornography \cite{graham_s3398_2020}. As illustrated by the previously mentioned \textit{New York Times} feature
\cite{keller_internet_2019} that likely triggered the December 2019 hearing, the problem is enormous; however, critics
largely see the \ac{EARNITAct} as an attempt to indirectly yet effectively outlaw \ac{E2EE} \cite{newman_2020}
\cite{pfefferkorn_2020}.

% NOTE: keep up to date, including the section above mentioning the pandemic
% IDEA: create timeline! https://tex.stackexchange.com/questions/196794/how-can-you-create-a-vertical-timeline


\section{Regulatory Environment}
\label{sec-reg-environment}

The following sections list laws which directly or indirectly affect use of encryption. Though this thesis is
U.S.--focused, it is worth briefly touching on the regulatory environment of other countries. \Ac{EA} is an international
problem, as digital technology has little respect for political borders.

% IDEA: Create an appendix to go into greater detail?
% Could go into these, as well as the commented-out ones below
%  Wiretap Act (http://www.law.cornell.edu/uscode/usc_sup_01_18_10_I_20_119.html)
%  Stored Communications Act (http://www.law.cornell.edu/uscode/usc_sup_01_18_10_I_20_121.html)
%  Pen Register Act (http://www.law.cornell.edu/uscode/usc_sup_01_18_10_II_20_206.html)
% TODO: I _really_ need to understand these and how they're used today.

\subsection{U.S. Efforts to Regulate Encryption}

This section includes both successful and failed cryptography regulation attempts in the U.S.

\subsubsection{Enacted U.S. Regulations}
% FIXME: distinguish statutes vs. regulations; rename "failed" section

The following laws and regulations have been applied to cases involving surveillance, cryptography, and access to
encrypted information:

\newcommand{\lawsstart}{\begin{itemize}}
\newcommand{\law}[4]{ % Year, name, citation, description
    \item #1: \textbf{#2} \cite{#3} \nopagebreak

    \vspace{0.5\baselineskip} \parbox{\linewidth}{#4} \vspace{0.5\baselineskip}
}
\newcommand{\lawsend}{\end{itemize}}

\lawsstart

    \law{1789}{\acf{AWA}}{congress_1789}{

A short law designed to grant federal courts the right to ``issue all writs necessary or appropriate in aid of their
respective jurisdictions and agreeable to the usages and principles of law,'' creating a legal framework for providing
data to law enforcement. The \acs{AWA} was famously cited in the Apple vs. FBI case, though its applicability to \ac{EA}
in general is unsettled \cite{matyas_incommensurability_2018}.

}

    \law{1791}{Bill of Rights: Amendments I, IV, and V}{madison_1791}{

The most frequently cited constitutional amendments in the \ac{EA} debate. I: freedom of speech; IV: protection from
unreasonable searches and seizures and requirements for warrants; V: right against self-incrimination.

}

    \law{1976}{\acf{AECA}}{morgan_hr13680_1976}{

Expanded arms export controls and created the \ac{ITAR} regulations framework. Encryption products were classified as
arms and subjected to export controls \cite{kehl_right_2015}.

}

    \law{1978}{\acf{FISA}}{rodino_1978}{

Allows the executive branch ``to authorize electronic surveillance for foreign intelligence purposes without a court
order, in some circumstances.'' \acs{FISA} applications take place in secret, and may be conducted against U.S. citizens
if foreign intelligence is the ``primary purpose'' \cite{shamsi_2011}. \acs{FISA} has been the subject of frequent FBI
abuse \cite{shamsi_2011} \cite{tucker_2020}.

% (the FBI almost lost some provisions; follow up on https://apnews.com/110ff653e98478da66765897dde3d613,
%     https://www.washingtontimes.com/news/2020/mar/15/adam-schiff-fisa-reform-intervention-protects-fbi-/,
%     https://saraacarter.com/fisa-senate-passes-measure-extending-surveillance-powers-abuses-not-addressed/)
% May 27: renewal in great doubt; Trump opposed because he sees himself as a victim of FISA abuse
%     (https://apnews.com/c04a5e3bb156774af83b686bbe2ea872)

}

%     \law{1986}{\acf{CFAA}}{hughes_hr4718_1986}{
% Criminalized ``knowingly access[ing] a computer without authorization or exceeding authorized access'' and thereby
% violating the confidentiality, integrity, or availability of the system. While presumably intended to target hacking,
% the \acs{CFAA} has been used to prosecute a host of crimes, and suffers from dated language;
% % ---what does it mean to ``access'' a ``computer'' loading a simple webpage may involve dozens of devices---
% whether violating the terms of service constitutes ``exceeding authorized access'' remains an open question
% \cite{wolff_computer_2016}. Importantly for \ac{EA}, the law includes carve-outs for law enforcement and intelligence
% activities.
%
% Follow up: CFAA going before supreme court: https://www.cyberscoop.com/cfaa-will-soon-day-supreme-court/
% }

    \law{1986}{\acf{ECPA}}{kastenmeier_hr4952_1986}{

Amended the Wiretap Act, Stored Communications Act, and Pen Register Act. Provided explicit protections for private
% FIXME: Briefly introduce these. Even just "Amended the switch-board-era"...
electronic communications data, and updated definitions to contemporary technology. It granted law enforcement explicit
access to certain data as well; some terminology has aged poorly with technological evolution, making the access
increasingly permissive \cite{shamsi_2011}.

}

    \law{1994}{\acf{CALEA}}{edwards_hr4922_1994}{

Mandated that telecommunications carriers enable the government to ``intercept all of the subscriber's wire and
electronic communications'' in a manner that ``protects the privacy and security'' of communications not authorized to
be intercepted. The law does not authorize law enforcement to compel use of any specific technologies, which meant that
the \ac{clipperchip} proposal issued a year earlier could not be made mandatory through \acs{CALEA}. \acs{CALEA}
specifically excludes ``information services'' from its interception requirement which has included internet platforms,
though that exclusion is currently under attack \cite{pfefferkorn_2019}.

}

    \law{2001}{\ac{USAPATRIOTAct}}{sensenbrenner_2001}{

Written in the aftermath of September 11, the \ac{USAPATRIOTAct} broadly expanded U.S. government surveillance powers
in 25 sections of ``Title II: Enhanced Surveillance Procedures.'' The act notably expands \acs{FISA} order scope
(Section 206), duration (207), and use on U.S. citizens (218). Section 215 enables court orders requiring business
records, but the \ac{snowden} leaks revealed that the government had been secretly using a non-standard definition of
``business records'' in order ``to justify requests for domestic telephone metadata delivered in bulk, not
individualized requests'' \cite{landau_making_2013}.

}

%     \law{2007}{\acf{PAA}}{mcconnell_s1927_2007}{
% Retroactively approved of GWB's warrantless wiretapping policy, a loose interpretation of FISA
% \cite{landau_making_2013}.
% }

    \law{2008}{\acf{FISAAA}}{reyes_hr6304_2008}{

Like the \ac{USAPATRIOTAct} before it, \acs{FISAAA} expanded \ac{FISA} powers once again. It additionally provided
``telephone companies retroactive immunity for participating in the warrantless surveillance'' on any international
communication, a policy established in 2001 under another loose, secret interpretation of \ac{FISA}, ``as well as
creating prospective immunity for FISAAA activities'' \cite{landau_making_2013}.

}

    \law{2015}{\ac{USAFREEDOMAct}}{sensenbrenner_2015}{

The \ac{USAFREEDOMAct}, introduced by the same U.S. House representative as the \ac{USAPATRIOTAct}, passed the Senate
almost two years to the day after \ac{snowden}'s leaks began. It contains many reforms to \ac{FISA} and the use of
\acp{NSL}. Most notably, it ends the interpretation of section 215 of the \ac{USAPATRIOTAct} that enabled mass
collection of telephone metadata.

}

\lawsend

\subsubsection{The Judicial Environment}
\label{sec-us-judicial}

The above history and section on U.S. law encompasses the executive and legislative branches' influence on surveillance
and cryptography. A complete picture requires understanding the judiciary branch's influence via court rulings. The
judiciary branch exercises power through a framework based on AAAA and BBBB. In this section we analyze several
important cases and developments in the last few years.

% TODO: Framework for understanding judicial influence. See bergerson_judicial_1998 and gizzi_fourth_2016. Update the
%   "AAAA and BBBB" in the intro.

% TODO: Review historically important cases on the 1st, 4th, and 5th amendments, e.g. Katz v. United States, 1969.

% TODO: Review recent cases. See orenstein_2016, bittenbender_2019, vaas_2019.
% NOTE: _Carpenter_ was a recent important Supreme Court case limiting the scope of the third-party doctrine!
% See franklin_2018 and rozenshtein_2018

\subsubsection{Failed U.S. Regulation Attempts}
\label{sec-us-reg-fails}

The following are proposed laws and regulations that did not go into effect or are still in process:

% \cite{burns_s1726_1996} \cite{leahy_s376_1997} \cite{ashcroft_s2067_1998} \cite{goss_hr2616_1999}
% \cite{goss_hr2617_1999} \cite{administration_CESA_1999} \cite{leahy_s3083_2000}

\lawsstart

    \law{1993}{The \ac{clipperchip}}{press_1993}{

As described in \mysec{sec-history-cw1}, the \ac{clipperchip} was a voluntary \ac{EA} initiative from the White House.
The initiative targeted \ac{DIM} and established the Escrowed Encryption Standard, which includes an encrypted copy of
the session key in the message \cite{blaze_protocol_1994}. The initiative prompted debate but received a largely hostile
reception \cite{kehl_right_2015}. When a security researcher discovered flaws that allowed users to subvert the
\ac{clipperchip} mechanisms, the proposal died \cite{blaze_protocol_1994}.

}

    \law{1996}{The \acf{SAFEAct}}{goodlatte_hr3011_1996}{

The \ac{SAFEAct} would have broadly protected ``use any encryption regardless of the encryption algorithm selected,
encryption key length chosen, or implementation technique or medium used,'' excepting ``the unlawful use of encryption
in furtherance of a criminal act.'' It also would have lifted export controls. The bill grew support as it was
reintroduced in consecutive congresses, but was abandoned when the Clinton administration adopted the act's
pro-encryption policies in 1999 \cite{kehl_right_2015}.

}

    \law{1996}{The \acf{PROCODEAct}}{burns_s1726_1996}{

The Senate's \ac{PROCODEAct} was very similar to House's \ac{SAFEAct}, though it focused primarily on removing export
controls, and used slightly weaker language protecting all forms of encryption. Like the \ac{SAFEAct}, it was abandoned
when the Clinton administration adopted the act's export control policies in 1996 \cite{thompson_2015}.

}

%     \law{1997}{Encrypted Communications Privacy Act}{leahy_s376_1997}{
% % mix of SE protection and EA guidelines?
% }

%     \law{1998}{Encryption Protects the Rights of Individuals from Violation and Abuse in CYberspace (E-PRIVACY) Act}
%         {ashcroft_s2067_1998}{
% % like above?
% }

%     \law{1999}{Encryption for the National Interest Act}{goss_hr2616_1999}{
% }

%     \law{1999}{Tax Relief for Responsible Encryption Act}{goss_hr2617_1999}{
% % ^^ these two introduced by same rep on same day
% }

    \law{1999}{\ac{CESA}}{administration_CESA_1999}{

\Ac{CESA} was a legislative proposal by Clinton administration introduced on same day as encryption policy changes that
led to the abandonment of the \ac{SAFEAct}. Section 102 lays out the government position precisely---encryption is an
important tool for information security, but is also used to ``hide unlawful activity by terrorists, drug traffickers,
child pornographers, and other criminals'' (the \ac{horsemen}), and therefore ``appropriate means must be available to
fulfill these law enforcement objectives.'' The bill would establish voluntary-participation third-party key escrow with
``recovery agents'' that would provide law enforcement with access to \ac{plaintext}. Access would be compelled through
a variety of mechanisms, including warrantless mechanisms through \ac{FISA}. The White House failed to attract a
member of Congress to officially sponsor the bill.

}

    \law{2000}{Enhancement of Privacy and Public Safety in Cyberspace Act}{leahy_s3083_2000}{

After \ac{CESA} failed, the White House proposed watered-down legislation that this time was successfully sponsored by a
senator. This bill would have amended the \ac{ECPA} and \ac{CFAA}. It would have made relatively modest changes to
government data access requirements. Though it received congressional sponsorship, even the sponsor was critical of
parts of the bill, and it died in committee \cite{senate_2000}.

}

    \law{2016}{Compliance with Court Orders Act (discussion draft)}{burr_2016}{

Though this bill was not officially proposed, it represents one of the first legislative attempts to regulate encryption
in \ac{the-cw2}. This draft was released shortly after the close of the Apple vs. FBI case, and would have compelled
Apple to unlock the phone. Though it would not mandate a technical mechanism, the bill would have mandated that
manufacturers and service providers be able to provide \ac{EA}. This mandate notably goes beyond several regulatory
proposals in \ac{the-cw1} by forcing platform and application developers to comply. Previewing a common phrase in recent
\ac{EA} arguments \cite{geller_2019}, the draft's authors both used the phrase ``above the law'' in promotion of the
bill.

}

    \law{2018}{The Secure Data Act}{lofgren_hr5823_2018}{

Proposed in reaction to the Compliance with Court Orders Act and anti-encryption sentiment, this bill would have
provided protections against ``mandating the deployment of vulnerabilities in data security technologies'' at the
federal level. It stopped short of explicitly protecting all forms of encryption.

}

    \law{2019}{The \ac{ENCRYPTAct}}{lieu_hr4170_2019}{

This bill is designed to ``preempt State data security vulnerability mandates and decryption requirements,'' being a
state-level version of the Secure Data Act. This bill goes further to explicitly disallow \ac{EA} requirements in state
law.

% TODO: as of 7/10/20, this bill is still active. Follow up.

}

    \law{2020}{The \acf{EARNITAct}}{graham_s3398_2020}{

Introduced by the chair of the Senate Judiciary Committee, one of the outspoken encryption critics during the 2019
Senate hearing on encryption and \ac{EA}, the \ac{EARNITAct} is designed to address \ac{CSAM} and has received attention
as a threat to encryption \cite{newman_2020} \cite{pfefferkorn_2020}. As described in \mysec{sec-history-current}, the
bill would revoke online platforms' liability protection for user-submitted content if it is does not doing enough to
combat \ac{CSAM}. Critics fear that meeting the regulatory requirements would preclude \ac{E2EE}, and at least one
popular \ac{E2EE} messaging platform has threatened to pull out of the U.S. market if the bill were to pass
\cite{lund_2020}.

% TODO: Update based on new amendment.

}

    \law{2020}{The \acf{LEADAct}}{graham_2020}{

Introduced by the same senator as the \ac{EARNITAct}, the \ac{LEADAct} is a direct attack on encryption. The
\ac{LEADAct} specifically addresses \ac{DAR} and \ac{DIM} by forcing device, operating system, and application
developers to implement the ability to decrypt all data stored or passing through the device or software system
``concurrently with their transmission'' ``unless the independent actions of an unaffiliated entity make it technically
impossible to do so.'' The act neither mandates nor recommends any technical approach to providing this capability.

% TODO: how does this differ from the old "Compliance with Court Orders Act" draft?

}

\lawsend


\subsection{Regulations around the World}

This thesis is U.S.--focused, but \ac{EA} technologies and policies have international impacts. The following is a very
brief account of the regulatory environment in various jurisdictions around the world based primarily on a 2016 analysis
by the Law Library of Congress \cite{acosta_government_2016}.

\newcommand{\countriesstart}{\begin{itemize}}
\newcommand{\country}[3]{ % Name, citation, description
    \item \textbf{#1} \cite{#2} \nopagebreak

    \vspace{0.5\baselineskip} \parbox{\linewidth}{#3} \vspace{0.5\baselineskip}
}
\newcommand{\countriesend}{\end{itemize}}

% What are the most relevant questions? Can the government---
% - Compel access to---
%   - all data?
%   - data encrypted by a service provider? Who are covered service providers?
% - Compel decryption of---
%   - all data?
%   - data encrypted by a service provider? Who are covered service providers?
% - Perform mass collection?
% - What legal limits are in place (e.g. warrants)?
% - What oversight is in place (e.g. inspectors general, public transparency)?
% - Does the government prescribe technical approaches?
% - Is the government explicitly allowed to engage in hacking?

\countriesstart

    \country{Five Eyes Countries}{acosta_government_2016}{

In 1946 The U.S. formalized an intelligence sharing operation with the U.K. in the BRUSA (now UKUSA) Agreement; over the
following 10 years, Australia, Canada, and New Zealand were made full partners to this agreement, which has become known
as ``Five Eyes'' \cite{nsa_2020}. Due to the close relationship between the intelligence and law enforcement agencies of
these countries, the member's encryption policies are relevant to one another.

% IDEA: put this in an appendix too? Or its own chapter? Too much detail for the background section.
%
% For more, read donahue_comparative_2018 (Israel and China) and budish_encryption_2018 (framework for analysis)
%
% Since the enactment of the Regulation of Investigatory Powers Act 2000, the U.K. government had the ability to serve
% written notices requiring mandated decryption. Law enforcement and intelligence agencies also have explicit permission
% to perform ``computer network exploitation,'' and approach this thesis refers to as ``\ac{lawful-hacking}.'' 2016's
% Investigatory Powers Act expanded these capabilities and, among other additions, in section 253 created ``technical
% capability notices'' that the Secretary of State can issue to telecommunications operators mandating \ac{EA}
% \cite{legislature_2016}.

The U.K. government has the explicit ability to force decryption, perform \ac{lawful-hacking}, and mandate \ac{EA}
though ``technical capability notices'' introduced in 2016's Investigatory Powers Act \cite{legislature_2016}. Australia
has weaker powers through a variety of laws, and in 2018 passed the Assistance and Access Act which created very similar
``technical capability notices'' \cite{ag_2018}. Canadian law requires cooperation between telecommunications providers
and law enforcement but does not directly address encryption. Canada has traditionally supported strong encryption, but
the pressure of \ac{the-cw2} is causing strain \cite{parsons_2019}.

}

    \country{European Countries}{acosta_government_2016}{

% TODO: it is very important to know who these requirements apply to. Traditional telecoms, obviously. Facebook and
% Google? Signal and WhatsApp? Telecoms, not platforms or apps. This is the big differentiator. This can be expanded
% upon when I talk a bit about pen registers, etc.

France, Belgium, Germany, and Sweden require cooperation between telecommunications providers and law enforcement; for
France, Belgium, and Germany, that includes decrypting network traffic when possible. France, Germany, and Sweden each
have some level of \ac{lawful-hacking} capability. There is no E.U. legislation that requires key disclosure or
decryption of network traffic.

}

    \country{Asian Countries}{acosta_government_2016}{

Japanese authorities require cooperation and can request access to decrypted data, but subjects are not punished for
declining such requests. Taiwanese regulation does not specifically address encryption, but does mandate that
telecommunications providers provide interfaces ``with functions that can cooperate with interception.'' Chinese
authorities have great access to plaintext data by virtue of the political structure of the state, but its 2015
counter-terrorism law explicitly compels access to plaintext data upon request \cite{donahue_comparative_2018}.

}

    \country{Other Countries}{acosta_government_2016}{

Brazil, South Africa, and Israel require cooperation between telecommunications providers and law enforcement. Brazil
law does not specifically address encryption, though it does require ``the technological resources necessary to suspend
telecommunications confidentiality in accordance with the law.'' South Africa mandates decryption when possible. Israeli
authorities can issue warrants for access to data or use warrantless orders similar to U.S. \ac{FISA} mechanisms. Israel
also has well developed \ac{lawful-hacking} capabilities and a centralized forensics laboratory
\cite{donahue_comparative_2018}.

}

\countriesend



\section{Approaches to Exceptional Access}
\label{sec-tech-approaches}

% There are several types of approaches:
% IDEA: my selections here are also rather sparse. Create another appendix? (I love work). Possibly create table of
% properties below, similar to denning_taxonomy_1996. savage_lawful_2018 has some good citations to mine.
% - Allow strong encryption (anyone with the users' private keys can see it)
% - Disallow encryption (anyone can see it)
% - Make encryption sufficiently weak, e.g. limit key length (anyone with enough CPU can see it)
% - Require use of backdoored algorithms, security via obscurity (anyone with the secret knowledge can see it)
% - Allow any encryption, just be able to provide keys (anyone with the extra keys can see it)
%   - Store extra in gov't DBs, in corporate DBs, in third-party DBs, on blockchain, in secure HW on device
%   - Split the key and store it multiple places
%   - See denning_taxonomy_1996
% - Use some alternative path
%   - Coerced passwords, finding unencrypted copies, seizing devices while unlocked, lawful hacking

% Lesson: the problem is _not_ cryptographically storing and splitting key recovery information. It's keeping those keys
%   safe! If you can sit on recorded data and wait for the keys to get leaked, which they will...

% Moving forward, what are the elements that are needed for a feasible EA system? (1) White-box-secure ways of producing
% key recovery information. Do the protocols exist? EES failed. Needs to be rock solid. (2) Dispersed key recovery
% information. (3) A robust, antifragile, inherently secure means of protecting those keys, and perhaps decaying them over
% time (https://en.wikipedia.org/wiki/Data_degradation).

There are several technical approaches to \ac{EA}. This section categorizes these approaches according to one of three
basic approaches---\ac{key-escrow}, cryptographic recovery without a key, or non-cryptographic means of acquiring
plaintext.

\newcommand{\propsstart}[0]{\begin{itemize}}
\newcommand{\prop}[2]{ % Name, description
    \item \textbf{#1} \nopagebreak

    \vspace{0.5\baselineskip} \parbox{\linewidth}{#2} \vspace{0.5\baselineskip}
}
\newcommand{\propsend}{\end{itemize}}


\subsection{Types of Key Escrow}

The most obvious approach to \ac{EA} is to store additional copies of the encrypting keys. A variation is to store
information that can be used to derive additional copies. This approach is called \ac{key-escrow}. There are several
classes of key escrow.

\propsstart
    \prop{Trusted-party key escrow}{

Any scheme that relies on the fidelity and security of information held by an entity besides the data owner (in the case
of \ac{DAR}) or sender or receiver (in the case of \ac{DIM}) is a ``trusted-party'' key escrow approach. Though there is
a wide variety of implementation options within this category \cite{denning_taxonomy_1996}---secret or open protocol,
hardware-enabled or software-only, single key or split key, government or third-party escrow---the foundation of the
effectiveness of these approaches lies in the security of the trusted party. The \ac{clipperchip} is one example, being
a secret protocol hardware-enabled split key government escrow system \cite{denning_taxonomy_1996}.

}

    \prop{Distributed key escrow}{

Some schemes compensate for the risk of concentrated sensitive information by massively distributing the secret
information. In this arrangement, trust is put in the distrubuted system, not in any single party. Such systems offer
high data availability while making it difficult for attempts to acquire keys to be secret or to subvert access
policies. This approach was introduced in \ac{the-cw1} \cite{goos_oblivious_1996} and has come into its own through the
application of blockchain \cite{phan_key_2017}. These approaches are not as thoroughly explored as trusted-party
\ac{key-escrow}.

}

    \prop{Device key escrow}{

A third type of \ac{key-escrow} is device-based. In device-based \ac{key-escrow}, special key information is held not by
trusted parties or distributed systems, but on the device itself in specialized hardware. Advances in secure hardware
``enclaves'' since \ac{the-cw1} have enabled secure local key storage. Approaches relying on hardware primarily target
\ac{DAR}, and may include time elements and split keys with trusted parties as well \cite{savage_lawful_2018}
\cite{ozzie_2018}.

}
\propsend


\subsection{Non-Escrow Cryptographic Recovery}

Though key recovery is the most discussed \ac{EA} approach, alternative technical means have been proposed.

\propsstart
    \prop{Translucent cryptography}{

Research in \ac{the-cw1} included the introduction of ``translucent'' cryptography, in which an observer could surveil
some but not all communications using statistical cryptographic methods \cite{bellare_translucent_1996}. Under this
scheme, no keys are escrowed, but law enforcement could recover a predetermined fraction---say, 40\%---of plaintext
data. That fraction would be designed to balance privacy, digital security, and public security. This research, though
decidedly more experimental than key escrow proposals, was explicitly pursued to demonstrate that alternatives to key
escrow do exist \cite{bellare_translucent_1996}.

}

% TODO: add wright_crypto_2018 (I _think_ it goes here)

\propsend


\subsection{Alternative Approaches}

The following approaches do not use \ac{EA} at all, but are alternative technical or legal mechanisms that can be used
towards the same goal.

\propsstart
    \prop{\Ac{lawful-hacking}}{

As introduced in \mysec{sec-reg-environment}, one workaround to direct \ac{EA} is \ac{lawful-hacking}. Under
\ac{lawful-hacking}, instead of having access to plaintext data via an alternative means of decryption, law enforcement
is allowed to perform otherwise-illegal hacking activity in order to find the key, compromise a device, or intercept
plaintext versions of the data \cite{kerr_encryption_2017}. While some see this as a viable middle ground
\cite{nguyen_lawful_2017}, encouraging law enforcement to exploit vulnerabilities creates mis-aligned incentives. If law
enforcement opposes strong security in general, it could foster the exploit market while costing ordinary users money
and security \cite{soesanto_2018}.

}

    \prop{Forced password disclosure}{

In some cases, a suspect in custody may have the ability to access the desired encrypted information via a key,
\ac{PIN}, or password. In these cases, authorities sometimes compel the suspect to disclose the password. In the U.S.,
this approach draws debates about the fifth amendment right against self-incrimination \cite{bittenbender_2019}. Of
course, this approach cannot address \ac{DIM} or situations in which the knowledgeable party is not in custody.

% these look good: sacharoff_unlocking_2018, fredona_fifth_2016
% this probably has something to say: kerr_encryption_2017

}

    \prop{Alternative paths to plaintext}{

Simpler methods can be used than computer hacking or legal coercion: encrypted data may exist in plaintext elsewhere, or
authorities may seize equipment while it is unlocked \cite{kerr_encryption_2017}. This approach relies on skills law
enforcement is traditionally good at---investigation and sting operations---and is used successfully. In 2017, an
international law enforcement operation used this technique to take down a large illicit online drug market
\cite{greenberg_2018}. This approach also does not address \ac{DIM}, and requires well-executed operations.

}
\propsend

\section{Argument Maps}
\label{sec-arg-maps-intro}

The arguments used in the \ac{EA} debate are diverse and complex; in order to advance the \ac{EA} discussion, it would
help to organize all the arguments used in a cohesive manner. One way to organize arguments is to create argument maps.
Argument maps are graphical representations of the logical structures and relationships between statements, premises,
and conclusions. Argument maps are an outgrowth of the same research by Horst Rittel that originated the idea of
\acp{wicked-prob}. In 1970 his research group developed \acp{IBIS} to break down \acp{wicked-prob} and document the
reasoned approaches that go into solving them \cite{kunz_issues_1970}. Interest in \ac{IBIS} has waxed and waned. Some
software tools have been developed, including the now-defunct gIBIS \cite{conklin_gibis_1988} and Compendium
\cite{dutoit_hypermedia_2006} tools designed to produce graphical representations. Argdown is a recent tool that
generates argument maps from structures specified in a Markdown-based language \cite{voigt_argdown_2018}.

Argdown is used in \mychap{chap-arguments} to analyze the arguments used in the \ac{EA} debate. \myfig{fig-args-demo}
shows the basic structure of arguments. Statements are positions on issues. Some statements are based on values that
cannot be addressed through argument. Statements and arguments may support or attack one another, and arguments support
or undercut other arguments.

\begin{figure}[ht]
    \centering\CaptionFontSize
    \includegraphics[max width=\linewidth]{arguments/build/demo.pdf}
    % \def\svgmaxwidth{\linewidth}
    % \input{arguments/build/demo.tex}
    \caption[Argdown Demo]{A demonstrative example of argument maps with Argdown.}
    \label{fig-args-demo}
\end{figure}

% IDEA:
% Use the slightly more complete IBIS notation, which includes ISSUES and POSITIONS as well as ARGUMENTS.
% (Argdown) basically just has arguments and positions. The additional types may make the total picture clearer.
% Either use styling with #hashtags (https://argdown.org/syntax/#hashtags with
%                                    https://argdown.org/guide/colorizing-maps.html#the-colorscheme-setting)
% Or add a plugin (https://argdown.org/guide/extending-argdown.html)



\section{Threat Models and Data Flow Diagrams}
\label{sec-threat-model-intro}

Threat modeling is an important step in analyzing the security at the systems level. Using models abstracts away fine
details and focuses on the architecture, processes, and dataflows in a system. Models assist in the understanding of
current systems and the prevention of problems in new systems, both of which are important when facing the prospect of
designing an \ac{EA} mechanism built on top of a complex and aging technology stack.

Threat modeling begins with the questions, ``What are you building?'' and ``What can go wrong?''
\cite{shostack_threat_2014}. Answering the first question accurately is crucial, particularly for the field of
cryptography, which hinges on precise definitions of security requirements \cite{varia_2018}. Answering the second
question depends on the types of attackers to worry about, and determines the scope of threats to be considered. ``What
are you building?'' hasn't been asked enough in the current phase of the \ac{EA} debate, and ``What can go wrong?''
cannot be faithfully answered without knowing what is being built.

\Acp{DFD} are one tool designed to address these questions. \Acp{DFD} feature processes, data flows, data stores, and
external entities. \Acp{DFD} are well suited for threat modeling because security vulnerabilities tend to follow data
flow, not control flow \cite{shostack_threat_2014}. They are particularly well suited for \ac{EA}, as data privacy is
the primary concern. \myfig{fig-dfd-demo} shows the basic elements of a \ac{DFD}. In \mychap{chap-threatmodel} I create
\acp{DFD} in this style to analyze the threats already present and those that \ac{EA} would introduce.

\begin{figure}[ht]
    \centering\CaptionFontSize
    \includegraphics[width=\linewidth]{dfds/build/DFD-demo.png}
    \caption[\Acs{DFD} Demo]{A demonstrative example of a \acf{DFD}.}
    \label{fig-dfd-demo}
\end{figure}
