\chapter{Background}
\label{chap-background}

The problem of strong encryption and \acl{EA} exists in a technical, historical, and regulatory context. This chapter
introduces cryptography, summarizes the history of encryption and the ``crypto wars,'' lists relevant encryption
regulations, and lists prominent technical \ac{EA} proposals. It then introduces \acp{argmap} as a logical modeling
tool, and introduces threat modeling with data flow diagrams.



\section{Cryptography Basics}
\label{sec-crypto-basics}

\Ac{cryptography} is the study of techniques for communicating secretly in the presence of third parties. This is
performed by using a \ac{cipher} to translate between \ac{plaintext} and \ac{ciphertext}. A cipher is a tool or
algorithm that performs the translation, plaintext is the original data, and ciphertext is the encoded data. The
processes for translating from plaintext to ciphertext and back are \ac{encryption} and \ac{decryption}. A well-designed
cipher ensures that only those parties with the correct secret information, the \ac{key}, can perform encryption or
decryption on the text.

% There are two classes of cryptographic ciphers---stream and block

There are two major cryptographic protocol families, symmetric and asymmetric. In \ac{sym-crypto}, which was invented
long ago, encryption and decryption are performed with the same key, and both parties must have this key in order to
communicate securely. In \ac{asym-crypto}, which was invented recently and is also called \ac{public-key-crypto},
encryption and decryption are performed with two paired keys, called the public key and the private key. The innovation
of \ac{public-key-crypto} is that the public key is not secret, and using this technique, two parties can communicate
securely without requiring a previously agreed upon shared secret.

One can also define two major cryptographic applications---securing \acf{DIM} and \acf{DAR}. Each application is a
different problem that results in different solutions. \Ac{DIM} typically uses long-lived \ac{asym-crypto} keys to
perform authentication and establish short-lived \ac{sym-crypto} session keys; the session keys perform the actual
encryption of the data in motion. Two important properties of \ac{DIM} encryption protocols are \ac{forward-secrecy} and
\ac{replay-protection}. \Ac{forward-secrecy} ensures that a leaked private key or session key does not compromise any
other private key or session key; \ac{replay-protection} ensures that messages cannot be replayed by an attacker without
detection \cite{bellovin_thinking_2016}. \Ac{E2EE} for instant messaging services is an example of encryption for
\ac{DIM}.

\Ac{DAR} by nature must use long-lived keys for encryption. Instead of being negotiated and randomly generated at
encryption-time, as \ac{DIM} session keys are, these keys are either derived from a user-entered password or are stored
somewhere in computer memory, which often takes place with the assistance of dedicated hardware. \Ac{disk-encryption}
for laptops and mobile devices is an example of encryption for \ac{DAR}.

Data secrecy is not cryptography's only use, however. Precisely speaking, data secrecy is the purpose of encryption.
Encryption is cryptography's ``killer app,'' but it is only a part of cryptography's usefulness to security.

Cryptography is the technical foundation for many forms of computer and network security. Security is defined in terms
of several properties: authentication, integrity, non-repudiation, confidentiality, availability, and authorization
\cite{shostack_threat_2014}. These system-level properties emerge from both the composition of the system's components
(architecture) and the security of the components themselves; likewise, the security of each component emerges from the
architecture of its subcomponents and the security of the subcomponents themselves. At the end of this chain of
analysis, the security of primitive components commonly relies on cryptography.

\mytab{table-security-and-crypto} connects each security property to its cryptographic basis. While lacking direct
cryptographic foundations, availability indirectly relies on each other property, and authorization schemes are
typically rooted in authentication.

% Spoofing                  Authentication
% Tampering                 Integrity
% Repudiation               Non-Repudiation
% Information Disclosure    Confidentiality
% Denial of Service         Availability
% Elevation of Privilege    Authorization
\begin{table}[h]
    \caption{The Cryptographic Basis of Security Properties}
    \label{table-security-and-crypto}
    \centering
    \begin{tabular}{ |l|l| }
        \hline
        \thead{Property} & \thead{Cryptographic Basis}           \\ \hline
        Authentication   & Digital certificates                  \\ \hline
        Integrity        & Cryptographic hashes                  \\ \hline
        Non-repudiation  & Digital signatures                    \\ \hline
        Confidentiality  & Encryption                            \\ \hline
        Availability     & \small{\ii{based on architecture}}    \\ \hline
        Authorization    & \small{\ii{rooted in authentication}} \\ \hline
    \end{tabular}
\end{table}

% Cryptographic primitives include symmetric key encryption, symmetric key encryption, one-way hash functions, and digital
% signatures. A few technologies that directly rely on these primitives include \ac{TLS}, \ac{PKI}, \ac{SSO} (e.g.
% Kerberos), \acp{VPN}, secure password storage, disk encryption tools, and secure- and trusted-boot processes. A few
% systems that directly rely on these technologies include the local and global financial systems; industrial control
% systems and critical infrastructure; health information systems; private, government, and military communications; and
% the integrity of the internet as a whole.
% % If I bring this back---this is jumping rather quickly from primitives to huge systems. Scale it more smoothly.
% % Connect little primitives to higher technologies, higher technologies to underpinnings of network computer systems,
% % and network computer systems as critical to these industries.

Violations of cryptographic integrity in primitive components, introduced by design or by accident, could have
catastrophic effects. Compromised digital certificates, hashes, or encryption would enable spoofing, tampering, and
information disclosure done both for their own sake and as tools in general attacks. The importance of taking these
tools away is clear when such attacks include interference with elections \cite{mueller_2018}, multi-billion dollar
disruptions of business \cite{greenberg_2018_notpetya}, and hospital network ransoms that disrupt care of patients
\cite{goodin_ransomware_2019}.

% I tried to find examples of high profile bugs or hacks that relied on crypto failures, but most are still
% architectural (exposed databases, default credentials (Mirai botnet)), human (BEC), or insecure code (buffer
% overflows--key to EternalBlue (wannacry and notpetya) and MS08-067 (Conficker)).

Encryption's dual role as enabler of privacy and cornerstone of security is at the heart of the EA debate. Cryptography
has an absolute, mathematical power---a power that is objectionable in the realm of privacy, but necessary in the realm
of security.


\section{Encryption History}
\label{sec-crypto-history}

The section provides a brief overview of encryption from ancient to modern times.

\subsection{Encryption In the Past}
\label{sec-history-old}

Computerized encryption is a new technology, but the field of cryptography is old, since demand for privacy is as old as
communication itself. The most well known ancient example of rudimentary encryption is the Caesar cipher, named after
the character substitution technique Julius Caesar used to protect private correspondence
\cite{luciano_cryptology_1987}. Significant developments include the first formal cryptographic study by Arab scholars
in the eighth century, advancements made out of necessity in the twentieth century's world wars, and the application of
computers to cryptographic problems \cite{kahn_codebreakers_1996}. Claude Shannon's formalized the modern ``mathematical
analysis of cryptography'' in 1949 \cite{shannon_communication_1949}, and Whitfield Diffie and Martin Hellman published
research on \ac{public-key-crypto} in 1976 \cite{diffie_new_1976}. The discovery of \ac{public-key-crypto} was an
important advance. Combined with computer networking and personal computing advances in the 1980s, it for the first time
put the power of strong encryption not just in the hands of governments and militaries, but of ordinary people.

However, this power enables very strong privacy, and privacy is a property governments aim to regulate. The use of
encryption for for private purposes has a contentious history. In 1587, Mary Queen of Scots was convicted of treason
based on evidence from decrypted letters, and in 1807, prosecutors trying Aaron Burr for treason tried to force
testimony from his secretary on the contents of encrypted messages \cite{kerr_encryption_2017}. Government's natural
stance towards privacy makes it inherently uncomfortable with the rapid increase in availability of strong encryption.

% Electronic encryption must be understood as a technological development embedded in the longer history of privacy and
% human rights.

\subsection{The First Crypto War}
\label{sec-history-cw1}

All these realities---government discomfort with absolute privacy, rapidly increasing availability of strong encryption,
and a blossoming computer industry foundationally reliant on cryptography---came to a head in what has become known as
the first ``crypto war.''

In 1976, the same year Diffie and Hellmann published their research in public key cryptography, the U.S. Congress passed
the \ac{AECA} and declared that strong cryptography is subject to export controls \cite{kehl_right_2015}. The opening
shots of \ac{the-cw1} came in 1991, when the U.S. Senate introduced, but did not pass, a bill mandating access to plain
text contents when authorized by law. In response, Philip Zimmermann released \ac{PGP}, a public key encryption tool to
secure email, in order that strong cryptography be ``made available to the American public before it became illegal to
use'' \cite{zimmermann_1996}. In 1993, the Clinton administration introduced the \ac{clipperchip} \cite{press_1993} with
the goal of ``providing the public with strong cryptographic tools without sacrificing the ability of law enforcement
and intelligence agencies to access unencrypted versions of those communications'' \cite{thompson_2015}. Citing the
foundational role of cryptography in security---and the potential of human rights abuses for compromised
privacy---industry and prominent technical leaders reacted negatively to the initiative \cite{kehl_right_2015}
\cite{zimmermann_1996}. When a prominent security researcher discovered flaws that allowed users to subvert the
\ac{clipperchip} mechanisms \cite{blaze_protocol_1994}, the proposal died.

Despite the failure of the \ac{clipperchip}, the debate over export controls and access to strong encryption continued,
primarily focused on various key escrow proposals \cite{thompson_2015}. In 1996, two pro-encryption bills were
introduced in the US Congress. In the Senate, it was S.1726, the \ac{PROCODEAct} of 1996, to abolish the export controls
on encryption software \cite{burns_s1726_1996}. In the House, it was HR.3011, the \ac{SAFEAct} of 1996, to explicitly
allow arbitrarily strong encryption for all legal activity \cite{goodlatte_hr3011_1996}. Indeed, the \ac{SAFEAct} went
further, including ``provisions that would have barred the government from creating a mandatory key escrow system and
would also have removed export restrictions on most generally available software and hardware containing encryption''
\cite{kehl_right_2015}. Zimmermann, the author of PGP, who had by this time endured an investigation by the Customs
Service for publishing his work, testified before the Senate in favor of the \ac{PROCODEAct} \cite{zimmermann_1996}. In
November of that year, the Clinton administration released an executive order effectively removing export controls on
strong encryption products along the lines of the \ac{PROCODEAct}, which never came to pass \cite{clinton_1996}.

From 1996 to 1999, the \ac{SAFEAct} was proposed several times, had hearings, and gained support \cite{kehl_right_2015}.
By this time, there was ``an overwhelming amount of evidence against moving ahead with any key escrow schemes''
\cite{thompson_2015}, and in 1999 the Clinton administration abruptly changed course, adopting almost all \ac{SAFEAct}
proposals \cite{kehl_right_2015}. This development marks the end of \ac{the-cw1}.

\subsection{The Second Crypto War}
\label{sec-history-cw2}

Two developments paved the way for \ac{the-cw2}. The first was actually a non-development: when the Clinton
administration changed its encryption policy, the U.S. House dropped the \ac{SAFEAct} \cite{goodlatte_hr3011_1996}. The
\ac{PROCODEAct} and other encryption-related bills went unpassed as well, as elaborated in \mysec{sec-us-reg-fails}.
This legislative failure meant that rather than being written in the pen of law, encryption policy was written in the
pencil of executive order.

The second development was the events of and reaction to the morning of September 11, 2001. These events occurred in the
context of decades of all three branches of government expanding law enforcement powers. Presidents promoted the idea of
being ``tough on crime'' and launched a war on drugs; legislators passed bills such as 1978's \ac{FISA}, which provided
broad surveillance powers over foreign nationals, and in some cases U.S. citizens \cite{rodino_1978}; and the judiciary
practiced a ``jurisprudence of crime control'' that gave police broad leeway \cite{gizzi_fourth_2016}.

In this context of expanded surveillance, the scale and audacity of the September 11 attacks seemed to justify yet
greater investigatory powers \cite{bloss_escalating_2007}. October of 2001 saw passage of the USA PATRIOT Act, which had
several significant impacts: it weakened the limitation for using \ac{FISA} requests on U.S. citizens; it expanded the
scope of what could be compelled via \ac{FISA} orders; it authorized ``roving'' wiretaps; and it increased the power of
\acp{NSL}, which can be used without judicial review to compel information from digital service providers while
precluding any public disclosure of the event \cite{sensenbrenner_2001} \cite{shamsi_2011}. The government was
performing more surveillance than ever, and even these weakened limitations would be repeatedly violated
\cite{shamsi_2011} \cite{tucker_2020}.

The weakness of data protection laws and absence of encryption protection laws left the door open for a second crypto
war, and increased government surveillance set events in motion toward conflict, but it was the 2013 Snowden revelations
that constituted the crossing of the threshold. Though policies such as the U.S. \ac{NSA}'s warrantless wiretapping
caused a stir, it was the mass data collection under the agency's \ac{PRISM} and related programs that caused the real
public outcry \cite{landau_making_2013}. With the public interest focused on digital privacy, encryption promised a
technical solution. Benefiting from advancements in underlying technologies and under pressure from both the human
rights field and from ordinary users demanding improved privacy, U.S. tech companies responded by introducing default
device encryption for \acl{DAR} and \acl{E2EE} for \acl{DIM} \cite{treguer_us_2018}.

The emergence of strong encryption caused \ac{the-cw1}; its proliferation is causing the second.

The U.S. corporate response to Snowden should not be overly construed as a morally motivated defense of civil rights, as
their behavior is a matter of several practical factors \cite{treguer_us_2018}, not least of which is the pursuit of
basic digital security. Recall encryption and cryptography's critical role in security as described in
\mysec{sec-crypto-basics}, and that encryption's dual role as enabler of strong privacy and cornerstone of computer
security is a central conflict in the \ac{EA} debate. When questioned by lawmakers, technical leaders and executives
have repeatedly appealed to the fact that strong cryptography is a necessity for security \cite{schulze_clipper_2017}.

\subsection{Current Context}
\label{sec-history-current}

Several events and arguments have come to characterize \ac{the-cw2}.

\paragraph*{``Security vs. Security''} The relationship between security and privacy is sometimes viewed as
antagonistic, an assumption implicit in the ``nothing-to-hide'' argument, but discussions in recent years have shown
that the debate is more about ``Security vs. Security'' than ``Security vs. Privacy''
\cite{stalla_bourdillon_privacy_2014}. In this context, there are two types of security: public security, the pursuit of
law enforcement, and cybersecurity, the pursuit of the technical community. Both sides of the debate have by now
acknowledged that privacy and public security are not always in conflict, and in fact \ac{EA}'s effects on public
security vs. cybersecurity---which in return affects public security---may be more important \cite{schneier_2019}.

\paragraph*{Apple vs. FBI} The 2015 San Bernardino terror attack in which the suspect was killed, leaving behind a
locked iPhone, resulted in the first major battle of \ac{the-cw2}. The \ac{FBI} issued an order under the \acrlong{AWA}
to compel Apple to unlock the device, which was among the first generation of Apple's fully encrypted iPhones; Apple
objected on grounds that it was ``unreasonably burdensome'' and would undercut the integrity of all iOS devices
\cite{schulze_clipper_2017}. The case occupied U.S. District courts, the media, and the political world's attention from
February 16, 2016, when the warrant was issued, to March 28, when the \ac{FBI} announced they had gained access to the
phone through alternate means \cite{novet_2016}. Even though the phone proved not to have any important data
\cite{schulze_clipper_2017}, the high profile case featured two characteristic elements of the new crypto
wars---terrorism and device encryption. Shortly after the case ended, a pair of Republican and Democratic senators
jointly released a discussion draft of a bill that would have forced Apple to comply \cite{burr_2016}. The draft did not
make it to the floor, and the unresolved nature of the court case left the legal debate unresolved.

\paragraph*{The \Ac{horsemen}} In the 1990s, an influential encryption advocate coined the phrase ``\ac{horsemen-full}'' to
describe four reasons that governments and law enforcement agencies use to undercut public support for strong encryption
\cite{may_1994}. The traditional list includes terrorists, pedophiles, drug dealers, and money launderers, though
sometimes kidnappers are substituted for money launderers \cite{schneier_scaring_2019}. Reflecting the times,
\ac{the-cw1} emphasized drug trafficking whereas \ac{the-cw2} is emphasizing terrorism and child pornography (\ac{CSAM})
\cite{schulze_clipper_2017}. The focus on terrorism is likely a result of culture that emerged from the September 11
terror attacks as well as the San Bernardino terror attack that launched the Apple vs. \ac{FBI} case; the focus on
\ac{CSAM} is likely a result of the growth of the ``dark web'' and a revelatory 2019 investigation by the \textit{New
York Times} \cite{keller_internet_2019}.

\paragraph*{\ac{DIM} vs. \ac{DAR}} As noted in \mysec{sec-crypto-basics}, securing \acl{DIM} and \acl{DAR} are two
different problems that result in different solutions. Therefore, both technical and policy proposals often split their
recommendations along these lines \cite{group_2019} \cite{owen_law_2018}. The focus from law enforcement in the U.S. has
pendulated between each of these applications a few times \cite{schneier_2019}. The typical \ac{DIM} application is
\ac{E2EE} in instant messaging applications, whereas the typical \ac{DAR} application is \ac{disk-encryption} of mobile
phones. A research group at Carnegie Mellon with participants from both sides of the debate has identified \ac{EA} for
\ac{DAR} as the more tractable problem \cite{group_2019}.

\paragraph*{Volatile Politics} Finally, \ac{the-cw2} is taking place amongst a political landscape marked by
uncertainty, extremism, misinformation, and a pandemic that will have unknown long-term impacts. Since legislature is
part of the broader data security threat model, its behavior is important. Unfortunately, the present political dynamics
and the lack of reliable data on what law enforcement agencies need make it difficult for the technical community to
engage productively with policymakers \cite{granick_2018}.

That brings us to where the debate stands today. A December 2019 U.S. Senate Judiciary Committee featured the top two
U.S. parties both expressing anger over whether data should be ``beyond the reach of the law'' and expressed threats
such as ``get your act together, or we will gladly get your act together for you'' \cite{geller_2019}. In March 2020,
the Republican atop the Senate Judiciary Committee introduced S.3398, the \ac{EARNITAct} of 2020, which seeks to
establish a 16-chair committee with the power to revoke online platforms' liability protection for user-submitted
content if the committee determines the platform is not doing enough to fight \ac{CSAM}, a legal synonym for child
pornography \cite{graham_s3398_2020}. As illustrated by the previously mentioned \textit{New York Times} feature
\cite{keller_internet_2019} that likely triggered the December 2019 hearing, the problem is enormous; however, critics
largely saw the \ac{EARNITAct} as an attempt to indirectly yet effectively outlaw \ac{E2EE} \cite{newman_2020}
\cite{pfefferkorn_2020}. In response, legislators narrowed the focus of the \ac{EARNITAct}, but only after unveiling the
\ac{LAEDAct}

% Could create timeline https://tex.stackexchange.com/questions/196794/how-can-you-create-a-vertical-timeline



\section{Approaches to Exceptional Access}
\label{sec-tech-approaches}

% TODO: Does this read well here? Used to be after Regulatory Environment section.

% There are several types of approaches:
%  My selections here are also rather sparse. Create another appendix? Possibly create table of
% properties below, similar to denning_taxonomy_1996. savage_lawful_2018 has some good citations to mine.
% - Allow strong encryption (anyone with the users' private keys can see it)
% - Disallow encryption (anyone can see it)
% - Make encryption sufficiently weak, e.g. limit key length (anyone with enough CPU can see it)
% - Require use of backdoor-ed algorithms, security via obscurity (anyone with the secret knowledge can see it)
% - Allow any encryption, just be able to provide keys (anyone with the extra keys can see it)
%   - Store extra in govt DBs, in corporate DBs, in third-party DBs, on blockchain, in secure HW on device
%   - Split the key and store it multiple places
%   - See denning_taxonomy_1996
% - Use some alternative path
%   - Coerced passwords, finding unencrypted copies, seizing devices while unlocked, lawful hacking

% Lesson: the problem is _not_ cryptographically storing and splitting key recovery information. It's keeping those keys
%   safe! If you can sit on recorded data and wait for the keys to get leaked, which they will...

% Moving forward, what are the elements that are needed for a feasible EA system? (1) White-box-secure ways of producing
% key recovery information. Do the protocols exist? EES failed. Needs to be rock solid. (2) Dispersed key recovery
% information. (3) A robust, anti-fragile, inherently secure means of protecting those keys, and perhaps decaying them
% over time (https://en.wikipedia.org/wiki/Data_degradation).

There are several technical approaches to \ac{EA}. This section categorizes these approaches according to one of three
basic approaches---\ac{key-escrow}, cryptographic recovery without a key, or non-cryptographic means of acquiring
plaintext.

\newcommand{\propsstart}[0]{\begin{itemize}}
\newcommand{\prop}[2]{ % Name, description
    \item \textbf{#1} \nopagebreak

    \vspace{0.5\baselineskip} \parbox{\linewidth}{#2} \vspace{0.5\baselineskip}
}
\newcommand{\propsend}{\end{itemize}}


\subsection{Types of Key Escrow}

The most obvious approach to \ac{EA} is to store additional copies of the encrypting keys. A variation is to store
information that can be used to derive additional copies. This approach is called \ac{key-escrow}. There are several
classes of key escrow.

\propsstart
    \prop{Trusted-party key escrow}{

Any scheme that relies on the fidelity and security of information held by an entity besides the data owner (in the case
of \ac{DAR}) or sender or receiver (in the case of \ac{DIM}) is a ``trusted-party'' key escrow approach. Though there is
a wide variety of implementation options within this category \cite{denning_taxonomy_1996}---secret or open protocol,
hardware-enabled or software-only, single key or split key, government or third-party escrow---the foundation of the
effectiveness of these approaches lies in the security of the trusted party. The \ac{clipperchip} is one example, being
a secret protocol hardware-enabled split key government escrow system \cite{denning_taxonomy_1996}.

}

    \prop{Distributed key escrow}{

Some schemes compensate for the risk of concentrated sensitive information by massively distributing the secret
information. In this arrangement, trust is put in the distributed system, not in any single party. Such systems offer
high data availability while making it difficult for attempts to acquire keys to be secret or to subvert access
policies. This approach was introduced in \ac{the-cw1} \cite{goos_oblivious_1996} and has modern blockchain
\cite{phan_key_2017} and distributed device \cite{servan_schreiber_jje_2020} variations. These approaches are not as
thoroughly explored as trusted-party \ac{key-escrow}.

}

    \prop{Device key escrow}{

A third type of \ac{key-escrow} is device-based. In device-based \ac{key-escrow}, special key information is held not by
trusted parties or distributed systems, but on the device itself in specialized hardware. Advances in secure hardware
``enclaves'' since \ac{the-cw1} have enabled secure local key storage. Approaches relying on hardware primarily target
\ac{DAR}, and may include time elements and split keys with trusted parties as well \cite{savage_lawful_2018}
\cite{ozzie_2018}.

}
\propsend


\subsection{Non-Escrow Cryptographic Data Recovery}

Though key escrow is the most discussed \ac{EA} approach, alternative technical means have been proposed.

\propsstart
    \prop{Translucent cryptography}{

Research in \ac{the-cw1} included the introduction of ``translucent'' cryptography, in which an observer could surveil
some but not all communications using statistical cryptographic methods \cite{bellare_translucent_1996}. Under this
scheme, no keys are escrowed, but law enforcement could recover a predetermined fraction---say, 40\%---of plaintext
data. That fraction would be designed to balance privacy, digital security, and public security. This research, though
decidedly more experimental than key escrow proposals, was explicitly pursued to demonstrate that alternatives to key
escrow do exist \cite{bellare_translucent_1996}.

}

    \prop{Cryptographic ``crumple zones''}{

A recent proposal adopts the idea of crumple zones from automotive engineering---``in an emergency situation the
construction should break a little bit in order to protect the integrity of the system as a whole and the safety of its
human users'' \cite{wright_crypto_2018}. Similar to the translucent approach, no keys are escrowed and only passive
surveillance is possible. Strong cryptography is a precondition for this scheme, in which keys are generated in a manner
that makes them inherently recoverable only after a large up front and marginal cost.

}
\propsend


\subsection{Alternative Approaches}
\label{sec-alt-approaches}

The following approaches do not use \ac{EA} at all, but are alternative technical or legal mechanisms that can be used
towards the same goal.

\propsstart
    \prop{\Ac{lawful-hacking}}{

As introduced in \mysec{sec-reg-environment}, one workaround to direct \ac{EA} is \ac{lawful-hacking}. Under
\ac{lawful-hacking}, instead of having access to plaintext data via an alternative means of decryption, law enforcement
is allowed to perform otherwise-illegal hacking activity in order to find the key, compromise a device, or intercept
plaintext versions of the data \cite{kerr_encryption_2017}. While some see this as a viable middle ground
\cite{nguyen_lawful_2017}, encouraging law enforcement to exploit vulnerabilities creates mis-aligned incentives. If law
enforcement opposes strong security in general, it could foster the exploit market while costing ordinary users money
and security \cite{soesanto_2018}.

}

    \prop{Compelled password disclosure}{

In some cases, a suspect in custody may have the ability to access the desired encrypted information via a key,
\ac{PIN}, or password. In these cases, authorities sometimes compel the suspect to disclose the password. In the U.S.,
this approach draws debates about the Fifth Amendment right against self-incrimination \cite{bittenbender_2019}
\cite{sobel_2019}. Of course, this approach cannot address \ac{DIM} or situations in which the knowledgeable party is
not in custody.

% these look good: \cite{sacharoff_unlocking_2018}, \cite{fredona_fifth_2016}
% this probably has something to say: kerr_encryption_2017

}

    \prop{Alternative paths to plaintext}{

Simpler methods can be used than computer hacking or legal coercion: encrypted data may exist in plaintext elsewhere, or
authorities may seize equipment while it is unlocked \cite{kerr_encryption_2017}. This approach relies on skills law
enforcement is traditionally good at---investigation and sting operations---and is used successfully. In 2017, an
international law enforcement operation used this technique to take down a large illicit online drug market
\cite{greenberg_2018}. This approach also does not address \ac{DIM}, and requires well-executed operations.

}
\propsend



\section{Regulatory Environment}
\label{sec-reg-environment}

The following sections list laws which directly or indirectly affect use of encryption. Though this thesis is
U.S.--focused, it is worth briefly touching on the regulatory environment of other countries. \Ac{EA} is an
international problem, as digital technology has little respect for political borders.
\mysecrange{sec-us-regs}{sec-us-judicial} describe the regulatory environment in the U.S. and \mysec{sec-world-regs}
describes regulations around the world.

\subsection{Enacted U.S. Regulations}
\label{sec-us-regs}

The following laws and regulations have been applied to cases involving surveillance, cryptography, and access to
encrypted information:

\newcommand{\lawsstart}{\begin{itemize}}
\newcommand{\law}[4]{ % Year, name, citation, description
    \item #1: \textbf{#2} #3 \nopagebreak

    \vspace{0.5\baselineskip} \parbox{\linewidth}{#4} \vspace{0.5\baselineskip}
}
\newcommand{\lawsend}{\end{itemize}}

\lawsstart

    \law{1789}{\acf{AWA}}{\cite{congress_1789}}{

A short law designed to grant federal courts the right to ``issue all writs necessary or appropriate in aid of their
respective jurisdictions and agreeable to the usages and principles of law,'' creating a legal framework for providing
data to law enforcement. The \acs{AWA} was famously cited in the Apple vs. FBI case, though its applicability to \ac{EA}
in general is unsettled \cite{matyas_incommensurability_2018}.

}

    \law{1791}{Bill of Rights: Amendments I, IV, and V}{\cite{madison_1791}}{

The most frequently cited constitutional amendments in the \ac{EA} debate. I: freedom of speech; IV: protection from
unreasonable searches and seizures and requirements for warrants; V: right against self-incrimination.

}

    \law{1976}{\acf{AECA}}{\cite{morgan_hr13680_1976}}{

Expanded arms export controls and created the \ac{ITAR} regulations framework. Encryption products were classified as
arms and subjected to export controls \cite{kehl_right_2015}.

}

    \law{1978}{\acf{FISA}}{\cite{rodino_1978}}{

Allows the executive branch ``to authorize electronic surveillance for foreign intelligence purposes without a court
order, in some circumstances.'' \acs{FISA} applications take place in secret, and may be conducted against U.S. citizens
if foreign intelligence is the ``primary purpose'' \cite{shamsi_2011}. \acs{FISA} has been the subject of frequent FBI
abuse \cite{shamsi_2011} \cite{tucker_2020}.

% (the FBI almost lost some provisions; follow up on https://apnews.com/110ff653e98478da66765897dde3d613,
%     https://www.washingtontimes.com/news/2020/mar/15/adam-schiff-fisa-reform-intervention-protects-fbi-/,
%     https://saraacarter.com/fisa-senate-passes-measure-extending-surveillance-powers-abuses-not-addressed/)
% May 27: renewal in great doubt; Trump opposed because he sees himself as a victim of FISA abuse
%     (https://apnews.com/c04a5e3bb156774af83b686bbe2ea872)

}

%     \law{1986}{\acf{CFAA}}{\cite{hughes_hr4718_1986}}{
% Criminalized ``knowingly access[ing] a computer without authorization or exceeding authorized access'' and thereby
% violating the confidentiality, integrity, or availability of the system. While presumably intended to target hacking,
% the \acs{CFAA} has been used to prosecute a host of crimes, and suffers from dated language;
% % ---what does it mean to ``access'' a ``computer'' loading a simple webpage may involve dozens of devices---
% whether violating the terms of service constitutes ``exceeding authorized access'' remains an open question
% \cite{wolff_computer_2016}. Importantly for \ac{EA}, the law includes carve-outs for law enforcement and intelligence
% activities.
%
% Follow up: CFAA going before supreme court: https://www.cyberscoop.com/cfaa-will-soon-day-supreme-court/
% }

    \law{1986}{\acf{ECPA}}{\cite{kastenmeier_hr4952_1986}}{

Included the Stored Communications Act and Pen Register Act, amending the switchboard-era Wiretap Act. Provided explicit
protections for private electronic communications data, and updated definitions to contemporary technology. It granted
law enforcement explicit access to certain data as well; some terminology has aged poorly with technological evolution,
making the access increasingly permissive \cite{shamsi_2011}.

}

    \law{1994}{\acf{CALEA}}{\cite{edwards_hr4922_1994}}{

Mandated that telecommunications carriers enable the government to ``intercept all of the subscriber's wire and
electronic communications'' in a manner that ``protects the privacy and security'' of communications not authorized to
be intercepted. The law does not authorize law enforcement to compel use of any specific technologies, which meant that
the \ac{clipperchip} proposal issued a year earlier could not be made mandatory through \acs{CALEA}. \acs{CALEA}
specifically excludes ``information services'' from its interception requirement which has included internet platforms,
though that exclusion is currently under attack \cite{pfefferkorn_2019}.

}

    \law{2001}{\ac{USAPATRIOTAct}}{\cite{sensenbrenner_2001}}{

Written in the aftermath of September 11, the \ac{USAPATRIOTAct} broadly expanded U.S. government surveillance powers in
25 sections of ``Title II: Enhanced Surveillance Procedures.'' The act notably expands \acs{FISA} order scope (Section
206), duration (207), and use on U.S. citizens (218). Section 215 enables court orders requiring business records, but
the Snowden leaks revealed that the government had been secretly using a non-standard definition of ``business records''
in order ``to justify requests for domestic telephone metadata delivered in bulk, not individualized requests''
\cite{landau_making_2013}.

}

%     \law{2007}{\acf{PAA}}{\cite{mcconnell_s1927_2007}}{
% Retroactively approved of George W. Bush's warrantless wiretapping policy, a loose interpretation of FISA
% \cite{landau_making_2013}.
% }

    \law{2008}{\acf{FISAAA}}{\cite{reyes_hr6304_2008}}{

Like the \ac{USAPATRIOTAct} before it, \acs{FISAAA} expanded \ac{FISA} powers once again. It additionally provided
``telephone companies retroactive immunity for participating in the warrantless surveillance'' on any international
communication, a policy established in 2001 under another loose, secret interpretation of \ac{FISA}, ``as well as
creating prospective immunity for FISAAA activities'' \cite{landau_making_2013}.

}

    \law{2015}{\ac{USAFREEDOMAct}}{\cite{sensenbrenner_2015}}{

The \ac{USAFREEDOMAct}, introduced by the same U.S. House representative as the \ac{USAPATRIOTAct}, passed the Senate
almost two years to the day after Snowden's leaks began. It contains many reforms to \ac{FISA} and the use of \acp{NSL}.
Most notably, it ends the interpretation of section 215 of the \ac{USAPATRIOTAct} that enabled mass collection of
telephone metadata.

}

\lawsend

\subsection{Unsuccessful U.S. Regulation Attempts}
\label{sec-us-reg-fails}

The following are proposed laws and regulations that did not go into effect or are still in process:

% \cite{burns_s1726_1996} \cite{leahy_s376_1997} \cite{ashcroft_s2067_1998} \cite{goss_hr2616_1999}
% \cite{goss_hr2617_1999} \cite{administration_CESA_1999} \cite{leahy_s3083_2000}

\lawsstart

    \law{1993}{The \ac{clipperchip}}{\cite{press_1993}}{

As described in \mysec{sec-history-cw1}, the \ac{clipperchip} was a voluntary \ac{EA} initiative from the White House.
The initiative targeted \ac{DIM} and established the Escrowed Encryption Standard, which includes an encrypted copy of
the session key in the message \cite{blaze_protocol_1994}. The initiative prompted debate but received a largely hostile
reception \cite{kehl_right_2015}. When a security researcher discovered flaws that allowed users to subvert the
\ac{clipperchip} mechanisms, the proposal died \cite{blaze_protocol_1994}.

}

    \law{1996}{The \acf{SAFEAct}}{\cite{goodlatte_hr3011_1996}}{

The \ac{SAFEAct} would have broadly protected ``use any encryption regardless of the encryption algorithm selected,
encryption key length chosen, or implementation technique or medium used,'' excepting ``the unlawful use of encryption
in furtherance of a criminal act.'' It also would have lifted export controls. The bill grew support as it was
reintroduced in consecutive congresses, but was abandoned when the Clinton administration adopted the act's
pro-encryption policies in 1999 \cite{kehl_right_2015}.

}

    \law{1996}{The \acf{PROCODEAct}}{\cite{burns_s1726_1996}}{

The Senate's \ac{PROCODEAct} was very similar to House's \ac{SAFEAct}, though it focused primarily on removing export
controls, and used slightly weaker language protecting all forms of encryption. Like the \ac{SAFEAct}, it was abandoned
when the Clinton administration adopted the act's export control policies in 1996 \cite{thompson_2015}.

}

%     \law{1997}{Encrypted Communications Privacy Act}{\cite{leahy_s376_1997}}{
% % mix of SE protection and EA guidelines?
% }

%     \law{1998}{Encryption Protects the Rights of Individuals from Violation and Abuse in CYberspace (E-PRIVACY) Act}
%         {\cite{ashcroft_s2067_1998}}{
% % like above?
% }

%     \law{1999}{Encryption for the National Interest Act}{\cite{goss_hr2616_1999}}{
% }

%     \law{1999}{Tax Relief for Responsible Encryption Act}{\cite{goss_hr2617_1999}}{
% % ^^ these two introduced by same rep on same day
% }

    \law{1999}{\ac{CESA}}{\cite{administration_CESA_1999}}{

\Ac{CESA} was a legislative proposal by Clinton administration introduced on same day as encryption policy changes that
led to the abandonment of the \ac{SAFEAct}. Section 102 lays out the government position precisely---encryption is an
important tool for information security, but is also used to ``hide unlawful activity by terrorists, drug traffickers,
child pornographers, and other criminals'' (the \ac{horsemen}), and therefore ``appropriate means must be available to
fulfill these law enforcement objectives.'' The bill would establish voluntary-participation third-party key escrow with
``recovery agents'' that would provide law enforcement with access to \ac{plaintext}. Access would be compelled through
a variety of mechanisms, including warrantless mechanisms through \ac{FISA}. The White House failed to attract a
member of Congress to officially sponsor the bill.

}

    \law{2000}{Enhancement of Privacy and Public Safety in Cyberspace Act}{\cite{leahy_s3083_2000}}{

After \ac{CESA} failed, the White House proposed watered-down legislation that this time was successfully sponsored by a
senator. This bill would have amended the \ac{ECPA} and \ac{CFAA}. It would have made relatively modest changes to
government data access requirements. Though it received congressional sponsorship, even the sponsor was critical of
parts of the bill, and it died in committee \cite{senate_2000}.

}

    \law{2016}{Compliance with Court Orders Act (discussion draft)}{\cite{burr_2016}}{

Though this bill was not officially proposed, it represents one of the first legislative attempts to regulate encryption
in \ac{the-cw2}. This draft was released shortly after the close of the Apple vs. FBI case, and would have compelled
Apple to unlock the phone. Though it would not mandate a technical mechanism, the bill would have mandated that
manufacturers and service providers be able to provide \ac{EA}. This mandate notably goes beyond several regulatory
proposals in \ac{the-cw1} by forcing platform and application developers to comply. Previewing a common phrase in recent
\ac{EA} arguments \cite{geller_2019}, the draft's authors both used the phrase ``above the law'' in promotion of the
bill.

}

    \law{2018}{The Secure Data Act}{\cite{lofgren_hr5823_2018}}{

Proposed in reaction to the Compliance with Court Orders Act and anti-encryption sentiment, this bill would have
provided protections against ``mandating the deployment of vulnerabilities in data security technologies'' at the
federal level. It stopped short of explicitly protecting all forms of encryption.

}

    \law{2019}{The \ac{ENCRYPTAct}}{\cite{lieu_hr4170_2019}}{

This bill is designed to ``preempt State data security vulnerability mandates and decryption requirements,'' being a
state-level version of the Secure Data Act. This bill goes further to explicitly disallow \ac{EA} requirements in state
law.

}

%     \law{2020}{The \acf{EARNITAct}}{\cite{graham_s3398_2020}}{

% Introduced by the chair of the Senate Judiciary Committee, one of the outspoken encryption critics during the 2019
% Senate hearing on encryption and \ac{EA}, the \ac{EARNITAct} is designed to address \ac{CSAM} and has received attention
% as a threat to encryption \cite{newman_2020} \cite{pfefferkorn_2020}. As described in \mysec{sec-history-current}, the
% bill would revoke online platforms' liability protection for user-submitted content if it is does not doing enough to
% combat \ac{CSAM}. Critics fear that meeting the regulatory requirements would preclude \ac{E2EE}, and at least one
% popular \ac{E2EE} messaging platform has threatened to pull out of the U.S. market if the bill were to pass
% \cite{lund_2020}.

% % Note: based on the amendment's modifications, it is no longer about encryption. This has become more moderation and
% % CSAM focused, and the LAED Act has taken over the encryption side. A wise split (not that either bill is necessarily
% % good.)
% % https://www.engadget.com/earn-it-act-amendments-pass-senate-judiciary-committee-165030518.html

% }

    \law{2020}{The \acf{LAEDAct}}{\cite{graham_2020}}{

The \ac{LAEDAct} is a direct attack on encryption and the direct successor of the Compliance with Court Orders Act. It
was introduced by the chair of the Senate Judiciary Committee, also sponsor of the \ac{EARNITAct} and one of the
outspoken encryption critics during the 2019 Senate hearing on encryption and \ac{EA}. The \ac{LAEDAct} specifically
addresses \ac{DAR} and \ac{DIM} by forcing device, operating system, and application developers to implement the ability
to decrypt all data stored or passing through the device or software system ``concurrently with their transmission''
``unless the independent actions of an unaffiliated entity make it technically impossible to do so.'' The act neither
mandates nor recommends any technical approach to providing this capability.

}

\lawsend

\subsection{The U.S. Judicial Environment}
\label{sec-us-judicial}

The above history and section on U.S. law encompasses the executive and legislative branches' influence on surveillance
and cryptography. A complete picture requires understanding the judiciary branch's influence via court rulings. The
judiciary branch influences policy through interpretation of laws and creation of legal doctrine. In this section I
describe this influence, review how it has affected cryptography policy, and analyze where cryptographic jurisprudence
may go from here.

The primary judiciary function is to adjudicate the law through the determination of facts and interpretation of
authoritative legal texts. However, whether it is condemned, denied, seen as a stark reality, or seen as a valid
function, the judicial branch also establishes legal doctrine and actively enforces rulings in a manner that amounts to
creation of public policy \cite{feeley_judicial_2000}. Due to the clear congressional authority over telecommunications
and federal investigatory powers, the courts are most likely to exert influence in this area through interpretation of
current law. This interpretation will both determine how present law is enforced and draw a constitutional line around
any actions the executive or legislative branches undertake.

Judicial influence on encryption policy is primarily mediated through the Fourth Amendment, particularly regarding the
interpretation of a person's ``effects,'' what is ``reasonable,'' and what is a ``search.'' The Supreme Court's
interpretation and implementation of the Amendment's crime control-- and civil liberty--balancing principles has changed
over time. An in-depth analysis of the Court's jurisprudence from the 1960's Warren Court, through the influential 1980s
Rehnquist Court, to the mid-2010s Roberts Court found a deep proclivity towards crime control that is slowly thawing
\cite{gizzi_fourth_2016}. This thawing, caused by evolution of technology, of the court, and of the justices themselves,
has been favorable for data privacy. Recent cases have increasingly sided with defendants, have caused justices to
strain to show that they understand technology, and have increased the categories of protected digital data
\cite{gizzi_fourth_2016}. 2018's potentially landmark \ii{Carpenter v. United States} may be the most impactful yet;
though it only resulted in a narrow decision against unwarranted cell phone location data tracking, it does undermine
the pre-digital third-party doctrine, which holds that Fourth Amendment protection is forfeit when the data is willingly
given to a third-party \cite{franklin_2018}.

As this relates to \ac{EA}, Fourth Amendment interpretation determines the threshold at which authorities require a
warrant, not what demands they can or cannot make once they have one (e.g. demands for access to \ac{plaintext}). As
mentioned above, the FBI argued in the San Bernardino case that the \ac{AWA} grants it authority to demand access,
though it is strongly argued that \acs{CALEA} explicitly precludes this kind of demand \cite{gidari_2016}. Since the FBI
dropped the case, the matter is not formally settled, though the consensus is that legislation such as the \ac{LAEDAct}
is required before courts would uphold that command.

The second most salient legal issue is the Fifth Amendment right against self-incrimination, which comes up in cases of
compelled password disclosure. This question has not yet reached the Supreme Court, and state courts have ruled
compelled disclosure both constitutional \cite{sobel_2019} \cite{lee_nj_2020} and unconstitutional \cite{lee_its_2020}
\cite{vaas_2019}.

That judicial influence on privacy and technology is changing is to be expected. To explain the fluctuating state of
legal interpretation as it relates to \ac{EA}, Matyas et al. make the helpful distinction between legal rules and
principles \cite{matyas_incommensurability_2018}:

\begin{displayquote}
The tension between technical and legal views of sensitive issues such as encryption and surveillance is illuminated by
applying the jurisprudential lens. \dots~Liberal legal systems, manifesting what is generally understood as ``the rule
of law,'' are actually composed of both rules and principles. Legal ``rules'' can be understood as logical propositions
that are expected to yield answers about what is and is not permitted using formal reasoning capabilities. By contrast,
legal ``principles'' articulate values and policies that must be reflected in a legal system but do not necessarily
dictate an unambiguous outcome in any given case.
\end{displayquote}

Rules are the low-level implementation of principles. When the underlying facts of the situation change, as they do by
definition for wicked problems, the rules become out of sync with the principles that bade them. Recent flux in judicial
rulings surrounding surveillance and technology, particularly around the Fourth Amendment, are evidence that the courts
are in the process of updating interpretations of rules in light of the new facts; which principles they ultimately
choose to favor remains to be seen, but rulings like \ii{Carpenter} show a willingness to protect privacy.

Looking ahead, there are three types of cases through which the judicial branch could have a strong effect on digital
privacy policy. First, Fourth Amendment cases will establish classes of protected data and thresholds for warrants.
Second, a Supreme Court Fifth Amendment case could settle under what circumstances, if any, a password could be
compelled. Third, a surprise \ac{AWA} ruling could open the door to demands for access, though legislation like
\ac{LAEDAct} is more likely to have this effect.



\subsection{Regulations around the World}
\label{sec-world-regs}

This thesis is U.S.--focused, but \ac{EA} technologies and policies have international impacts. The following is a very
brief account of the regulatory environment in various geographical jurisdictions around the world based primarily on a
2016 analysis by the Law Library of Congress \cite{acosta_government_2016}. Globally, a 2017 study found that more than
half the world's internet users lived in a country where some form of plaintext recovery is mandated \cite{lewis_2017}.

\newcommand{\countriesstart}{\begin{itemize}}
\newcommand{\country}[3]{ % Name, citation, description
    \item \textbf{#1} \cite{#2} \nopagebreak

    \vspace{0.5\baselineskip} \parbox{\linewidth}{#3} \vspace{0.5\baselineskip}
}
\newcommand{\countriesend}{\end{itemize}}

% What are the most relevant questions? Can the government---
% - Compel access to---
%   - all data?
%   - data encrypted by a service provider? Who are covered service providers?
% - Compel decryption of---
%   - all data?
%   - data encrypted by a service provider? Who are covered service providers?
% - Perform mass collection?
% - What legal limits are in place (e.g. warrants)?
% - What oversight is in place (e.g. inspectors general, public transparency)?
% - Does the government prescribe technical approaches?
% - Is the government explicitly allowed to engage in hacking?

\countriesstart

    \country{Five Eyes Countries}{acosta_government_2016}{

In 1946 The U.S. formalized an intelligence sharing operation with the U.K. in the BRUSA (now UKUSA) Agreement; over the
following 10 years, Australia, Canada, and New Zealand were made full partners to this agreement, which has become known
as ``Five Eyes'' \cite{nsa_2020}. Due to the close relationship between the intelligence and law enforcement agencies of
these countries, the member's encryption policies are relevant to one another.

% Put this in an appendix too? Or its own chapter? Too much detail for the background section.
%
% For more, read donahue_comparative_2018 (Israel and China) and \cite{budish_encryption_2018} (framework for analysis)
%
% Since the enactment of the Regulation of Investigatory Powers Act 2000, the U.K. government had the ability to serve
% written notices requiring mandated decryption. Law enforcement and intelligence agencies also have explicit permission
% to perform ``computer network exploitation,'' and approach this thesis refers to as ``\ac{lawful-hacking}.'' 2016's
% Investigatory Powers Act expanded these capabilities and, among other additions, in section 253 created ``technical
% capability notices'' that the Secretary of State can issue to telecommunications operators mandating \ac{EA}
% \cite{legislature_2016}.

The U.K. government has the explicit ability to force decryption, perform \ac{lawful-hacking}, and mandate \ac{EA}
though ``technical capability notices'' introduced in 2016's Investigatory Powers Act \cite{legislature_2016}. Australia
has weaker powers through a variety of laws, and in 2018 passed the Assistance and Access Act which created very similar
``technical capability notices'' \cite{ag_2018}. Canadian law requires cooperation between telecommunications providers
and law enforcement but does not directly address encryption. Canada has traditionally supported strong encryption, but
the pressure of \ac{the-cw2} is causing strain \cite{parsons_2019}.

}

    \country{European Countries}{acosta_government_2016}{

% It is very important to know who these requirements apply to. This is for telecoms, not Facebook, Google, Signal, or
% WhatsApp. That's a little unclear, but the vagueness is a necessity, since I don't actually know this very well.
% Consider removing the internation section altogether because it's complicated and I'm not sure I'm adding a whole lot
% of value.

Among European countries, France and Russia join the U.K. in having access mandates \cite{lewis_2017}. France, Belgium,
Germany, and Sweden require cooperation between telecommunications providers and law enforcement; for France, Belgium,
and Germany, that includes decrypting network traffic when possible. France, Germany, and Sweden each have some level of
\ac{lawful-hacking} capability. There is no E.U. legislation that requires key disclosure or decryption of network
traffic.

}

    \country{Asian Countries}{acosta_government_2016}{

Japanese authorities require cooperation and can request access to decrypted data, but subjects are not punished for
declining such requests. Taiwanese regulation does not specifically address encryption, but does mandate that
telecommunications providers provide interfaces ``with functions that can cooperate with interception.'' Chinese
authorities have great access to plaintext data by virtue of the political structure of the state, but also through
explicit requirements in recent anti-terrorism and cybersecurity laws \cite{lewis_2017}.

}

    \country{Other Countries}{acosta_government_2016}{

Brazil, South Africa, and Israel require cooperation between telecommunications providers and law enforcement. Brazil
law does not specifically address encryption, though it does require ``the technological resources necessary to suspend
telecommunications confidentiality in accordance with the law.'' South Africa mandates decryption when possible. Israeli
authorities can issue warrants for access to data or use warrantless orders similar to U.S. \ac{FISA} mechanisms. Israel
also has well developed \ac{lawful-hacking} capabilities and a centralized forensics laboratory
\cite{donahue_comparative_2018}.

}

\countriesend
